<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D1104.0305%2C1210.7495%2C1103.5112%2C1210.2959%2C1211.1990%2C1206.0166%2C1209.2562%2C1208.3228%2C1107.2834%2C1201.6255%2C1202.1696%2C1208.3383%2C1203.0886%2C1104.3795%2C1206.4841%2C1210.4145%2C1206.0560%2C1108.0251%2C1103.6007%2C1211.6894%2C1109.2893%2C1201.3022%2C1212.5054%2C1210.3741%2C1106.3616%2C1202.4578%2C1204.3198%2C1209.1859%2C1109.2556%2C1108.4167%2C1102.5225%2C1103.2373%2C1209.5549%2C1209.2918%2C1101.1094%2C1206.1428%2C1204.1094%2C1112.2072%2C1101.1919%2C1102.1384%2C1212.3549%2C1110.0373%2C1103.3886%2C1201.3561%2C1103.5934%2C1208.2666%2C1106.2679%2C1105.1278%2C1202.2249%2C1206.0380%2C1210.0564%2C1209.3150%2C1202.4174%2C1210.3633%2C1110.4914%2C1203.0834%2C1211.5390%2C1102.5171%2C1111.1360%2C1208.2100%2C1204.3861%2C1111.1241%2C1110.0452%2C1111.0669%2C1210.2944%2C1210.2945%2C1210.2942%2C1210.2943%2C1205.6598%2C1201.3574%2C1212.0592%2C1202.5783%2C1110.3161%2C1110.6565%2C1111.2660%2C1207.7196%2C1102.0566%2C1111.6573%2C1103.5279%2C1202.5434%2C1211.5688%2C1203.3596%2C1206.1800%2C1201.5944%2C1107.1621%2C1105.2512%2C1209.5046%2C1209.0426%2C1210.8295%2C1201.5428%2C1206.3537%2C1110.3547%2C1210.3229%2C1102.1707%2C1103.3634%2C1203.0873%2C1106.5862%2C1210.3632%2C1202.6670%2C1111.6489%2C1111.6488%2C1208.6471%2C1107.5872%2C1201.2933%2C1210.3555%2C1209.4722%2C1211.0318%2C1211.5953%2C1208.3766%2C1209.6607%2C1209.6604%2C1204.2945%2C1202.6388%2C1204.4393%2C1205.0335%2C1210.6554%2C1112.5116%2C1104.4931%2C1105.4705%2C1203.0872%2C1109.4140%2C1208.0921%2C1112.2464%2C1208.0924%2C1209.0257%2C1102.5528%2C1112.3968%2C1211.6348%2C1211.4766%2C1208.4872%2C1203.0448%2C1110.6927%2C1204.5307%2C1210.6789%2C1210.1983%2C1111.3062%2C1111.3065%2C1102.3680%2C1205.3072%2C1111.2879%2C1106.6185%2C1107.4572%2C1204.3838%2C1210.4784%2C1109.2036%2C1201.5901%2C1105.0695%2C1108.2414%2C1112.5449%2C1205.6158%2C1104.1090%2C1209.5411%2C1202.5080%2C1207.5047%2C1109.2083%2C1212.0076%2C1204.5841%2C1103.1167%2C1212.5619%2C1201.4987%2C1103.2605%2C1207.4586%2C1203.1067%2C1205.6438%2C1202.1189%2C1212.3470%2C1210.6989%2C1207.7228%2C1206.0094%2C1106.3600%2C1207.4401%2C1108.4796%2C1101.0296%2C1111.6217%2C1209.4017%2C1209.5559%2C1209.5006%2C1202.2491%2C1202.0836%2C1207.3169%2C1101.0271%2C1212.4239%2C1102.0166%2C1101.3570%2C1201.4339%2C1110.3933%2C1103.5952%2C1208.2659%2C1111.4526%2C1206.4386%2C1204.1395%2C1111.6062%2C1207.4085%2C1210.2104%2C1109.6524%2C1209.3411%2C1210.8406%2C1101.5539%2C1107.5124%2C1203.3966%2C1208.0972%2C1111.3610%2C1105.2801%2C1108.4644%2C1208.2720%2C1112.0213%2C1203.0441%2C1112.3496%2C1101.5322%2C1207.5720%2C1212.0031%2C1111.3581%2C1102.4749%2C1209.3744%2C1111.6563%2C1107.3450%2C1209.5353%2C1208.6041%2C1208.0547%2C1101.6054%2C1201.4726%2C1110.4294%2C1201.4896%2C1112.0778%2C1104.3707%2C1205.3747%2C1212.3908%2C1108.4296%2C1108.4297%2C1201.0288%2C1210.1530%2C1111.6496%2C1111.6494%2C1111.6495%2C1210.6317%2C1111.6493%2C1208.6467%2C1103.1791%2C1203.6832%2C1211.2342%2C1101.2592%2C1108.2840%2C1209.5629%2C1103.2852%2C1209.3886%2C1211.6238%2C1109.3798%2C1204.4558%2C1204.4559%2C1210.2147%2C1210.2140%2C1211.6177%2C1212.1135%2C1205.0321%2C1210.8442%2C1104.1202%2C1211.1255%2C1111.3126%2C1207.7257%2C1212.4201%2C1106.5678%2C1212.5188%2C1102.5021%2C1212.6146%2C1204.5686%2C1112.2588%2C1105.1117%2C1201.2845%2C1108.0073%2C1201.0339%2C1206.3666%2C1103.0182%2C1105.5942%2C1111.0642%2C1106.4317%2C1210.5082%2C1207.6251%2C1107.3410%2C1204.3928%2C1103.2070%2C1212.3765%2C1205.7085%2C1112.3138%2C1112.0639%2C1111.3241%2C1107.3911%2C1204.0142%2C1210.7414%2C1111.6353%2C1103.2382%2C1101.5495%2C1206.4862%2C1108.6271%2C1207.5933%2C1209.5245%2C1201.4617%2C1206.4469%2C1206.0311%2C1203.1076%2C1204.2916%2C1204.6539%2C1109.2577%2C1111.0309%2C1211.2417%2C1203.3954%2C1210.1544%2C1104.2616%2C1103.0451%2C1108.2819%2C1107.4228%2C1212.5550%2C1201.6594%2C1104.4586%2C1212.0758%2C1112.4987%2C1109.3582%2C1210.6082%2C1104.2532%2C1106.0758%2C1210.8415%2C1207.5159%2C1209.3330%2C1208.4611%2C1106.2032%2C1206.3963%2C1110.0433%2C1102.3260%2C1208.1652%2C1109.3888%2C1112.3867%2C1211.0947%2C1105.5376%2C1212.0621%2C1212.3647%2C1206.3108%2C1101.3915%2C1210.7083%2C1202.4482%2C1207.6319%2C1210.4485%2C1106.2048%2C1209.3051%2C1109.2239%2C1205.0528%2C1202.5041%2C1210.6979%2C1210.0754%2C1206.6129%2C1209.2596%2C1204.1564%2C1205.3025%2C1209.2599%2C1101.5853%2C1112.5913%2C1209.5922%2C1106.0863%2C1211.0249%2C1207.0033%2C1206.2081%2C1204.3683%2C1209.5029%2C1208.6451%2C1204.0119%2C1211.3616%2C1204.6176%2C1208.1513%2C1207.3211%2C1111.7098%2C1104.2717%2C1209.0121%2C1105.2352%2C1208.5673%2C1105.0158%2C1209.5306%2C1212.1096%2C1206.4358%2C1105.1217%2C1101.2686%2C1201.2458%2C1109.3014%2C1104.1503%2C1211.6662%2C1107.2521%2C1202.3087%2C1205.4282%2C1112.5463%2C1101.3622%2C1103.2366%2C1112.5507%2C1206.5771%2C1209.4890%2C1212.3577%2C1206.5811%2C1104.5425%2C1209.3277%2C1101.4773%2C1209.3271%2C1104.1946%2C1209.3829%2C1112.1330%2C1102.5428%2C1101.2434%2C1203.3113%2C1201.0732%2C1207.0298%2C1211.6615%2C1208.5350%2C1104.2443%2C1101.1358%2C1110.0763%2C1212.3078%2C1204.0710%2C1206.1108%2C1111.0097%2C1201.0328%2C1203.4771%2C1204.1558%2C1203.3073%2C1201.0321%2C1104.5458%2C1210.3474%2C1101.1858%2C1102.3353%2C1111.2957%2C1211.4487%2C1103.0668%2C1206.1865%2C1206.1864%2C1211.0628%2C1104.0025%2C1111.0388%2C1204.3270%2C1106.1105%2C1107.3443%2C1106.2265%2C1203.0738%2C1201.5721%2C1208.3354%2C1110.6568%2C1207.2816%2C1210.5348%2C1210.4695%2C1206.4812%2C1102.0817%2C1101.6074%2C1105.0866%2C1205.2012%2C1207.2928%2C1112.2630%2C1202.3539%2C1211.6027%2C1203.5673%2C1206.0637%2C1206.0324%2C1209.0729%2C1207.3364%2C1201.6199%2C1206.3697%2C1201.6352%2C1210.6230%2C1102.1101%2C1106.2250%2C1204.6189%2C1206.6286%2C1209.4223%2C1104.1824%2C1201.3552%2C1104.1355%2C1211.0309%2C1104.5674%2C1104.3433%2C1202.2034%2C1204.5001%2C1106.3386%2C1106.2977%2C1105.1386%2C1211.5686%2C1207.3563%2C1206.4082%2C1107.3111%2C1207.2743%2C1104.4823%2C1203.0868%2C1105.3106%2C1209.6445%2C1202.2148%2C1102.0604%2C1212.3106%2C1208.0986%2C1204.0574%2C1204.0576%2C1212.0469%2C1105.4786%2C1107.1160%2C1110.3677%2C1210.7165%2C1104.3805%2C1210.2901%2C1204.3822%2C1212.0083%2C1112.4059%2C1202.4751%2C1108.2407%2C1204.0751%26start%3D0%26max_results%3D1000" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=1104.0305,1210.7495,1103.5112,1210.2959,1211.1990,1206.0166,1209.2562,1208.3228,1107.2834,1201.6255,1202.1696,1208.3383,1203.0886,1104.3795,1206.4841,1210.4145,1206.0560,1108.0251,1103.6007,1211.6894,1109.2893,1201.3022,1212.5054,1210.3741,1106.3616,1202.4578,1204.3198,1209.1859,1109.2556,1108.4167,1102.5225,1103.2373,1209.5549,1209.2918,1101.1094,1206.1428,1204.1094,1112.2072,1101.1919,1102.1384,1212.3549,1110.0373,1103.3886,1201.3561,1103.5934,1208.2666,1106.2679,1105.1278,1202.2249,1206.0380,1210.0564,1209.3150,1202.4174,1210.3633,1110.4914,1203.0834,1211.5390,1102.5171,1111.1360,1208.2100,1204.3861,1111.1241,1110.0452,1111.0669,1210.2944,1210.2945,1210.2942,1210.2943,1205.6598,1201.3574,1212.0592,1202.5783,1110.3161,1110.6565,1111.2660,1207.7196,1102.0566,1111.6573,1103.5279,1202.5434,1211.5688,1203.3596,1206.1800,1201.5944,1107.1621,1105.2512,1209.5046,1209.0426,1210.8295,1201.5428,1206.3537,1110.3547,1210.3229,1102.1707,1103.3634,1203.0873,1106.5862,1210.3632,1202.6670,1111.6489,1111.6488,1208.6471,1107.5872,1201.2933,1210.3555,1209.4722,1211.0318,1211.5953,1208.3766,1209.6607,1209.6604,1204.2945,1202.6388,1204.4393,1205.0335,1210.6554,1112.5116,1104.4931,1105.4705,1203.0872,1109.4140,1208.0921,1112.2464,1208.0924,1209.0257,1102.5528,1112.3968,1211.6348,1211.4766,1208.4872,1203.0448,1110.6927,1204.5307,1210.6789,1210.1983,1111.3062,1111.3065,1102.3680,1205.3072,1111.2879,1106.6185,1107.4572,1204.3838,1210.4784,1109.2036,1201.5901,1105.0695,1108.2414,1112.5449,1205.6158,1104.1090,1209.5411,1202.5080,1207.5047,1109.2083,1212.0076,1204.5841,1103.1167,1212.5619,1201.4987,1103.2605,1207.4586,1203.1067,1205.6438,1202.1189,1212.3470,1210.6989,1207.7228,1206.0094,1106.3600,1207.4401,1108.4796,1101.0296,1111.6217,1209.4017,1209.5559,1209.5006,1202.2491,1202.0836,1207.3169,1101.0271,1212.4239,1102.0166,1101.3570,1201.4339,1110.3933,1103.5952,1208.2659,1111.4526,1206.4386,1204.1395,1111.6062,1207.4085,1210.2104,1109.6524,1209.3411,1210.8406,1101.5539,1107.5124,1203.3966,1208.0972,1111.3610,1105.2801,1108.4644,1208.2720,1112.0213,1203.0441,1112.3496,1101.5322,1207.5720,1212.0031,1111.3581,1102.4749,1209.3744,1111.6563,1107.3450,1209.5353,1208.6041,1208.0547,1101.6054,1201.4726,1110.4294,1201.4896,1112.0778,1104.3707,1205.3747,1212.3908,1108.4296,1108.4297,1201.0288,1210.1530,1111.6496,1111.6494,1111.6495,1210.6317,1111.6493,1208.6467,1103.1791,1203.6832,1211.2342,1101.2592,1108.2840,1209.5629,1103.2852,1209.3886,1211.6238,1109.3798,1204.4558,1204.4559,1210.2147,1210.2140,1211.6177,1212.1135,1205.0321,1210.8442,1104.1202,1211.1255,1111.3126,1207.7257,1212.4201,1106.5678,1212.5188,1102.5021,1212.6146,1204.5686,1112.2588,1105.1117,1201.2845,1108.0073,1201.0339,1206.3666,1103.0182,1105.5942,1111.0642,1106.4317,1210.5082,1207.6251,1107.3410,1204.3928,1103.2070,1212.3765,1205.7085,1112.3138,1112.0639,1111.3241,1107.3911,1204.0142,1210.7414,1111.6353,1103.2382,1101.5495,1206.4862,1108.6271,1207.5933,1209.5245,1201.4617,1206.4469,1206.0311,1203.1076,1204.2916,1204.6539,1109.2577,1111.0309,1211.2417,1203.3954,1210.1544,1104.2616,1103.0451,1108.2819,1107.4228,1212.5550,1201.6594,1104.4586,1212.0758,1112.4987,1109.3582,1210.6082,1104.2532,1106.0758,1210.8415,1207.5159,1209.3330,1208.4611,1106.2032,1206.3963,1110.0433,1102.3260,1208.1652,1109.3888,1112.3867,1211.0947,1105.5376,1212.0621,1212.3647,1206.3108,1101.3915,1210.7083,1202.4482,1207.6319,1210.4485,1106.2048,1209.3051,1109.2239,1205.0528,1202.5041,1210.6979,1210.0754,1206.6129,1209.2596,1204.1564,1205.3025,1209.2599,1101.5853,1112.5913,1209.5922,1106.0863,1211.0249,1207.0033,1206.2081,1204.3683,1209.5029,1208.6451,1204.0119,1211.3616,1204.6176,1208.1513,1207.3211,1111.7098,1104.2717,1209.0121,1105.2352,1208.5673,1105.0158,1209.5306,1212.1096,1206.4358,1105.1217,1101.2686,1201.2458,1109.3014,1104.1503,1211.6662,1107.2521,1202.3087,1205.4282,1112.5463,1101.3622,1103.2366,1112.5507,1206.5771,1209.4890,1212.3577,1206.5811,1104.5425,1209.3277,1101.4773,1209.3271,1104.1946,1209.3829,1112.1330,1102.5428,1101.2434,1203.3113,1201.0732,1207.0298,1211.6615,1208.5350,1104.2443,1101.1358,1110.0763,1212.3078,1204.0710,1206.1108,1111.0097,1201.0328,1203.4771,1204.1558,1203.3073,1201.0321,1104.5458,1210.3474,1101.1858,1102.3353,1111.2957,1211.4487,1103.0668,1206.1865,1206.1864,1211.0628,1104.0025,1111.0388,1204.3270,1106.1105,1107.3443,1106.2265,1203.0738,1201.5721,1208.3354,1110.6568,1207.2816,1210.5348,1210.4695,1206.4812,1102.0817,1101.6074,1105.0866,1205.2012,1207.2928,1112.2630,1202.3539,1211.6027,1203.5673,1206.0637,1206.0324,1209.0729,1207.3364,1201.6199,1206.3697,1201.6352,1210.6230,1102.1101,1106.2250,1204.6189,1206.6286,1209.4223,1104.1824,1201.3552,1104.1355,1211.0309,1104.5674,1104.3433,1202.2034,1204.5001,1106.3386,1106.2977,1105.1386,1211.5686,1207.3563,1206.4082,1107.3111,1207.2743,1104.4823,1203.0868,1105.3106,1209.6445,1202.2148,1102.0604,1212.3106,1208.0986,1204.0574,1204.0576,1212.0469,1105.4786,1107.1160,1110.3677,1210.7165,1104.3805,1210.2901,1204.3822,1212.0083,1112.4059,1202.4751,1108.2407,1204.0751&amp;start=0&amp;max_results=1000</title>
  <id>http://arxiv.org/api/tw2CTvlBESfngWbNTVURHXle59s</id>
  <updated>2015-05-26T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">504</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1000</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1104.0305v3</id>
    <updated>2012-04-05T01:30:21Z</updated>
    <published>2011-04-02T09:10:42Z</published>
    <title>Dynamical Synapses Enhance Neural Information Processing: Gracefulness,
  Accuracy and Mobility</title>
    <summary>  Experimental data have revealed that neuronal connection efficacy exhibits
two forms of short-term plasticity, namely, short-term depression (STD) and
short-term facilitation (STF). They have time constants residing between fast
neural signaling and rapid learning, and may serve as substrates for neural
systems manipulating temporal information on relevant time scales. The present
study investigates the impact of STD and STF on the dynamics of continuous
attractor neural networks (CANNs) and their potential roles in neural
information processing. We find that STD endows the network with slow-decaying
plateau behaviors-the network that is initially being stimulated to an active
state decays to a silent state very slowly on the time scale of STD rather than
on the time scale of neural signaling. This provides a mechanism for neural
systems to hold sensory memory easily and shut off persistent activities
gracefully. With STF, we find that the network can hold a memory trace of
external inputs in the facilitated neuronal interactions, which provides a way
to stabilize the network response to noisy inputs, leading to improved accuracy
in population decoding. Furthermore, we find that STD increases the mobility of
the network states. The increased mobility enhances the tracking performance of
the network in response to time-varying stimuli, leading to anticipative neural
responses. In general, we find that STD and STP tend to have opposite effects
on network dynamics and complementary computational advantages, suggesting that
the brain may employ a strategy of weighting them differentially depending on
the computational purpose.
</summary>
    <author>
      <name>C. C. Alan Fung</name>
    </author>
    <author>
      <name>K. Y. Michael Wong</name>
    </author>
    <author>
      <name>He Wang</name>
    </author>
    <author>
      <name>Si Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00269</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00269" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 17 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Comput. 24 (2012) 1147-1185</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0305v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0305v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7495v2</id>
    <updated>2012-11-02T12:00:10Z</updated>
    <published>2012-10-28T19:37:33Z</published>
    <title>The neural computation of Sherlock Holmes' old maxim</title>
    <summary>  Natural languages can express some logical propositions that humans, with
similar cultural traditions, are able to immediately and correctly compute. We
illustrate this fact with a famous text that Arthur Conan Doyle attributed to
Sherlock Holmes: the 'old maxim' mentioned in 'The Adventure of the Beryl
Coronet', where Holmes said: 'It is an old maxim of mine that when you have
excluded the impossible, whatever remains, however improbable, must be the
truth'. This maxim is a subtle logical statement and the astonishing point is
that the reader feels that it is an evident true. The problem we are trying to
explain is the cognitive reason for such a feeling. We connect Holmes' maxim
with the modal logic of Aristotle, the symbolic methods developed by Boole, and
the matrix algebra created by Cayley. We show how these theories converge in a
class of neural network model, and we suggest that we accept as true Holmes'
maxim because our adult brains are equipped with neural modules that perform
naturally modal logical computations.
</summary>
    <author>
      <name>Eduardo Mizraji</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages; corrected typos; one added reference in Section 10 (E.
  Mizraji and J. Lin 2001); acknowledgments added; results and equations
  unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.7495v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7495v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20, 68T05, 68T37" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5112v1</id>
    <updated>2011-03-26T06:57:37Z</updated>
    <published>2011-03-26T06:57:37Z</published>
    <title>Weight-conserving characterization of complex functional brain networks</title>
    <summary>  Complex functional brain networks are large networks of brain regions and
functional brain connections. Statistical characterizations of these networks
aim to quantify global and local properties of brain activity with a small
number of network measures. Important functional network measures include
measures of modularity (measures of the goodness with which a network is
optimally partitioned into functional subgroups) and measures of centrality
(measures of the functional influence of individual brain regions).
Characterizations of functional networks are increasing in popularity, but are
associated with several important methodological problems. These problems
include the inability to characterize densely connected and weighted functional
networks, the neglect of degenerate topologically distinct high-modularity
partitions of these networks, and the absence of a network null model for
testing hypotheses of association between observed nontrivial network
properties and simple weighted connectivity properties. In this study we
describe a set of methods to overcome these problems. Specifically, we
generalize measures of modularity and centrality to fully connected and
weighted complex networks, describe the detection of degenerate high-modularity
partitions of these networks, and introduce a weighted-connectivity null model
of these networks. We illustrate our methods by demonstrating degenerate
high-modularity partitions and strong correlations between two complementary
measures of centrality in resting-state functional magnetic resonance imaging
(MRI) networks from the 1000 Functional Connectomes Project, an open-access
repository of resting-state functional MRI datasets. Our methods may allow more
sound and reliable characterizations and comparisons of functional brain
networks across conditions and subjects.
</summary>
    <author>
      <name>Mikail Rubinov</name>
    </author>
    <author>
      <name>Olaf Sporns</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neuroimage.2011.03.069</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neuroimage.2011.03.069" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeuroImage, in press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuroimage. 2011 Jun 15;56(4):2068-79. Epub 2011 Apr 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.5112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2959v1</id>
    <updated>2012-10-10T15:42:23Z</updated>
    <published>2012-10-10T15:42:23Z</published>
    <title>Psychophysical Responses Comparison in Spatial Visual, Audiovisual, and
  Auditory BCI-Spelling Paradigms</title>
    <summary>  The paper presents a pilot study conducted with spatial visual, audiovisual
and auditory brain-computer-interface (BCI) based speller paradigms. The
psychophysical experiments are conducted with healthy subjects in order to
evaluate a difficulty and a possible response accuracy variability. We also
present preliminary EEG results in offline BCI mode. The obtained results
validate a thesis, that spatial auditory only paradigm performs as good as the
traditional visual and audiovisual speller BCI tasks.
</summary>
    <author>
      <name>Moonjeong Chang</name>
    </author>
    <author>
      <name>Nozomu Nishikawa</name>
    </author>
    <author>
      <name>Zhenyu Cai</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 6th International Conference on Soft Computing and Intelligent
  Systems and The 13th International Symposium on Advanced Intelligent Systems,
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1990v1</id>
    <updated>2012-11-08T21:19:23Z</updated>
    <published>2012-11-08T21:19:23Z</published>
    <title>Potential mechanisms for imperfect synchronization in parkinsonian basal
  ganglia</title>
    <summary>  Neural activity in the brain of parkinsonian patients is characterized by the
intermittently synchronized oscillatory dynamics. This imperfect
synchronization, observed in the beta frequency band, is believed to be related
to the hypokinetic motor symptoms of the disorder. Our study explores potential
mechanisms behind this intermittent synchrony. We study the response of a
bursting pallidal neuron to different patterns of synaptic input from
subthalamic nucleus (STN) neuron. We show how external globus pallidus (GPe)
neuron is sensitive to the phase of the input from the STN cell and can exhibit
intermittent phase-locking with the input in the beta band. The temporal
properties of this intermittent phase-locking show similarities to the
intermittent synchronization observed in experiments. We also study the
synchronization of GPe cells to synaptic input from the STN cell with
dependence on the dopamine-modulated parameters. Dopamine also affects the
cellular properties of neurons. We show how the changes in firing patterns of
STN neuron due to the lack of dopamine may lead to transition from a lower to a
higher coherent state, roughly matching the synchrony levels observed in basal
ganglia in normal and parkinsonian states. The intermittent nature of the
neural beta band synchrony in Parkinson's disease is achieved in the model due
to the interplay of the timing of STN input to pallidum and pallidal neuronal
dynamics, resulting in sensitivity of pallidal output to the phase of the
arriving STN input. Thus the mechanism considered here (the change in firing
pattern of subthalamic neurons through the dopamine-induced change of membrane
properties) may be one of the potential mechanisms responsible for the
generation of the intermittent synchronization observed in Parkinson's disease.
</summary>
    <author>
      <name>Choongseok Park</name>
    </author>
    <author>
      <name>Leonid Rubchinsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0051530</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0051530" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS One. 2012; 7(12): e51530</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.1990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0166v3</id>
    <updated>2014-10-07T10:20:19Z</updated>
    <published>2012-06-01T12:40:02Z</published>
    <title>Avalanches in self-organized critical neural networks: A minimal model
  for the neural SOC universality class</title>
    <summary>  The brain keeps its overall dynamics in a corridor of intermediate activity
and it has been a long standing question what possible mechanism could achieve
this task. Mechanisms from the field of statistical physics have long been
suggesting that this homeostasis of brain activity could occur even without a
central regulator, via self-organization on the level of neurons and their
interactions, alone. Such physical mechanisms from the class of self-organized
criticality exhibit characteristic dynamical signatures, similar to seismic
activity related to earthquakes. Measurements of cortex rest activity showed
first signs of dynamical signatures potentially pointing to self-organized
critical dynamics in the brain. Indeed, recent more accurate measurements
allowed for a detailed comparison with scaling theory of non-equilibrium
critical phenomena, proving the existence of criticality in cortex dynamics. We
here compare this new evaluation of cortex activity data to the predictions of
the earliest physics spin model of self-organized critical neural networks. We
find that the model matches with the recent experimental data and its
interpretation in terms of dynamical signatures for criticality in the brain.
The combination of signatures for criticality, power law distributions of
avalanche sizes and durations, as well as a specific scaling relationship
between anomalous exponents, defines a universality class characteristic of the
particular critical phenomenon observed in the neural experiments. The spin
model is a candidate for a minimal model of a self-organized critical adaptive
network for the universality class of neural criticality. As a prototype model,
it provides the background for models that include more biological details, yet
share the same universality class characteristic of the homeostasis of activity
in the brain.
</summary>
    <author>
      <name>Matthias Rybarsch</name>
    </author>
    <author>
      <name>Stefan Bornholdt</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0093090</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0093090" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 9(4): e93090 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.0166v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0166v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2562v1</id>
    <updated>2012-09-12T11:07:27Z</updated>
    <published>2012-09-12T11:07:27Z</published>
    <title>Synchronization with mismatched synaptic delays: A unique role of
  elastic neuronal latency</title>
    <summary>  We show that the unavoidable increase in neuronal response latency to ongoing
stimulation serves as a nonuniform gradual stretching of neuronal circuit delay
loops and emerges as an essential mechanism in the formation of various types
of neuronal timers. Synchronization emerges as a transient phenomenon without
predefined precise matched synaptic delays. These findings are described in an
experimental procedure where conditioned stimulations were enforced on a
circuit of neurons embedded within a large-scale network of cortical cells
in-vitro, and are corroborated by neuronal simulations. They evidence a new
cortical timescale based on tens of microseconds stretching of neuronal circuit
delay loops per spike, and with realistic delays of a few milliseconds,
synchronization emerges for a finite fraction of neuronal circuit delays.
</summary>
    <author>
      <name>Roni Vardi</name>
    </author>
    <author>
      <name>Reut Timor</name>
    </author>
    <author>
      <name>Shimon Marom</name>
    </author>
    <author>
      <name>Moshe Abeles</name>
    </author>
    <author>
      <name>Ido Kanter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/100/48003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/100/48003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures, 13 pages of Supplementary material</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPL, 100, 48003 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.2562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3228v1</id>
    <updated>2012-08-15T21:11:21Z</updated>
    <published>2012-08-15T21:11:21Z</published>
    <title>Model of the Human Sleep Wake System</title>
    <summary>  A model and analysis of the human sleep/wake system is presented. The model
is derived using the known neuronal groups, and their various projections,
involved with sleep and wake. Inherent in the derivation is the existence of a
slow time scale associated with homeostatic regulation, and a faster time scale
associated with the dynamics within the sleep phase. A significant feature of
the model is that it does not contain a periodic forcing term, common in other
models, reflecting the fact that sleep/wake is not dependent upon a diurnal
stimulus. Once derived, the model is analyzed using a linearized stability
analysis. We then use experimental data from normal sleep-wake systems and
orexin knockout systems to verify the physiological validity of the equations.
</summary>
    <author>
      <name>Lisa Rogers</name>
    </author>
    <author>
      <name>Mark Holmes</name>
    </author>
    <link href="http://arxiv.org/abs/1208.3228v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3228v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2834v1</id>
    <updated>2011-07-14T14:14:29Z</updated>
    <published>2011-07-14T14:14:29Z</published>
    <title>A showcase of torus canards in neuronal bursters</title>
    <summary>  Rapid action potential generation --- spiking --- and alternating intervals
of spiking and quiescence --- bursting --- are two dynamic patterns observed in
neuronal activity. In computational models of neuronal systems, the transition
from spiking to bursting often exhibits complex bifurcation structure. One type
of transition involves the torus canard, which was originally observed in a
simple biophysical model of a Purkinje cell. In this article, we expand on that
original result by showing that torus canards arise in a broad array of
well-known computational neuronal models with three different classes of
bursting dynamics: sub-Hopf/fold cycle bursting, circle/fold cycle bursting,
and fold/fold cycle bursting. The essential features that these models share
are multiple time scales leading naturally to decomposition into slow and fast
systems, a saddle-node of periodic orbits in the fast system, and a torus
bifurcation in the full system. We show that the transition from spiking to
bursting in each model system is given by an explosion of torus canards. Based
on these examples, as well as on emerging theory, we propose that torus canards
are a common dynamic phenomenon separating the regimes of spiking and bursting
activity.
</summary>
    <author>
      <name>John Burke</name>
    </author>
    <author>
      <name>Mathieu Desroches</name>
    </author>
    <author>
      <name>Anna M. Barry</name>
    </author>
    <author>
      <name>Tasso J. Kaper</name>
    </author>
    <author>
      <name>Mark A. Kramer</name>
    </author>
    <link href="http://arxiv.org/abs/1107.2834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.6255v6</id>
    <updated>2014-11-28T17:43:38Z</updated>
    <published>2012-01-30T15:29:53Z</published>
    <title>Is a 4-bit synaptic weight resolution enough? - Constraints on enabling
  spike-timing dependent plasticity in neuromorphic hardware</title>
    <summary>  Large-scale neuromorphic hardware systems typically bear the trade-off
between detail level and required chip resources. Especially when implementing
spike-timing-dependent plasticity, reduction in resources leads to limitations
as compared to floating point precision. By design, a natural modification that
saves resources would be reducing synaptic weight resolution. In this study, we
give an estimate for the impact of synaptic weight discretization on different
levels, ranging from random walks of individual weights to computer simulations
of spiking neural networks. The FACETS wafer-scale hardware system offers a
4-bit resolution of synaptic weights, which is shown to be sufficient within
the scope of our network benchmark. Our findings indicate that increasing the
resolution may not even be useful in light of further restrictions of
customized mixed-signal synapses. In addition, variations due to production
imperfections are investigated and shown to be uncritical in the context of the
presented study. Our results represent a general framework for setting up and
configuring hardware-constrained synapses. We suggest how weight discretization
could be considered for other backends dedicated to large-scale simulations.
Thus, our proposition of a good hardware verification practice may rise synergy
effects between hardware developers and neuroscientists.
</summary>
    <author>
      <name>Thomas Pfeil</name>
    </author>
    <author>
      <name>Tobias C. Potjans</name>
    </author>
    <author>
      <name>Sven Schrader</name>
    </author>
    <author>
      <name>Wiebke Potjans</name>
    </author>
    <author>
      <name>Johannes Schemmel</name>
    </author>
    <author>
      <name>Markus Diesmann</name>
    </author>
    <author>
      <name>Karlheinz Meier</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fnins.2012.00090</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fnins.2012.00090" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Neurosci. 6:90 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.6255v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.6255v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1696v1</id>
    <updated>2012-02-08T13:52:05Z</updated>
    <published>2012-02-08T13:52:05Z</published>
    <title>Bayesian Inference of Whole-Brain Networks</title>
    <summary>  In structural brain networks the connections of interest consist of
white-matter fibre bundles between spatially segregated brain regions. The
presence, location and orientation of these white matter tracts can be derived
using diffusion MRI in combination with probabilistic tractography.
Unfortunately, as of yet no approaches have been suggested that provide an
undisputed way of inferring brain networks from tractography. In this paper, we
provide a computational framework which we refer to as Bayesian connectomics.
Rather than applying an arbitrary threshold to obtain a single network, we
consider the posterior distribution of networks that are supported by the data,
combined with an exponential random graph (ERGM) prior that captures a priori
knowledge concerning the graph-theoretical properties of whole-brain networks.
We show that, on simulated probabilistic tractography data, our approach is
able to reconstruct whole-brain networks. In addition, our approach directly
supports multi-model data fusion and group-level network inference.
</summary>
    <author>
      <name>M. Hinne</name>
    </author>
    <author>
      <name>T. Heskes</name>
    </author>
    <author>
      <name>M. A. J. van Gerven</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.1696v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1696v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3383v1</id>
    <updated>2012-08-16T14:37:31Z</updated>
    <published>2012-08-16T14:37:31Z</published>
    <title>Structual Vulnerability of the Nematode Worm Neural Graph</title>
    <summary>  The number of connected components and the size of the largest connected
component are studied under node and edge removal in the connectivity graph of
the C. elegans nervous system. By studying the two subgraphs - the directed
graph of chemical synapses and the undirected graph of electrical junctions -
we observe that adding a small number of undirected edges dramatically reduces
the number of components in the complete graph. Under random node and edge
removal, the C. elegans graph displays a remarkable structural robustness. We
then compare these results with the vulnerability of a number of canonical
graph models.
</summary>
    <author>
      <name>Michelle Rudolph-Lilith</name>
    </author>
    <author>
      <name>Alain Destexhe</name>
    </author>
    <author>
      <name>Lyle E. Muller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.3383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0886v2</id>
    <updated>2012-05-02T16:59:30Z</updated>
    <published>2012-03-05T12:32:50Z</published>
    <title>Energy and information in Hodgkin-Huxley neurons</title>
    <summary>  The generation of spikes by neurons is energetically a costly process and the
evaluation of the metabolic energy required to maintain the signalling activity
of neurons a challenge of practical interest. Neuron models are frequently used
to represent the dynamics of real neurons but hardly ever to evaluate the
electrochemical energy required to maintain that dynamics. This paper discusses
the interpretation of a Hodgkin-Huxley circuit as an energy model for real
biological neurons and uses it to evaluate the consumption of metabolic energy
in the transmission of information between neurons coupled by electrical
synapses, i.e. gap junctions. We show that for a single postsynaptic neuron
maximum energy efficiency, measured in bits of mutual information per ATP
molecule consumed, requires maximum energy consumption. On the contrary, for
groups of parallel postsynaptic neurons we determine values of the synaptic
conductance at which the energy efficiency of the transmission presents clear
maxima at relatively very low values of metabolic energy consumption. Contrary
to what it could be expected best performance occurs at low energy cost.
</summary>
    <author>
      <name>A. Moujahid</name>
    </author>
    <author>
      <name>A. d'Anjou</name>
    </author>
    <author>
      <name>F. J. Torrealdea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to technical issues</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review E 83, 031912(2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0886v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0886v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3795v2</id>
    <updated>2011-06-23T05:35:26Z</updated>
    <published>2011-04-19T16:30:02Z</published>
    <title>Statistics of spike trains in conductance-based neural networks:
  Rigorous results</title>
    <summary>  We consider a conductance based neural network inspired by the generalized
Integrate and Fire model introduced by Rudolph and Destexhe. We show the
existence and uniqueness of a unique Gibbs distribution characterizing spike
train statistics. The corresponding Gibbs potential is explicitly computed.
These results hold in presence of a time-dependent stimulus and apply therefore
to non-stationary dynamics.
</summary>
    <author>
      <name>B. Cessac</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 1 figure, to appear in Journal of Mathematical Neuroscience</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.3795v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3795v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4841v2</id>
    <updated>2013-02-19T14:25:30Z</updated>
    <published>2012-06-21T11:38:53Z</published>
    <title>In-phase and anti-phase synchronization in noisy Hodgkin-Huxley neurons</title>
    <summary>  We numerically investigate the influence of intrinsic channel noise on the
dynamical response of delay-coupling in neuronal systems. The stochastic
dynamics of the spiking is modeled within a stochastic modification of the
standard Hodgkin-Huxley model wherein the delay-coupling accounts for the
finite propagation time of an action potential along the neuronal axon. We
quantify this delay-coupling of the Pyragas-type in terms of the difference
between corresponding presynaptic and postsynaptic membrane potentials. For an
elementary neuronal network consisting of two coupled neurons we detect
characteristic stochastic synchronization patterns which exhibit multiple
phase-flip bifurcations: The phase-flip bifurcations occur in form of alternate
transitions from an in-phase spiking activity towards an anti-phase spiking
activity. Interestingly, these phase-flips remain robust in strong channel
noise and in turn cause a striking stabilization of the spiking frequency.
</summary>
    <author>
      <name>Xue Ao</name>
    </author>
    <author>
      <name>Peter Hanggi</name>
    </author>
    <author>
      <name>Gerhard Schmid</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.mbs.2013.02.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.mbs.2013.02.007" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathemathical Biosciences 245, 49 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4841v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4841v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4145v1</id>
    <updated>2012-10-15T19:33:27Z</updated>
    <published>2012-10-15T19:33:27Z</published>
    <title>A Biologically Realistic Model of Saccadic Eye Control with
  Probabilistic Population Codes</title>
    <summary>  The posterior parietal cortex is believed to direct eye movements, especially
in regards to target tracking tasks, and a number of debates exist over the
precise nature of the computations performed by the parietal cortex, with each
side supported by different sets of biological evidence. In this paper I will
present my model which navigates a course between some of these debates,
towards the end of presenting a model which can explain some of the competing
interpretations among the data sets. In particular, rather than assuming that
proprioception or efference copies form the key source of information for
computing eye position information, I use a biological plausible implementation
of a Kalman filter to optimally combine the two signals, and a simple gain
control mechanism in order to accommodate the latency of the proprioceptive
signal. Fitting within the Bayesian brain hypothesis, the result is a Bayes
optimal solution to the eye control problem, with a range of data supporting
claims of biological plausibility.
</summary>
    <author>
      <name>Sacha Sokoloski</name>
    </author>
    <link href="http://arxiv.org/abs/1210.4145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0560v1</id>
    <updated>2012-06-04T09:35:41Z</updated>
    <published>2012-06-04T09:35:41Z</published>
    <title>The information content of Local Field Potentials: experiments and
  models</title>
    <summary>  The LFPs is a broadband signal that captures variations of neural population
activity over a wide range of time scales. The range of time scales available
in LFPs is particularly interesting from the neural coding point of view
because it opens up the possibility to investigate whether there are privileged
time scales for information processing, a question that has been hotly debated
over the last one or two decades.It is possible that information is represented
by only a small number of specific frequency ranges, each carrying a separate
contribution to the information representation. To shed light on this issue, it
is important to quantify the information content of each frequency range of
neural activity, and understand which ranges carry complementary or similar
information.
</summary>
    <author>
      <name>Alberto Mazzoni</name>
    </author>
    <author>
      <name>Nikos K. Logothetis</name>
    </author>
    <author>
      <name>Stefano Panzeri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Quian Quiroga and Panzeri (Eds) Principles of Neural
  Coding, CRC Press, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0251v1</id>
    <updated>2011-08-01T07:07:01Z</updated>
    <published>2011-08-01T07:07:01Z</published>
    <title>Cortical current source connectivity by means of partial coherence
  fields</title>
    <summary>  An important field of research in functional neuroimaging is the discovery of
integrated, distributed brain systems and networks, whose different regions
need to work in unison for normal functioning.
  The EEG is a non-invasive technique that can provide information for massive
connectivity analyses. Cortical signals of time varying electric neuronal
activity can be estimated from the EEG. Although such techniques have very high
time resolution, two cortical signals even at distant locations will appear to
be highly similar due to the low spatial resolution nature of the EEG.
  In this study a method for eliminating the effect of common sources due to
low spatial resolution is presented. It is based on an efficient estimation of
the whole-cortex partial coherence matrix. Using as a starting point any linear
EEG tomography that satisfies the EEG forward equation, it is shown that the
generalized partial coherences for the cortical grey matter current density
time series are invariant to the selected tomography. It is empirically shown
with simulation experiments that the generalized partial coherences have higher
spatial resolution than the classical coherences. The results demonstrate that
with as little as 19 electrodes, lag-connected brain regions can often be
missed and misplaced even with lagged coherence measures, while the new method
detects and localizes correctly the connected regions using the lagged partial
coherences.
</summary>
    <author>
      <name>Roberto D. Pascual-Marqui</name>
    </author>
    <author>
      <name>Rolando J. Biscay</name>
    </author>
    <author>
      <name>Pedro A. Valdes-Sosa</name>
    </author>
    <author>
      <name>Jorge Bosch-Bayard</name>
    </author>
    <author>
      <name>Jorge J. Riera-Diaz</name>
    </author>
    <link href="http://arxiv.org/abs/1108.0251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.6007v2</id>
    <updated>2011-04-21T12:35:32Z</updated>
    <published>2011-03-30T18:06:30Z</published>
    <title>Computing with space: a tangle formalism for chora and difference</title>
    <summary>  What is space computing, simulation, or understanding? Converging from
several sources, this seems to be something more primitive than what is usually
meant by computation, something that was along with us since antiquity (the
word "choros", "chora", denotes "space" or "place" and is seemingly the most
mysterious notion from Plato, described in Timaeus 48e - 53c) which has to do
with cybernetics and with the understanding of the front end visual system. It
may have some unexpected applications, also. Here, inspired by Bateson (see
Supplementary Material), I explore from the mathematical side the point of view
that there is no difference between the map and the territory, but instead the
transformation of one into another can be understood by using a formalism of
tangle diagrams.
  This paper continues arXiv:1009.5028 "What is a space? Computations in
emergent algebras and the front end visual system" and the arXiv:1007.2362
"Introduction to metric spaces with dilations".
</summary>
    <author>
      <name>Marius Buliga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">56 pages, added content and reorganized the paper, title changed,
  many figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.6007v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.6007v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6894v1</id>
    <updated>2012-11-29T12:10:53Z</updated>
    <published>2012-11-29T12:10:53Z</published>
    <title>Impact of noise and damage on collective dynamics of scale-free neuronal
  networks</title>
    <summary>  We study the role of scale-free structure and noise in collective dynamics of
neuronal networks. For this purpose, we simulate and study analytically a
cortical circuit model with stochastic neurons. We compare collective neuronal
activity of networks with different topologies: classical random graphs and
scale-free networks. We show that, in scale-free networks with divergent second
moment of degree distribution, an influence of noise on neuronal activity is
strongly enhanced in comparison with networks with a finite second moment. A
very small noise level can stimulate spontaneous activity of a finite fraction
of neurons and sustained network oscillations. We demonstrate tolerance of
collective dynamics of the scale-free networks to random damage in a broad
range of the number of randomly removed excitatory and inhibitory neurons. A
random removal of neurons leads to gradual decrease of frequency of network
oscillations similar to the slowing-down of the alpha rhythm in Alzheimer's
disease. However, the networks are vulnerable to targeted attacks. A removal of
a few excitatory or inhibitory hubs can impair sustained network oscillations.
</summary>
    <author>
      <name>D. Holstein</name>
    </author>
    <author>
      <name>A. V. Goltsev</name>
    </author>
    <author>
      <name>J. F. F. Mendes</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.87.032717</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.87.032717" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 87, 032717 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2893v2</id>
    <updated>2012-10-25T19:56:57Z</updated>
    <published>2011-09-13T19:45:19Z</published>
    <title>Multimodal transition and excitability of a neural oscillator</title>
    <summary>  We analyze the response of the Morris-Lecar model to a periodic train of
short current pulses in the period-amplitude plane. For a wide parameter range
encompassing both class 2 and class 3 behavior in Hodgkin's classification
there is a multimodal transition between the set of odd modes and the set of
all modes. It is located between the 2:1 and 3:1 locked-in regions. It is the
same dynamic instability as the one discovered earlier in the Hodgkin-Huxley
model and observed experimentally in squid giant axons. It appears
simultaneously with the bistability of the states 2:1 and 3:1 in the
perithreshold regime. These results imply that the multimodal transition may be
a universal property of resonant neurons.
</summary>
    <author>
      <name>L. S. Borkowski</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Phys. Pol. A 122, 776 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.2893v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2893v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3022v1</id>
    <updated>2012-01-14T14:49:09Z</updated>
    <published>2012-01-14T14:49:09Z</published>
    <title>Computational Models For Epilepsy</title>
    <summary>  Epilepsy is a neurological disease characterized by recurrent and spontaneous
seizures. It affects approximately 50 million people worldwide. In majority of
the cases accurate diagnosis of the disease can be made without using any
technologically advanced techniques and seizures are controlled using standard
treatment in the form of regular use of anti-epileptic drugs. However,
approximately 30% of the patients suffer from medically refractory epilepsy,
wherein seizures are not controlled by the use of anti-epileptic drugs.
Understanding the mechanisms underlying these forms of drug resistant epileptic
seizures and the development of alternative effective treatment strategies is a
fundamental challenge in modern epilepsy research. In this context, the need
for integrative approaches combining various modalities of treatment strategies
is high. Computational modeling has gained prominence in recent years as an
important tool for tackling the complexity of the epileptic phenomenon. In this
review article we present a survey of different computational models for
epilepsy and discuss how computer models can aid in our understanding of brain
mechanisms in epilepsy and the development of new epilepsy treatment protocols.
</summary>
    <author>
      <name>Roxana A. Stephanescu</name>
    </author>
    <author>
      <name>R. G. Shivakeshavan</name>
    </author>
    <author>
      <name>Sachin S. Talathi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.seizure.2012.08.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.seizure.2012.08.012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Seizure: European Journal of Epilepsy, 2012 Dec;21(10):748-59</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.3022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5054v2</id>
    <updated>2013-01-15T14:50:55Z</updated>
    <published>2012-12-20T14:30:48Z</published>
    <title>Generating functionals for autonomous latching dynamics in attractor
  relict networks</title>
    <summary>  Well characterized sequences of dynamical states play an important role for
motor control and associative neural computation in the brain. Autonomous
dynamics involving sequences of transiently stable states have been termed
associative latching in the context of grammar generation. We propose that
generating functionals allow for a systematic construction of dynamical
networks with well characterized dynamical behavior, such as regular or
intermittent bursting latching dynamics.
  Coupling local, slowly adapting variables to an attractor network allows to
destabilize all attractors, turning them into attractor ruins. The resulting
attractor relict network may show ongoing autonomous latching dynamics. We
propose to use two generating functionals for the construction of attractor
relict networks. The first functional is a simple Hopfield energy functional,
known to generate a neural attractor network. The second generating functional,
which we denote polyhomeostatic optimization, is based on
information-theoretical principles, encoding the information content of the
neural firing statistics. Polyhomeostatic optimization destabilizes the
attractors of the Hopfield network inducing latching dynamics.
  We investigate the influence of stress, in terms of conflicting optimization
targets, on the resulting dynamics. Objective function stress is absent when
the target level for the mean of neural activities is identical for the two
generating functionals and the resulting latching dynamics is then found to be
regular. Objective function stress is present when the respective target
activity levels differ, inducing intermittent bursting latching dynamics. We
propose that generating functionals may be useful quite generally for the
controlled construction of complex dynamical systems.
</summary>
    <author>
      <name>Mathias Linkerhand</name>
    </author>
    <author>
      <name>Claudius Gros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">replaced two figures which were not showing up properly</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Reports, Vol 3, 2042 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5054v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5054v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3741v1</id>
    <updated>2012-10-13T21:49:32Z</updated>
    <published>2012-10-13T21:49:32Z</published>
    <title>Online computation of sparse representations of time varying stimuli
  using a biologically motivated neural network</title>
    <summary>  Natural stimuli are highly redundant, possessing significant spatial and
temporal correlations. While sparse coding has been proposed as an efficient
strategy employed by neural systems to encode sensory stimuli, the underlying
mechanisms are still not well understood. Most previous approaches model the
neural dynamics by the sparse representation dictionary itself and compute the
representation coefficients offline. In reality, faced with the challenge of
constantly changing stimuli, neurons must compute the sparse representations
dynamically in an online fashion. Here, we describe a leaky linearized Bregman
iteration (LLBI) algorithm which computes the time varying sparse
representations using a biologically motivated network of leaky rectifying
neurons. Compared to previous attempt of dynamic sparse coding, LLBI exploits
the temporal correlation of stimuli and demonstrate better performance both in
representation error and the smoothness of temporal evolution of sparse
coefficients.
</summary>
    <author>
      <name>Tao Hu</name>
    </author>
    <author>
      <name>Dmitri B. Chklovskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3616v4</id>
    <updated>2015-02-13T18:20:53Z</updated>
    <published>2011-06-18T05:06:20Z</published>
    <title>When can dictionary learning uniquely recover sparse data from
  subsamples?</title>
    <summary>  Sparse coding or sparse dictionary learning has been widely used to recover
underlying structure in many kinds of natural data. Here, we provide conditions
guaranteeing when this recovery is universal; that is, when sparse codes and
dictionaries are unique (up to natural symmetries). Our main tool is a useful
lemma in combinatorial matrix theory that allows us to derive bounds on the
sample sizes guaranteeing such uniqueness under various assumptions for how
training data are generated. Whenever the conditions to one of our theorems are
met, any sparsity-constrained learning algorithm that succeeds in
reconstructing the data recovers the original sparse codes and dictionary. We
also discuss potential applications to neuroscience and data analysis.
</summary>
    <author>
      <name>Christopher J. Hillar</name>
    </author>
    <author>
      <name>Friedrich T. Sommer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.3616v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3616v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4578v1</id>
    <updated>2012-02-21T09:52:48Z</updated>
    <published>2012-02-21T09:52:48Z</published>
    <title>Modeling rhythmic patterns in the hippocampus</title>
    <summary>  We investigate different dynamical regimes of neuronal network in the CA3
area of the hippocampus. The proposed neuronal circuit includes two fast- and
two slowly-spiking cells which are interconnected by means of dynamical
synapses. On the individual level, each neuron is modeled by FitzHugh-Nagumo
equations. Three basic rhythmic patterns are observed: gamma-rhythm in which
the fast neurons are uniformly spiking, theta-rhythm in which the individual
spikes are separated by quiet epochs, and theta/gamma rhythm with repeated
patches of spikes. We analyze the influence of asymmetry of synaptic strengths
on the synchronization in the network and demonstrate that strong asymmetry
reduces the variety of available dynamical states. The model network exhibits
multistability; this results in occurrence of hysteresis in dependence on the
conductances of individual connections. We show that switching between
different rhythmic patterns in the network depends on the degree of
synchronization between the slow cells.
</summary>
    <author>
      <name>Anastasia I. Lavrova</name>
    </author>
    <author>
      <name>Michael A. Zaks</name>
    </author>
    <author>
      <name>Lutz Schimansky-Geier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3198v2</id>
    <updated>2012-09-28T17:26:00Z</updated>
    <published>2012-04-14T19:25:54Z</published>
    <title>The failure of the law of brevity in two New World primates. Statistical
  caveats</title>
    <summary>  Parallels of Zipf's law of brevity, the tendency of more frequent words to be
shorter, have been found in bottlenose dolphins and Formosan macaques. Although
these findings suggest that behavioral repertoires are shaped by a general
principle of compression, common marmosets and golden-backed uakaris do not
exhibit the law. However, we argue that the law may be impossible or difficult
to detect statistically in a given species if the repertoire is too small, a
problem that could be affecting golden backed uakaris, and show that the law is
present in a subset of the repertoire of common marmosets. We suggest that the
visibility of the law will depend on the subset of the repertoire under
consideration or the repertoire size.
</summary>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <author>
      <name>Antoni Hernández-Fernández</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1524/glot.2013.0004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1524/glot.2013.0004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Little improvements in the statistical arguments</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Statistical caveats. Glottotheory 4 (1), 45-55 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3198v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3198v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1859v1</id>
    <updated>2012-09-10T00:01:23Z</updated>
    <published>2012-09-10T00:01:23Z</published>
    <title>Operation of a Brain-Computer Interface Walking Simulator by Users with
  Spinal Cord Injury</title>
    <summary>  Background: Spinal cord injury (SCI) can leave the affected individuals
unable to ambulate. Since there are no restorative treatments for SCI, novel
approaches such as brain-controlled prostheses have been sought. Our recent
studies show that a brain-computer interface (BCI) can be used to control
ambulation within a virtual reality environment (VRE), suggesting that a
BCI-controlled lower extremity prosthesis for ambulation may be feasible.
However, the operability of our BCI has not been tested in a SCI population.
  Methods: Five subjects with paraplegia or tetraplegia due to SCI underwent a
10-min training session in which they alternated between kinesthetic motor
imagery (KMI) of idling and walking while their electroencephalogram (EEG) were
recorded. Subjects then performed a goal-oriented online task, where they
utilized KMI to control the linear ambulation of an avatar and make 10
sequential stops at designated points within the VRE. Multiple online trials
were performed over 5 experimental days.
  Results: Classification accuracy of idling and walking was estimated offline
and ranged from 60.5% (p=0.0176) to 92.3% (p=1.36*10^-20) across subjects and
days. In the online task, all subjects achieved purposeful control with an
average performance of 7.4 +/- 2.3 successful stops in 273 +/- 51 sec (p&lt;0.01).
All subjects maintained purposeful control throughout the study, and their
online performances improved over time.
  Conclusions: The results demonstrate that SCI subjects can purposefully
operate a self-paced BCI walking simulator to complete a goal-oriented
ambulation task. The operation of this BCI system requires short training, is
intuitive, and robust against subject-to-subject and day-to-day
neurophysiological variations. These findings indicate that BCI-controlled
lower extremity prostheses for gait rehabilitation or restoration after SCI may
be feasible in the future.
</summary>
    <author>
      <name>Christine E. King</name>
    </author>
    <author>
      <name>Po T. Wang</name>
    </author>
    <author>
      <name>Luis A. Chui</name>
    </author>
    <author>
      <name>An H. Do</name>
    </author>
    <author>
      <name>Zoran Nenadic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures, 5 tables, supplementary video link
  (http://www.youtube.com/watch?v=K4Frq9pwAz8)</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.1859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2556v1</id>
    <updated>2011-09-12T18:18:34Z</updated>
    <published>2011-09-12T18:18:34Z</published>
    <title>Intermittent synchronization in a network of bursting neurons</title>
    <summary>  Synchronized oscillations in networks of inhibitory and excitatory coupled
bursting neurons are common in a variety of neural systems from central pattern
generators to human brain circuits. One example of the latter is the
subcortical network of the basal ganglia, formed by excitatory and inhibitory
bursters of the subthalamic nucleus and globus pallidus, involved in motor
control and affected in Parkinson's disease. Recent experiments have
demonstrated the intermittent nature of the phase-locking of neural activity in
this network. Here we explore one potential mechanism to explain the
intermittent phase-locking in a network. We simplify the network to obtain a
model of two inhibitory coupled elements and explore its dynamics. We used
geometric analysis and singular perturbation methods for dynamical systems to
reduce the full model to a simpler set of equations. Mathematical analysis was
completed using three slow variables with two different time scales.
Intermittently synchronous oscillations are generated by overlapped spiking
which crucially depends on the geometry of the slow phase plane and the
interplay between slow variables as well as the strength of synapses. Two slow
variables are responsible for the generation of activity patterns with
overlapped spiking and the other slower variable enhances the robustness of an
irregular and intermittent activity pattern. While the analyzed network and the
explored mechanism of intermittent synchrony appear to be quite generic, the
results of this analysis can be used to trace particular values of biophysical
parameters (synaptic strength and parameters of calcium dynamics), which are
known to be impacted in Parkinson's disease.
</summary>
    <author>
      <name>Choongseok Park</name>
    </author>
    <author>
      <name>Leonid L. Rubchinsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3633078</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3633078" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos, 21, 033125, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.2556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4167v1</id>
    <updated>2011-08-21T06:54:49Z</updated>
    <published>2011-08-21T06:54:49Z</published>
    <title>Storing events to retell them (Commentary on Suddendorf and Corballis:
  'The evolution of foresight')</title>
    <summary>  Episodic memory is certainly a unique endowment, but its primary purpose is
something other than to provide raw material for creative synthesis of future
scenarios. Remembered episodes are exactly those which are worth telling. The
function of episodic memory, in our view, is to accumulate stories that are
relevant to recount in conversation.
</summary>
    <author>
      <name>Jean-Louis Dessalles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INFRES, LTCI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">jld-07051403</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Behavioral and Brain Sciences 30, 3 (2007) 321-322</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.4167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5225v4</id>
    <updated>2012-02-13T17:51:39Z</updated>
    <published>2011-02-25T12:29:51Z</published>
    <title>Let Us Dance Just a Little Bit More --- On the Information Capacity of
  the Human Motor System</title>
    <summary>  Fitts' law is a fundamental tool in measuring the capacity of the human motor
system. However, it is, by definition, limited to aimed movements toward
spatially expanded targets. We revisit its information-theoretic basis with the
goal of generalizing it into unconstrained trained movement such as dance and
sports. The proposed new measure is based on a subject's ability to accurately
reproduce a complex movement pattern. We demonstrate our framework using
motion-capture data from professional dance performances.
</summary>
    <author>
      <name>Teemu Roos</name>
    </author>
    <author>
      <name>Antti Oulasvirta</name>
    </author>
    <author>
      <name>Laura Leppänen</name>
    </author>
    <author>
      <name>Arttu Modig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2012 Information Theory and Applications Workshop,
  San Diego, CA</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.5225v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5225v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2373v1</id>
    <updated>2011-03-11T21:05:18Z</updated>
    <published>2011-03-11T21:05:18Z</published>
    <title>Drive for Creativity</title>
    <summary>  We advance a hypothesis that creativity has evolved with evolution of
internal representations, possibly from amniotes to primates, and further in
human cultural evolution. Representations separated sensing from acting and
gave "internal room" for creativity. To see (or perform any sensing), creatures
with internal representations had to modify these representations to fit sensor
signals. Therefore the knowledge instinct, KI, the drive to fit representations
to the world, had to evolve along with internal representations. Until
primates, it remained simple, without language internal representations could
not evolve from perceptions to abstract representations, and abstract thoughts
were not possible. We consider creative vs. non-creative decision making, and
compare KI with Kahneman-Tversky's heuristic thinking. We identify higher,
conscious levels of KI with the drive for creativity (DC) and discuss the roles
of language and music, brain mechanisms involved, and experimental directions
for testing the advanced hypotheses.
</summary>
    <author>
      <name>Leonid Perlovsky</name>
    </author>
    <author>
      <name>Daniel Levine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 fig</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5549v1</id>
    <updated>2012-09-25T09:23:41Z</updated>
    <published>2012-09-25T09:23:41Z</published>
    <title>Towards a learning-theoretic analysis of spike-timing dependent
  plasticity</title>
    <summary>  This paper suggests a learning-theoretic perspective on how synaptic
plasticity benefits global brain functioning. We introduce a model, the
selectron, that (i) arises as the fast time constant limit of leaky
integrate-and-fire neurons equipped with spiking timing dependent plasticity
(STDP) and (ii) is amenable to theoretical analysis. We show that the selectron
encodes reward estimates into spikes and that an error bound on spikes is
controlled by a spiking margin and the sum of synaptic weights. Moreover, the
efficacy of spikes (their usefulness to other reward maximizing selectrons)
also depends on total synaptic strength. Finally, based on our analysis, we
propose a regularized version of STDP, and show the regularization improves the
robustness of neuronal learning when faced with multiple stimuli.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <author>
      <name>Michel Besserve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Adv. Neural Inf. Proc. Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.5549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2918v3</id>
    <updated>2014-01-17T12:46:51Z</updated>
    <published>2012-09-13T14:55:05Z</published>
    <title>A new class of metrics for spike trains</title>
    <summary>  The distance between a pair of spike trains, quantifying the differences
between them, can be measured using various metrics. Here we introduce a new
class of spike train metrics, inspired by the Pompeiu-Hausdorff distance, and
compare them with existing metrics. Some of our new metrics (the modulus-metric
and the max-metric) have characteristics that are qualitatively different than
those of classical metrics like the van Rossum distance or the Victor &amp; Purpura
distance. The modulus-metric and the max-metric are particularly suitable for
measuring distances between spike trains where information is encoded in
bursts, but the number and the timing of spikes inside a burst does not carry
information. The modulus-metric does not depend on any parameters and can be
computed using a fast algorithm, in a time that depends linearly on the number
of spikes in the two spike trains. We also introduce localized versions of the
new metrics, which could have the biologically-relevant interpretation of
measuring the differences between spike trains as they are perceived at a
particular moment in time by a neuron receiving these spike trains.
</summary>
    <author>
      <name>Cătălin V. Rusu</name>
    </author>
    <author>
      <name>Răzvan V. Florian</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00545</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00545" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Rusu, C. V., &amp; Florian, R. V. (2014). A new class of metrics for
  spike trains. Neural Computation, 26(2), 306-348</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.2918v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2918v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1094v3</id>
    <updated>2011-09-13T21:01:19Z</updated>
    <published>2011-01-05T21:04:11Z</published>
    <title>A generalized theory for current-source density analysis in brain tissue</title>
    <summary>  The current-source density (CSD) analysis is a widely used method in brain
electrophysiology, but this method rests on a series of assumptions, namely
that the surrounding extracellular medium is resistive and uniform, and in some
versions of the theory, that the current sources are exclusively made by
dipoles. Because of these assumptions, this standard model does not correctly
describe the contributions of monopolar sources or of non-resistive aspects of
the extracellular medium. We propose here a general framework to model electric
fields and potentials resulting from current source densities, without relying
on the above assumptions. We develop a mean-field formalism which is a
generalization of the standard model, and which can directly incorporate
non-resistive (non-ohmic) properties of the extracellular medium, such as ionic
diffusion effects. This formalism recovers the classic results of the standard
model such as the CSD analysis, but in addition, we provide expressions to
generalize the CSD approach to situations with non-resistive media and
arbitrarily complex multipolar configurations of current sources. We found that
the power spectrum of the signal contains the signature of the nature of
current sources and extracellular medium, which provides a direct way to
estimate those properties from experimental data, and in particular, estimate
the possible contribution of electric monopoles.
</summary>
    <author>
      <name>Claude Bedard</name>
    </author>
    <author>
      <name>Alain Destexhe</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.84.041909</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.84.041909" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review E, in press, 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review E 84: 041909 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.1094v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1094v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1428v2</id>
    <updated>2012-08-07T12:19:28Z</updated>
    <published>2012-06-07T09:17:34Z</published>
    <title>Visualization in Connectomics</title>
    <summary>  Connectomics is a field of neuroscience that analyzes neuronal connections. A
connectome is a complete map of a neuronal system, comprising all neuronal
connections between its structures. The term "connectome" is close to the word
"genome" and implies completeness of all neuronal connections, in the same way
as a genome is a complete listing of all nucleotide sequences. The goal of
connectomics is to create a complete representation of the brain's wiring. Such
a representation is believed to increase our understanding of how functional
brain states emerge from their underlying anatomical structure. Furthermore, it
can provide important information for the cure of neuronal dysfunctions like
schizophrenia or autism. In this paper, we review the current state-of-the-art
of visualization and image processing techniques in the field of connectomics
and describe some remaining challenges.
</summary>
    <author>
      <name>Hanspeter Pfister</name>
    </author>
    <author>
      <name>Verena Kaynig</name>
    </author>
    <author>
      <name>Charl P. Botha</name>
    </author>
    <author>
      <name>Stefan Bruckner</name>
    </author>
    <author>
      <name>Vincent J. Dercksen</name>
    </author>
    <author>
      <name>Hans-Christian Hege</name>
    </author>
    <author>
      <name>Jos B. T. M. Roerdink</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Improved definition of diffusion PDF. Integrated reviewer comments:
  Added figures showing DTI tractography and glyphs, fMRI connectivity vis, EM
  reconstruction of neuronal structures, Brainbow image. Typos and grammar
  errors fixed. Description of connectivity matrix added</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1428v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1428v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1094v1</id>
    <updated>2012-04-04T23:38:57Z</updated>
    <published>2012-04-04T23:38:57Z</published>
    <title>Control over stress induces plasticity of individual prefrontal cortical
  neurons: A conductance-based neural simulation</title>
    <summary>  Behavioral control over stressful stimuli induces resilience to future
conditions when control is lacking. The medial prefrontal cortex(mPFC) is a
critically important brain region required for plasticity of stress resilience.
We found that control over stress induces plasticity of the intrinsic
voltage-gated conductances of pyramidal neurons in the PFC. To gain insight
into the underlying biophysical mechanisms of this plasticity we used the
conductance- based neural simulation software tool, NEURON, to model the
increase in membrane excitability associated with resilience to stress. A ball
and stick multicompartment conductance-based model was used to realistically
fit passive and active data traces from prototypical pyramidal neurons in
neurons in rats with control over tail shock stress and those lacking control.
The results indicate that the plasticity of membrane excitability associated
with control over stress can be attributed to an increase in Na+ and Ca2+
T-type conductances and an increase in the leak conductance. Using simulated
dendritic synaptic inputs we observed an increase in excitatory postsynaptic
summation and amplification resulting in elevated action potential output. This
realistic simulation suggests that control over stress enhances the output of
the PFC and offers specific testable hypotheses to guide future
electrophysiological mechanistic studies in animal models of resilience and
vulnerability to stress.
</summary>
    <author>
      <name>Juan A. Varela</name>
    </author>
    <author>
      <name>Jungang Wang</name>
    </author>
    <author>
      <name>Andrew L. Varnell</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/npre.2011.6267.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/npre.2011.6267.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages 2 figures Nature Precedings
  &lt;http://dx.doi.org/10.1038/npre.2011.6267.1&gt; (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2072v1</id>
    <updated>2011-12-09T11:09:30Z</updated>
    <published>2011-12-09T11:09:30Z</published>
    <title>Long Brief Pulse Method for Pulse-wave modified Electroconvulsive
  Therapy</title>
    <summary>  Modified-Electroconvulsive Therapy (m-ECT) is administered for the treatment
of various psychiatric disorders. The Seizure Generalization Hypothesis holds
that propagation of the induced seizure throughout the whole brain is essential
for the effective ECT intervention. However, we encounter many clinical cases
where, due to high thresholds, seizure is not induced by the maximum dose of
electrical charge. Some studies have indicated that the ultrabrief pulse
method, in which pulse width is less than 0.5millisecond (ms), is more
effective at inducing seizure than conventional brief pulse (0.5ms-2.0ms).
Contrary to the studies, we experienced a case of schizophrenia in which m-ECT
with 1.0 and 1.5 ms width pulse (referred to as 'long' brief pulse as 0.5ms
width pulse is the default in Japan) succeeded in inducing seizure, whereas
ultrabrief pulse failed to induce seizure. This case is described in detail.
Moreover, we discuss the underlying mechanism of this phenomenon.
</summary>
    <author>
      <name>Hiroaki Inomata</name>
    </author>
    <author>
      <name>Harima Hirohiko</name>
    </author>
    <author>
      <name>Masanari Itokawa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5348/ijcri-2012-07-147-CR-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5348/ijcri-2012-07-147-CR-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1919v1</id>
    <updated>2011-01-10T18:40:41Z</updated>
    <published>2011-01-10T18:40:41Z</published>
    <title>Correlation transfer in stochastically driven oscillators over long and
  short time scales</title>
    <summary>  In the absence of synaptic coupling, two or more neural oscillators may
become synchronized by virtue of the statistical correlations in their noisy
input streams. Recent work has shown that the degree of correlation transfer
from input currents to output spikes depends not only on intrinsic oscillator
dynamics, but also depends on the length of the observation window over which
the correlation is calculated. In this paper we use stochastic phase reduction
and regular perturbations to derive the correlation of the total phase elapsed
over long time scales, a quantity which provides a convenient proxy for the
spike count correlation. Over short time scales, we derive the spike count
correlation directly using straightforward probabilistic reasoning applied to
the density of the phase difference. Our approximations show that output
correlation scales with the autocorrelation of the phase resetting curve over
long time scales. We also find a concise expression for the influence of the
shape of the phase resetting curve on the initial slope of the output
correlation over short time scales. These analytic results together with
numerical simulations provide new intuitions for the recent counterintuitive
finding that type I oscillators transfer correlations more faithfully than do
type II over long time scales, while the reverse holds true for the better
understood case of short time scales.
</summary>
    <author>
      <name>Aushra Abouzeid</name>
    </author>
    <author>
      <name>Bard Ermentrout</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.84.061914</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.84.061914" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, submitted to Physical Review E</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.1919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.1384v1</id>
    <updated>2011-02-07T18:19:29Z</updated>
    <published>2011-02-07T18:19:29Z</published>
    <title>Relational Dynamics in Perception: Impacts on trial-to-trial variation</title>
    <summary>  We show that trial-to-trial variability in sensory detection of a weak visual
stimulus is dramatically diminished when rather than presenting a fixed
stimulus contrast, fluctuations in a subject's judgment are matched by
fluctuations in stimulus contrast. This attenuation of fluctuations does not
involve a change in the subject's psychometric function. The result is
consistent with the interpretation of trial-to-trial variability in this
sensory detection task being a high-level meta-cognitive control process that
explores for something that our brains are so used to: subject-object
relational dynamics.
</summary>
    <author>
      <name>Shimon Marom</name>
    </author>
    <author>
      <name>Avner Wallach</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fncom.2011.00016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fncom.2011.00016" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Comput. Neurosci. (2011) 5:16</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.1384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.1384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3549v2</id>
    <updated>2013-11-25T17:03:27Z</updated>
    <published>2012-12-14T18:06:38Z</published>
    <title>Input nonlinearities shape beyond-pairwise correlations and can improve
  information transmission by neural populations</title>
    <summary>  While recent experiments with relatively large neural populations show
significant beyond-pairwise, or {\it higher-order} correlations (HOC), the
impact of HOC on the network's ability to encode information is poorly
understood. We investigate how the biophysical properties of neurons in
networks shape HOC, and how HOC affect population coding. Specifically, we show
that input nonlinearities similar to those observed in physiology experiments
are equivalent to beyond-pairwise interactions in spin-glass-type statistical
models. We then discuss one such model with parameterized pairwise- and
higher-order interactions, revealing conditions under which beyond-pairwise
interactions increase the mutual information between a given stimulus type and
the population responses. For jointly Gaussian stimuli, coding performance is
improved by shaping output HOC via input nonlinearities when neural firing
rates are constrained to be sufficiently low. For natural image stimuli,
performance improves for a broader range of firing rates. Our work suggests
surprising connections between single-neuron biophysics, population activity
statistics, and normative theories of population coding.
</summary>
    <author>
      <name>Joel Zylberberg</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper is 6 pages, including references. 4-page supporting information
  is included the end of the .pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3549v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3549v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0373v1</id>
    <updated>2011-10-03T15:03:35Z</updated>
    <published>2011-10-03T15:03:35Z</published>
    <title>An excitable electronic circuit as a sensory neuron model</title>
    <summary>  An electronic circuit device, inspired on the FitzHugh-Nagumo model of
neuronal excitability, was constructed and shown to operate with
characteristics compatible with those of biological sensory neurons. The
nonlinear dynamical model of the electronics quantitatively reproduces the
experimental observations on the circuit, including the Hopf bifurcation at the
onset of tonic spiking. Moreover, we have implemented an analog noise generator
as a source to study the variability of the spike trains. When the circuit is
in the excitable regime, coherence resonance is observed. At sufficiently low
noise intensity the spike trains have Poisson statistics, as in many biological
neurons. The transfer function of the stochastic spike trains has a dynamic
range of 6 dB, close to experimental values for real olfactory receptor
neurons.
</summary>
    <author>
      <name>Bruno N. S. Medeiros</name>
    </author>
    <author>
      <name>Victor Minces</name>
    </author>
    <author>
      <name>Gabriel B. Mindlin</name>
    </author>
    <author>
      <name>Mauro Copelli</name>
    </author>
    <author>
      <name>José R. Rios Leite</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0218127412502446</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0218127412502446" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Bifurcation Chaos 22 (2012) 1250244</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.0373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3886v1</id>
    <updated>2011-03-20T20:46:29Z</updated>
    <published>2011-03-20T20:46:29Z</published>
    <title>Control of the repetitive firing in the squid giant axon using
  electrical fields</title>
    <summary>  In this research, the aim is to develop a repetitive firing stopper mechanism
using electrical fields exerted on the fiber. The Hodgkin - Huxley nerve fiber
model is used for modeling the membrane potential behavior. The repetitive
firing of the nerve fiber can be stopped using approaches based on the control
theory where the nonlinear Hodgkin - Huxley model is used to achieve this goal.
The effects of the electrical field are considered as an additive quantity over
the equilibrium potentials of the cell membrane channels. The study is a
representative of an experimental application.
</summary>
    <author>
      <name>Resat Ozgur Doruk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, 2 tables, submitted to journal of Computer
  Methods and Programs in Biomedicine</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.3886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3561v1</id>
    <updated>2012-01-17T17:16:05Z</updated>
    <published>2012-01-17T17:16:05Z</published>
    <title>Splay states in finite pulse-coupled networks of excitable neurons</title>
    <summary>  The emergence and stability of splay states is studied in fully coupled
finite networks of N excitable quadratic integrate-and-fire neurons, connected
via synapses modeled as pulses of finite amplitude and duration. For such
synapses, by introducing two distinct types of synaptic events (pulse emission
and termination), we were able to write down an exact event-driven map for the
system and to evaluate the splay state solutions. For M overlapping post
synaptic potentials the linear stability analysis of the splay state should
take in account, besides the actual values of the membrane potentials, also the
firing times associated to the M previous pulse emissions. As a matter of fact,
it was possible, by introducing M complementary variables, to rephrase the
evolution of the network as an event-driven map and to derive an analytic
expression for the Floquet spectrum. We find that, independently of M, the
splay state is marginally stable with N-2 neutral directions. Furthermore, we
have identified a family of periodic solutions surrounding the splay state and
sharing the same neutral stability directions. In the limit of $\delta$-pulses,
it is still possible to derive an event-driven formulation for the dynamics,
however the number of neutrally stable directions, associated to the splay
state, becomes N. Finally, we prove a link between the results for our system
and a previous theory [Watanabe and Strogatz, Physica D, 74 (1994), pp. 197-
253] developed for networks of phase oscillators with sinusoidal coupling.
</summary>
    <author>
      <name>Mario Dipoppa</name>
    </author>
    <author>
      <name>Martin Krupa</name>
    </author>
    <author>
      <name>Alessandro Torcini</name>
    </author>
    <author>
      <name>Boris S. Gutkin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/110859683</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/110859683" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 12 Figures, submitted to SIAM Journal on Applied Dynamical
  Systems (SIADS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM J. Appl. Dyn. Syst. 11, 864-894 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.3561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5934v3</id>
    <updated>2011-07-29T15:21:45Z</updated>
    <published>2011-03-30T14:12:25Z</published>
    <title>On spatial and temporal multilevel dynamics and scaling effects in
  epileptic seizures</title>
    <summary>  Epileptic seizures are one of the most well-known dysfunctions of the nervous
system. During a seizure, a highly synchronized behavior of neural activity is
observed that can cause symptoms ranging from mild sensual malfunctions to the
complete loss of body control. In this paper, we aim to contribute towards a
better understanding of the dynamical systems phenomena that cause seizures.
Based on data analysis and modelling, seizure dynamics can be identified to
possess multiple spatial scales and on each spatial scale also multiple time
scales. At each scale, we reach several novel insights. On the smallest spatial
scale we consider single model neurons and investigate early-warning signs of
spiking. This introduces the theory of critical transitions to excitable
systems. For clusters of neurons (or neuronal regions) we use patient data and
find oscillatory behavior and new scaling laws near the seizure onset. These
scalings lead to substantiate the conjecture obtained from mean-field models
that a Hopf bifurcation could be involved near seizure onset. On the largest
spatial scale we introduce a measure based on phase-locking intervals and
wavelets into seizure modelling. It is used to resolve synchronization between
different regions in the brain and identifies time-shifted scaling laws at
different wavelet scales. We also compare our wavelet-based multiscale approach
with maximum linear cross-correlation and mean-phase coherence measures.
</summary>
    <author>
      <name>Christian Kuehn</name>
    </author>
    <author>
      <name>Christian Meisel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.5934v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5934v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2666v4</id>
    <updated>2013-06-25T13:16:31Z</updated>
    <published>2012-08-13T19:00:24Z</published>
    <title>Evolutionary instability of Zero Determinant strategies demonstrates
  that winning isn't everything</title>
    <summary>  Zero Determinant (ZD) strategies are a new class of probabilistic and
conditional strategies that are able to unilaterally set the expected payoff of
an opponent in iterated plays of the Prisoner's Dilemma irrespective of the
opponent's strategy, or else to set the ratio between a ZD player's and their
opponent's expected payoff. Here we show that while ZD strategies are weakly
dominant, they are not evolutionarily stable and will instead evolve into less
coercive strategies. We show that ZD strategies with an informational advantage
over other players that allows them to recognize other ZD strategies can be
evolutionarily stable (and able to exploit other players). However, such an
advantage is bound to be short-lived as opposing strategies evolve to
counteract the recognition.
</summary>
    <author>
      <name>Christoph Adami</name>
    </author>
    <author>
      <name>Arend Hintze</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/ncomms3193</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/ncomms3193" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures. Change in title (again!) to comply with Nature
  Communications requirements. To appear in Nature Communications</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature Communications 4 (2013) 2193</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.2666v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2666v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2679v1</id>
    <updated>2011-06-14T11:37:46Z</updated>
    <published>2011-06-14T11:37:46Z</published>
    <title>BEM-based SMS-LORETA - an advanced method to localize multiple
  simultaneously active sources in the cerebral cortex</title>
    <summary>  In this paper the method and performance data of 'Boundary Element Method
(BEM)'-based SMS-LORETA (Simultaneous Multiple Sources LORETA) are presented.
According to these data the method is capable of locating efficiently multiple
simultaneously active neural sources from scalp potential topographies
automatically. BEM-based SMS-LORETA is a procedure to fully interpret sLORETA
solutions, i.e., with a given scalp potential distribution it gives the number
of identifiable sources as well as their strength and orientation. Performance
data result from numerous analyses of simulated noise-free and
noise-contaminated potential distributions (topographies) that have been
obtained by means of BEM-based forward solutions, where one, two or three
simultaneously active dipoles were randomly chosen regarding their positions
and polarity.
</summary>
    <author>
      <name>Avni Pllana</name>
    </author>
    <author>
      <name>Herbert Bauer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1278v3</id>
    <updated>2012-04-05T15:16:44Z</updated>
    <published>2011-05-06T13:06:00Z</published>
    <title>Mixed-mode oscillations and interspike interval statistics in the
  stochastic FitzHugh-Nagumo model</title>
    <summary>  We study the stochastic FitzHugh-Nagumo equations, modelling the dynamics of
neuronal action potentials, in parameter regimes characterised by mixed-mode
oscillations. The interspike time interval is related to the random number of
small-amplitude oscillations separating consecutive spikes. We prove that this
number has an asymptotically geometric distribution, whose parameter is related
to the principal eigenvalue of a substochastic Markov chain. We provide
rigorous bounds on this eigenvalue in the small-noise regime, and derive an
approximation of its dependence on the system's parameters for a large range of
noise intensities. This yields a precise description of the probability
distribution of observed mixed-mode patterns and interspike intervals.
</summary>
    <author>
      <name>Nils Berglund</name>
    </author>
    <author>
      <name>Damien Landon</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/0951-7715/25/8/2303</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/0951-7715/25/8/2303" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nonlinearity 25 (2012) 2303--2335</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1278v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1278v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H10, 34C26 (Primary) 60J20, 92C20 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2249v1</id>
    <updated>2012-02-10T12:57:34Z</updated>
    <published>2012-02-10T12:57:34Z</published>
    <title>Supervised Learning in Multilayer Spiking Neural Networks</title>
    <summary>  The current article introduces a supervised learning algorithm for multilayer
spiking neural networks. The algorithm presented here overcomes some
limitations of existing learning algorithms as it can be applied to neurons
firing multiple spikes and it can in principle be applied to any linearisable
neuron model. The algorithm is applied successfully to various benchmarks, such
as the XOR problem and the Iris data set, as well as complex classifications
problems. The simulations also show the flexibility of this supervised learning
algorithm which permits different encodings of the spike timing patterns,
including precise spike trains encoding.
</summary>
    <author>
      <name>Ioana Sporea</name>
    </author>
    <author>
      <name>André Grüning</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00396</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00396" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Compuation February 2013, Vol. 25, No. 2, Pages 473-509</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0380v1</id>
    <updated>2012-06-02T13:22:50Z</updated>
    <published>2012-06-02T13:22:50Z</published>
    <title>The Poincare map of randomly perturbed periodic motion</title>
    <summary>  A system of autonomous differential equations with a stable limit cycle and
perturbed by small white noise is analyzed in this work. In the vicinity of the
limit cycle of the unperturbed deterministic system, we define, construct, and
analyze the Poincare map of the randomly perturbed periodic motion. We show
that the time of the first exit from a small neighborhood of the fixed point of
the map, which corresponds to the unperturbed periodic orbit, is well
approximated by the geometric distribution. The parameter of the geometric
distribution tends zero together with the noise intensity. Therefore, our
result can be interpreted as an estimate of stability of periodic motion to
random perturbations.
  In addition, we show that the geometric distribution of the first exit times
translates into statistical properties of solutions of important differential
equation models in applications. To this end, we demonstrate three examples
from mathematical neuroscience featuring complex oscillatory patterns
characterized by the geometric distribution. We show that in each of these
models the statistical properties of emerging oscillations are fully explained
by the general properties of randomly perturbed periodic motions identified in
this paper.
</summary>
    <author>
      <name>Pawel Hitczenko</name>
    </author>
    <author>
      <name>Georgi S. Medvedev</name>
    </author>
    <link href="http://arxiv.org/abs/1206.0380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0564v1</id>
    <updated>2012-10-01T20:30:36Z</updated>
    <published>2012-10-01T20:30:36Z</published>
    <title>Super-resolution using Sparse Representations over Learned Dictionaries:
  Reconstruction of Brain Structure using Electron Microscopy</title>
    <summary>  A central problem in neuroscience is reconstructing neuronal circuits on the
synapse level. Due to a wide range of scales in brain architecture such
reconstruction requires imaging that is both high-resolution and
high-throughput. Existing electron microscopy (EM) techniques possess required
resolution in the lateral plane and either high-throughput or high depth
resolution but not both. Here, we exploit recent advances in unsupervised
learning and signal processing to obtain high depth-resolution EM images
computationally without sacrificing throughput. First, we show that the brain
tissue can be represented as a sparse linear combination of localized basis
functions that are learned using high-resolution datasets. We then develop
compressive sensing-inspired techniques that can reconstruct the brain tissue
from very few (typically 5) tomographic views of each section. This enables
tracing of neuronal processes and, hence, high throughput reconstruction of
neural circuits on the level of individual synapses.
</summary>
    <author>
      <name>Tao Hu</name>
    </author>
    <author>
      <name>Juan Nunez-Iglesias</name>
    </author>
    <author>
      <name>Shiv Vitaladevuni</name>
    </author>
    <author>
      <name>Lou Scheffer</name>
    </author>
    <author>
      <name>Shan Xu</name>
    </author>
    <author>
      <name>Mehdi Bolorizadeh</name>
    </author>
    <author>
      <name>Harald Hess</name>
    </author>
    <author>
      <name>Richard Fetter</name>
    </author>
    <author>
      <name>Dmitri Chklovskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3150v1</id>
    <updated>2012-09-14T10:46:38Z</updated>
    <published>2012-09-14T10:46:38Z</published>
    <title>Agent-based Exploration of Wirings of Biological Neural Networks:
  Position Paper</title>
    <summary>  The understanding of human central nervous system depends on knowledge of its
wiring. However, there are still gaps in our understanding of its wiring due to
technical difficulties. While some information is coming out from human
experiments, medical research is lacking of simulation models to put current
findings together to obtain the global picture and to predict hypotheses to
lead future experiments. Agent-based modeling and simulation (ABMS) is a strong
candidate for the simulation model. In this position paper, we discuss the
current status of "neural wiring" and "ABMS in biological systems". In
particular, we discuss that the ABMS context provides features required for
exploration of biological neural wiring.
</summary>
    <author>
      <name>Önder Gürcan</name>
    </author>
    <author>
      <name>Oğuz Dikenelli</name>
    </author>
    <author>
      <name>Kemal S. Türker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, ABModSim 2010 Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4174v1</id>
    <updated>2012-02-19T18:12:28Z</updated>
    <published>2012-02-19T18:12:28Z</published>
    <title>Perception Lie Paradox: Mathematically Proved Uncertainty about Humans
  Perception Similarity</title>
    <summary>  Agents' judgment depends on perception and previous knowledge. Assuming that
previous knowledge depends on perception, we can say that judgment depends on
perception. So, if judgment depends on perception, can agents judge that they
have the same perception? In few words, this is the addressed paradox through
this document. While illustrating on the paradox, it's found that to reach
agreement in communication, it's not necessary for parties to have the same
perception however the necessity is to have perception correspondence. The
attempted solution to this paradox reveals a potential uncertainty in judging
the matter thus supporting the skeptical view of the problem. Moreover,
relating perception to intelligence, the same uncertainty is inherited by
judging the level of intelligence of an agent compared to others not
necessarily from the same kind (e.g. machine intelligence compared to human
intelligence). Using a proposed simple mathematical model for perception and
action, a tool is developed to construct scenarios, and the problem is
addressed mathematically such that conclusions are drawn systematically based
on mathematically defined properties. When it comes to formalization,
philosophical arguments and views become more visible and explicit.
</summary>
    <author>
      <name>Ahmed M. Mahran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3633v1</id>
    <updated>2012-10-12T20:52:55Z</updated>
    <published>2012-10-12T20:52:55Z</published>
    <title>A Simulation of the Effects of Receive Field Contrast on
  Motion-Corrected EPI Time Series</title>
    <summary>  The receive field of MRI imparts an image contrast which is spatially fixed
relative to the receive coil. If motion correction is used to correct subject
motion occurring during an EPI time series then the receiver contrast will
effectively move relative to the subject and produce temporal modulations in
the image amplitude. This effect, which we will call the RFC-MoCo effect, may
have consequences in the analysis and interpretation of fMRI results. There are
many potential causes of motion-related noise and systematic error in EPI time
series and isolating the RFC-MoCo effect would be difficult. Therefore, we have
undertaken a simulation of this effect to better understand its severity. The
simulations examine this effect for a receive-only single-channel 16-leg
birdcage coil and a receive-only 12-channel phased array. In particular we
study: (1) The effect size; (2) Its consequences to the temporal correlations
between signals arising at different spatial locations (spatial-temporal
correlations) as is often calculated in resting state fMRI analyses; and (3)
Its impact on the temporal signal-to-noise ratio of an EPI time series. We find
that signal changes arising from the RFC-MoCo effect are likely to compete with
BOLD (blood-oxygen-level-dependent) signal changes in the presence of
significant motion, even under the assumption of perfect motion correction.
Consequently, we find that the RFC-MoCo effect may lead to spurious temporal
correlations across the image space, and that temporal SNR may be degraded with
increasing motion.
</summary>
    <author>
      <name>D. Sheltraw</name>
    </author>
    <author>
      <name>B. Inglis</name>
    </author>
    <link href="http://arxiv.org/abs/1210.3633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4914v1</id>
    <updated>2011-10-21T21:47:08Z</updated>
    <published>2011-10-21T21:47:08Z</published>
    <title>Impact of network structure and cellular response on spike time
  correlations</title>
    <summary>  Novel experimental techniques reveal the simultaneous activity of larger and
larger numbers of neurons. As a result there is increasing interest in the
structure of cooperative -- or correlated -- activity in neural populations,
and in the possible impact of such correlations on the neural code. A
fundamental theoretical challenge is to understand how the architecture of
network connectivity along with the dynamical properties of single cells shape
the magnitude and timescale of correlations. We provide a general approach to
this problem by extending prior techniques based on linear response theory. We
consider networks of general integrate-and-fire cells with arbitrary
architecture, and provide explicit expressions for the approximate
cross-correlation between constituent cells. These correlations depend strongly
on the operating point (input mean and variance) of the neurons, even when
connectivity is fixed. Moreover, the approximations admit an expansion in
powers of the matrices that describe the network architecture. This expansion
can be readily interpreted in terms of paths between different cells. We apply
our results to large excitatory-inhibitory networks, and demonstrate first how
precise balance --- or lack thereof --- between the strengths and timescales of
excitatory and inhibitory synapses is reflected in the overall correlation
structure of the network. We then derive explicit expressions for the average
correlation structure in randomly connected networks. These expressions help to
identify the important factors that shape coordinated neural activity in such
networks.
</summary>
    <author>
      <name>James Trousdale</name>
    </author>
    <author>
      <name>Yu Hu</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <author>
      <name>Krešimir Josić</name>
    </author>
    <link href="http://arxiv.org/abs/1110.4914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0834v1</id>
    <updated>2012-03-05T09:00:50Z</updated>
    <published>2012-03-05T09:00:50Z</published>
    <title>Efficient synchronization of structurally adaptive coupled
  Hindmarsh-Rose neurons</title>
    <summary>  The use of spikes to carry information between brain areas implies complete
or partial synchronization of the neurons involved. The degree of
synchronization reached by two coupled systems and the energy cost of
maintaining their synchronized behaviour is highly dependent on the nature of
the systems. For non-identical systems the maintenance of a synchronized regime
is energetically a costly process. In this work, we study conditions under
which two non-identical electrically coupled neurons can reach an efficient
regime of synchronization at low energy cost. We show that the energy
consumption required to keep the synchronized regime can be spontaneously
reduced if the receiving neuron has adaptive mechanisms able to bring its
biological parameters closer in value to the corresponding ones in the sending
neuron.
</summary>
    <author>
      <name>A. Moujahid</name>
    </author>
    <author>
      <name>A. d'Anjou</name>
    </author>
    <author>
      <name>F. J. Torrealdea</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos, Solitons and Fractals, 44 (2011) 929-933</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5390v3</id>
    <updated>2013-04-27T14:00:35Z</updated>
    <published>2012-11-22T22:33:40Z</published>
    <title>Remote synchronization reveals network symmetries and functional modules</title>
    <summary>  We study a Kuramoto model in which the oscillators are associated with the
nodes of a complex network and the interactions include a phase frustration,
thus preventing full synchronization. The system organizes into a regime of
remote synchronization where pairs of nodes with the same network symmetry are
fully synchronized, despite their distance on the graph. We provide analytical
arguments to explain this result and we show how the frustration parameter
affects the distribution of phases. An application to brain networks suggests
that anatomical symmetry plays a role in neural synchronization by determining
correlated functional modules across distant locations.
</summary>
    <author>
      <name>Vincenzo Nicosia</name>
    </author>
    <author>
      <name>Miguel Valencia</name>
    </author>
    <author>
      <name>Mario Chavez</name>
    </author>
    <author>
      <name>Albert Díaz-Guilera</name>
    </author>
    <author>
      <name>Vito Latora</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.174102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.174102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. Lett. 110, 174102 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.5390v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5390v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5171v1</id>
    <updated>2011-02-25T07:11:13Z</updated>
    <published>2011-02-25T07:11:13Z</published>
    <title>Fast Inference of Interactions in Assemblies of Stochastic
  Integrate-and-Fire Neurons from Spike Recordings</title>
    <summary>  We present two Bayesian procedures to infer the interactions and external
currents in an assembly of stochastic integrate-and-fire neurons from the
recording of their spiking activity. The first procedure is based on the exact
calculation of the most likely time courses of the neuron membrane potentials
conditioned by the recorded spikes, and is exact for a vanishing noise variance
and for an instantaneous synaptic integration. The second procedure takes into
account the presence of fluctuations around the most likely time courses of the
potentials, and can deal with moderate noise levels. The running time of both
procedures is proportional to the number S of spikes multiplied by the squared
number N of neurons. The algorithms are validated on synthetic data generated
by networks with known couplings and currents. We also reanalyze previously
published recordings of the activity of the salamander retina (including from
32 to 40 neurons, and from 65,000 to 170,000 spikes). We study the dependence
of the inferred interactions on the membrane leaking time; the differences and
similarities with the classical cross-correlation analysis are discussed.
</summary>
    <author>
      <name>Remi Monasson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPTENS</arxiv:affiliation>
    </author>
    <author>
      <name>Simona Cocco</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in J. Comput. Neurosci. (dec 2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.5171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1360v1</id>
    <updated>2011-11-05T23:17:02Z</updated>
    <published>2011-11-05T23:17:02Z</published>
    <title>Magnetic Field-Assisted Gene Delivery: Achievements and Therapeutic
  Potential</title>
    <summary>  The discovery in the early 2000's that magnetic nanoparticles (MNPs)
complexed to nonviral or viral vectors can, in the presence of an external
magnetic field, greatly enhance gene transfer into cells has raised much
interest. This technique, called magnetofection, was initially developed mainly
to improve gene transfer in cell cultures, a simpler and more easily
controllable scenario than in vivo models. These studies provided evidence for
some unique capabilities of magnetofection. Progressively, the interest in
magnetofection expanded to its application in animal models and led to the
association of this technique with another technology, magnetic drug targeting
(MDT). This combination offers the possibility to develop more efficient and
less invasive gene therapy strategies for a number of major pathologies like
cancer, neurodegeneration and myocardial infarction. The goal of MDT is to
concentrate MNPs functionalized with therapeutic drugs, in target areas of the
body by means of properly focused external magnetic fields. The availability of
stable, nontoxic MNP-gene vector complexes now offers the opportunity to
develop magnetic gene targeting (MGT), a variant of MDT in which the gene
coding for a therapeutic molecule, rather than the molecule itself, is
delivered to a therapeutic target area in the body. This article will first
outline the principle of magnetofection, subsequently describing the properties
of the magnetic fields and MNPs used in this technique. Next, it will review
the results achieved by magnetofection in cell cultures. Last, the potential of
MGT for implementing minimally invasive gene therapy will be discussed.
</summary>
    <author>
      <name>José I. Schwerdt</name>
    </author>
    <author>
      <name>Gerardo F. Goya</name>
    </author>
    <author>
      <name>Pilar Calatayud</name>
    </author>
    <author>
      <name>Claudia B. Hereñú</name>
    </author>
    <author>
      <name>Paula C. Reggiani</name>
    </author>
    <author>
      <name>Rodolfo G. Goya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.1360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2100v1</id>
    <updated>2012-08-10T06:54:09Z</updated>
    <published>2012-08-10T06:54:09Z</published>
    <title>Input Statistics and Hebbian Crosstalk Effects</title>
    <summary>  As an extension of prior work, we study inspecific Hebbian learning using the
classical Oja model. We use a combination of analytical tools and numerical
simulations to investigate how the effects of inspecificity (or synaptic
"cross-talk") depend on the input statistics. We investigated a variety of
patterns that appear in dimensions higher than 2 (and classified them based on
covariance type and input bias). The effects of inspecificity on the learning
outcome were found to depend very strongly on the nature of the input, and in
some cases were very dramatic, making unlikely the existence of a generic
neural algorithm to correct learning inaccuracy due to cross-talk. We discuss
the possibility that sophisticated learning, such as presumably occurs in the
neocortex, is enabled as much by special proofreading machinery for enhancing
specificity, as by special algorithms.
</summary>
    <author>
      <name>Anca Radulescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages text, 5 figures, 1 page references, 2 appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.2100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3861v1</id>
    <updated>2012-04-17T18:03:56Z</updated>
    <published>2012-04-17T18:03:56Z</published>
    <title>Statistical Properties of Avalanches in Networks</title>
    <summary>  We characterize the distributions of size and duration of avalanches
propagating in complex networks. By an avalanche we mean the sequence of events
initiated by the externally stimulated `excitation' of a network node, which
may, with some probability, then stimulate subsequent firings of the nodes to
which it is connected, resulting in a cascade of firings. This type of process
is relevant to a wide variety of situations, including neuroscience, cascading
failures on electrical power grids, and epidemology. We find that the
statistics of avalanches can be characterized in terms of the largest
eigenvalue and corresponding eigenvector of an appropriate adjacency matrix
which encodes the structure of the network. By using mean-field analyses,
previous studies of avalanches in networks have not considered the effect of
network structure on the distribution of size and duration of avalanches. Our
results apply to individual networks (rather than network ensembles) and
provide expressions for the distributions of size and duration of avalanches
starting at particular nodes in the network. These findings might find
application in the analysis of branching processes in networks, such as
cascading power grid failures and critical brain dynamics. In particular, our
results show that some experimental signatures of critical brain dynamics
(i.e., power-law distributions of size and duration of neuronal avalanches),
are robust to complex underlying network topologies.
</summary>
    <author>
      <name>Daniel B. Larremore</name>
    </author>
    <author>
      <name>Marshall Y. Carpenter</name>
    </author>
    <author>
      <name>Edward Ott</name>
    </author>
    <author>
      <name>Juan G. Restrepo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.85.066131</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.85.066131" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 85, 066131 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1241v1</id>
    <updated>2011-11-03T03:27:27Z</updated>
    <published>2011-11-03T03:27:27Z</published>
    <title>Strange Nonchaotic Oscillations in The Quasiperiodically Forced
  Hodgkin-Huxley Neuron</title>
    <summary>  We numerically study dynamical behaviors of the quasiperiodically forced
Hodgkin-Huxley neuron and compare the dynamical responses with those for the
case of periodic stimulus. In the periodically forced case, a transition from a
periodic to a chaotic oscillation was found to occur via period doublings in
previous numerical and experimental works. We investigate the effect of the
quasiperiodic forcing on this period-doubling route to chaotic oscillation. In
contrast to the case of periodic forcing, new type of strange nonchaotic (SN)
oscillating states (that are geometrically strange but have no positive
Lyapunov exponents) are found to exist between the regular and chaotic
oscillating states as intermediate ones. Their strange fractal geometry leads
to aperiodic "complex" spikings. Various dynamical routes to SN oscillations
are identified, as in the quasiperiodically forced logistic map. These SN
spikings are expected to be observed in experiments of the quasiperiodically
forced squid giant axon.
</summary>
    <author>
      <name>Woochang Lim</name>
    </author>
    <author>
      <name>Sang-Yoon Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1751-8113/42/26/265103</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1751-8113/42/26/265103" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Phys. A 42, 265103 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.1241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0452v1</id>
    <updated>2011-10-03T19:41:26Z</updated>
    <published>2011-10-03T19:41:26Z</published>
    <title>Onset of negative interspike interval correlations in adapting neurons</title>
    <summary>  Negative serial correlations in single spike trains are an effective method
to reduce the variability of spike counts. One of the factors contributing to
the development of negative correlations between successive interspike
intervals is the presence of adaptation currents. In this work, based on a
hidden Markov model and a proper statistical description of conditional
responses, we obtain analytically these correlations in an adequate dynamical
neuron model resembling adaptation. We derive the serial correlation
coefficients for arbitrary lags, under a small adaptation scenario. In this
case, the behavior of correlations is universal and depends on the first-order
statistical description of an exponentially driven time-inhomogeneous
stochastic process.
</summary>
    <author>
      <name>Eugenio Urdapilleta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.84.041904</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.84.041904" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages (10 pages in the journal version), 6 figures, published in
  Phys. Rev. E; http://link.aps.org/doi/10.1103/PhysRevE.84.041904</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 84, 041904 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.0452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0669v1</id>
    <updated>2011-11-02T21:24:43Z</updated>
    <published>2011-11-02T21:24:43Z</published>
    <title>Coherent states of the Euclidean group and activation regions of primary
  visual cortex</title>
    <summary>  The uncertainty principle of SE(2) allows to construct a coherent states
transform that is strictly related to the Bargmann transform for the second
Heisenberg group H2. The corresponding target space is characterized
constructively and related to the almost complex structure of SE(2) as a
contact manifold. Such a coherent state transform provides a model for neural
activity maps in the primary visual cortex, that are then described in terms of
minimal uncertainty states. The results of the model are compared with the
experimental measurements.
</summary>
    <author>
      <name>Davide Barbieri</name>
    </author>
    <author>
      <name>Giovanna Citti</name>
    </author>
    <author>
      <name>Gonzalo Sanguinetti</name>
    </author>
    <author>
      <name>Alessandro Sarti</name>
    </author>
    <link href="http://arxiv.org/abs/1111.0669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.RT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2944v1</id>
    <updated>2012-10-10T14:59:26Z</updated>
    <published>2012-10-10T14:59:26Z</published>
    <title>Spatial Auditory BCI Paradigm Utilizing N200 and P300 Responses</title>
    <summary>  The paper presents our recent results obtained with a new auditory spatial
localization based BCI paradigm in which the ERP shape differences at early
latencies are employed to enhance the traditional P300 responses in an oddball
experimental setting. The concept relies on the recent results in auditory
neuroscience showing a possibility to differentiate early anterior
contralateral responses to attended spatial sources. Contemporary
stimuli-driven BCI paradigms benefit mostly from the P300 ERP latencies in so
called "aha-response" settings. We show the further enhancement of the
classification results in spatial auditory paradigms by incorporating the N200
latencies, which differentiate the brain responses to lateral, in relation to
the subject head, sound locations in the auditory space. The results reveal
that those early spatial auditory ERPs boost online classification results of
the BCI application. The online BCI experiments with the multi-command BCI
prototype support our research hypothesis with the higher classification
results and the improved information-transfer-rates.
</summary>
    <author>
      <name>Zhenyu Cai</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Takeshi Yamada</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">APSIPA ASC 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2945v1</id>
    <updated>2012-10-10T15:00:00Z</updated>
    <published>2012-10-10T15:00:00Z</published>
    <title>The Spatial Real and Virtual Sound Stimuli Optimization for the Auditory
  BCI</title>
    <summary>  The paper presents results from a project aiming to create horizontally
distributed surround sound sources and virtual sound images as auditory BCI
(aBCI) stimuli. The purpose is to create evoked brain wave response patterns
depending on attended or ignored sound directions. We propose to use a modified
version of the vector based amplitude panning (VBAP) approach to achieve the
goal. The so created spatial sound stimulus system for the novel oddball aBCI
paradigm allows us to create a multi-command experimental environment with very
encouraging results reported in this paper. We also present results showing
that a modulation of the sound image depth changes also the subject responses.
Finally, we also compare the proposed virtual sound approach with the
traditional one based on real sound sources generated from the real loudspeaker
directions. The so obtained results confirm the hypothesis of the possibility
to modulate independently the brain responses to spatial types and depths of
sound sources which allows for the development of the novel multi-command aBCI.
</summary>
    <author>
      <name>Nozomu Nishikawa</name>
    </author>
    <author>
      <name>Yoshihiro Matsumoto</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">APSIPA ASC 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2942v2</id>
    <updated>2012-10-11T02:44:10Z</updated>
    <published>2012-10-10T14:57:01Z</published>
    <title>Vibrotactile Stimulus Frequency Optimization for the Haptic BCI
  Prototype</title>
    <summary>  The paper presents results from a psychophysical study conducted to optimize
vibrotactile stimuli delivered to subject finger tips in order to evoke the
somatosensory responses to be utilized next in a haptic brain computer
interface (hBCI) paradigm. We also present the preliminary EEG evoked responses
for the chosen stimulating frequency. The obtained results confirm our
hypothesis that the hBCI paradigm concept is valid and it will allow for rapid
stimuli presentation in order to improve information-transfer-rate (ITR) of the
BCI.
</summary>
    <author>
      <name>Hiromu Mori</name>
    </author>
    <author>
      <name>Yoshihiro Matsumito</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Victor Kryssanov</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 6th International Conference on Soft Computing and Intelligent
  Systems and The 13th International Symposium on Advanced Intelligent Systems,
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2943v1</id>
    <updated>2012-10-10T14:58:37Z</updated>
    <published>2012-10-10T14:58:37Z</published>
    <title>Auditory Steady-State Response Stimuli based BCI Application - The
  Optimization of the Stimuli Types and Lengths</title>
    <summary>  We propose a method for an improvement of auditory BCI (aBCI) paradigm based
on a combination of ASSR stimuli optimization by choosing the subjects' best
responses to AM-, flutter-, AM/FM and click-envelope modulated sounds. As the
ASSR response features we propose pairwise phase-locking-values calculated from
the EEG and next classified using binary classifier to detect attended and
ignored stimuli. We also report on a possibility to use the stimuli as short as
half a second, which is a step forward in ASSR based aBCI. The presented
results are helpful for optimization of the aBCI stimuli for each subject.
</summary>
    <author>
      <name>Yoshihiro Matsumoto</name>
    </author>
    <author>
      <name>Nozomu Nishikawa</name>
    </author>
    <author>
      <name>Takeshi Yamada</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">APSIPA ASC 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.6598v2</id>
    <updated>2012-12-08T08:07:53Z</updated>
    <published>2012-05-30T09:29:44Z</published>
    <title>Retinal metric: a stimulus distance measure derived from population
  neural responses</title>
    <summary>  The ability of the organism to distinguish between various stimuli is limited
by the structure and noise in the population code of its sensory neurons. Here
we infer a distance measure on the stimulus space directly from the recorded
activity of 100 neurons in the salamander retina. In contrast to previously
used measures of stimulus similarity, this "neural metric" tells us how
distinguishable a pair of stimulus clips is to the retina, given the noise in
the neural population response. We show that the retinal distance strongly
deviates from Euclidean, or any static metric, yet has a simple structure: we
identify the stimulus features that the neural population is jointly sensitive
to, and show the SVM-like kernel function relating the stimulus and neural
response spaces. We show that the non-Euclidean nature of the retinal distance
has important consequences for neural decoding.
</summary>
    <author>
      <name>Gašper Tkačik</name>
    </author>
    <author>
      <name>Einat Granot-Atedgi</name>
    </author>
    <author>
      <name>Ronen Segev</name>
    </author>
    <author>
      <name>Elad Schneidman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.058104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.058104" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, to appear in Phys Rev Lett</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys Rev Lett 110 (2013): 058104</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.6598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.6598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3574v1</id>
    <updated>2012-01-17T17:55:18Z</updated>
    <published>2012-01-17T17:55:18Z</published>
    <title>Noninvasive Realistic Stimulation/Recording of Freely Swimming Weakly
  Electric Fish: Movement Detection and Discharge Entropy to Infer Fish
  Behavior</title>
    <summary>  Weakly electric fish are unique models in Neuroscience allowing
experimentalists to access, with non invasive techniques,a central nervous
system generated spatio-temporal electric pattern of pulses with roles in at
least two complex and not yet completely understood
abilities:electrocommunication and electrolocation. We developed an apparatus
to allow realistic stimulation and simultaneous recording of electric pulses in
freely moving Gymnotus carapo for very long periods-several days. Voltage time
series from a 3dimensional array of sensitive dipoles that detects electric
field in several positions underwater were digitized and home made real-time
software allowed reliable recording of pulse timestamps,independently of the
fish's position,and also to infer fish movement. A stimulus fish was mimicked
by a dipole electrode that reproduced the voltage time series of real
conspecific pulses,but according to timestamp sequences previously recorded
that could be chosen by the experimenter. Two independent variables were used
to analyze fish behavior:the entropy of the recorded timestamp sequences and
the movement of the fish inferred from pulse amplitude variability at each
detection dipole. All fish presented very long transient exploratory behavior
(about 8hours) when exposed to a new environment in the absence of stimuli.
After the transient there were several intervals(5min-2hours),in which entropy
vanished and no movement was observed, that could be associated with behavioral
sleeping. Our experiments also revealed that fish are able to discriminate
between real and random stimuli distributions by changing the timing
probability of the next discharge. Moreover,most fish presented behavioral
sleep periods when the artificial fish timestamp sequence was random,but no
fish showed any behavioral sleep period when the artificial fish fired
according to a real fish timestamp series.
</summary>
    <author>
      <name>Caroline Garcia Forlim</name>
    </author>
    <author>
      <name>Reynaldo Daniel Pinto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.3574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0592v2</id>
    <updated>2013-07-09T22:10:55Z</updated>
    <published>2012-12-04T00:36:51Z</published>
    <title>The joint use of the tangential electric field and surface Laplacian in
  EEG classification</title>
    <summary>  This paper discusses the use of the scalp electric field to decode
EEG-recorded brain processes. Instead of using bipolar measurements, the scalp
electric field is described as a 3-vector field whose orthogonal components are
obtained from the data through spline differentiation. The method was tested in
the context of brainwave recognition with experiments involving brain
representation of spoken phonemes, visual images, and mental images. The
practical effect of improvements in recognition rates was assessed by
estimating effect sizes and confidence intervals, the results suggesting a good
prospect for other applications.
</summary>
    <author>
      <name>C. G. Carvalhaes</name>
    </author>
    <author>
      <name>J. Acacio de Barros</name>
    </author>
    <author>
      <name>M. Perreau-Guimarães</name>
    </author>
    <author>
      <name>P. Suppes</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10548-013-0305-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10548-013-0305-y" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0592v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0592v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5783v1</id>
    <updated>2012-02-26T17:28:02Z</updated>
    <published>2012-02-26T17:28:02Z</published>
    <title>On the Fitzhugh-Nagumo model</title>
    <summary>  The initial value problem P0, in all of the space, for the spatio - temporal
FitzHugh - Nagumo equations is analyzed. When the reaction kinetics of the
model can be outlined by means of piecewise linear approximations, then the
solution of P0 is explicitly obtained. For periodic initial data are possible
damped travelling waves and their speed of propagation is evaluated. The
results imply applications also to the non linear case.
</summary>
    <author>
      <name>M. De Angelis</name>
    </author>
    <author>
      <name>P. Renno</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings WASCOM 2007 XIV International Conference on Waves and
  Stability in Continuous Media World Scientific Publishing Company 2008,
  193-198</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.5783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3161v1</id>
    <updated>2011-10-14T09:42:06Z</updated>
    <published>2011-10-14T09:42:06Z</published>
    <title>Intrinsic adaptation in autonomous recurrent neural networks</title>
    <summary>  A massively recurrent neural network responds on one side to input stimuli
and is autonomously active, on the other side, in the absence of sensory
inputs. Stimuli and information processing depends crucially on the qualia of
the autonomous-state dynamics of the ongoing neural activity. This default
neural activity may be dynamically structured in time and space, showing
regular, synchronized, bursting or chaotic activity patterns.
  We study the influence of non-synaptic plasticity on the default dynamical
state of recurrent neural networks. The non-synaptic adaption considered acts
on intrinsic neural parameters, such as the threshold and the gain, and is
driven by the optimization of the information entropy. We observe, in the
presence of the intrinsic adaptation processes, three distinct and globally
attracting dynamical regimes, a regular synchronized, an overall chaotic and an
intermittent bursting regime. The intermittent bursting regime is characterized
by intervals of regular flows, which are quite insensitive to external stimuli,
interseeded by chaotic bursts which respond sensitively to input signals. We
discuss these finding in the context of self-organized information processing
and critical brain dynamics.
</summary>
    <author>
      <name>Dimitrije Markovic</name>
    </author>
    <author>
      <name>Claudius Gros</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00232</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00232" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation February 2012, Vol. 24, No. 2: 523-540</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.3161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.6565v1</id>
    <updated>2011-10-29T22:58:02Z</updated>
    <published>2011-10-29T22:58:02Z</published>
    <title>Heterogeneity-Induced Inhibitory Coherence in An Ensemble of
  Subthreshold and Suprathreshold Type-I Neurons</title>
    <summary>  We study inhibitory coherence (i.e., collective coherence by synaptic
inhibition) in an ensemble of globally-coupled type-I neurons which can fire at
arbitrarily low frequencies. No inhibitory coherence is observed in a
homogeneous ensemble composed of only subthreshold neurons (which cannot fire
spontaneously without noise). By increasing the fraction of (spontaneously
firing) suprathreshold neurons $P_{supra}$, heterogeneity-induced inhibitory
coherence is investigated in a heterogeneous ensemble of subthreshold and
suprathreshold neurons. As $P_{supra}$ passes a threshold $P_{supra}^*$,
suprathreshold neurons begin to synchronize and play the role of coherent
inhibitors for the emergence of inhibitory coherence. Thus,
regularly-oscillating ensemble-averaged global potential appears for $P_{supra}
&gt; P_{supra}^*$. For this coherent case suprathreshold neurons exhibit coherent
mixed-mode oscillations with a fast subthreshold (small-amplitude) hopping
frequency and a lower spiking frequency. By virtue of their coherent
inhibition, sparsely synchronized suprathreshold neurons suppress noisy
activities of subthreshold neurons. Thus, only coherent subthreshold hoppings
appear in the individual potentials of subthreshold neurons. We also
characterize the inhibitory coherence in terms of the "statistical-mechanical"
spike-based and correlation-based measures and find that the degree of
inhibitory coherence increases with increasing $P_{supra}$ for $P_{supra} &gt;
P_{supra}^*$. Finally, effect of sparse randomness of synaptic connectivity on
the inhibitory coherence and universality of the heterogeneity-induced
inhibitory coherence are briefly discussed.
</summary>
    <author>
      <name>Duk-Geun Hong</name>
    </author>
    <author>
      <name>Sang-Yoon Kim</name>
    </author>
    <author>
      <name>Woochang Lim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.6565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.6565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.2660v1</id>
    <updated>2011-11-11T04:28:28Z</updated>
    <published>2011-11-11T04:28:28Z</published>
    <title>Magnetic Resonance Connectome Automated Pipeline</title>
    <summary>  This manuscript presents a novel, tightly integrated pipeline for estimating
a connectome, which is a comprehensive description of the neural circuits in
the brain. The pipeline utilizes magnetic resonance imaging (MRI) data to
produce a high-level estimate of the structural connectivity in the human
brain. The Magnetic Resonance Connectome Automated Pipeline (MRCAP) is
efficient and its modular construction allows researchers to modify algorithms
to meet their specific requirements. The pipeline has been validated and over
200 connectomes have been processed and analyzed to date.
  This tool enables the prediction and assessment of various cognitive
covariates, and this research is applicable to a variety of domains and
applications. MRCAP will enable MR connectomes to be rapidly generated to
ultimately help spur discoveries about the structure and function of the human
brain.
</summary>
    <author>
      <name>William R. Gray</name>
    </author>
    <author>
      <name>John A. Bogovic</name>
    </author>
    <author>
      <name>Joshua T. Vogelstein</name>
    </author>
    <author>
      <name>Bennett A. Landman</name>
    </author>
    <author>
      <name>Jerry L. Prince</name>
    </author>
    <author>
      <name>R. Jacob Vogelstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.2660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.2660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.7196v1</id>
    <updated>2012-07-31T09:42:31Z</updated>
    <published>2012-07-31T09:42:31Z</published>
    <title>Binary Willshaw learning yields high synaptic capacity for long-term
  familiarity memory</title>
    <summary>  We investigate from a computational perspective the efficiency of the
Willshaw synaptic update rule in the context of familiarity discrimination, a
binary-answer, memory-related task that has been linked through psychophysical
experiments with modified neural activity patterns in the prefrontal and
perirhinal cortex regions. Our motivation for recovering this well-known
learning prescription is two-fold: first, the switch-like nature of the induced
synaptic bonds, as there is evidence that biological synaptic transitions might
occur in a discrete stepwise fashion. Second, the possibility that in the
mammalian brain, unused, silent synapses might be pruned in the long-term.
Besides the usual pattern and network capacities, we calculate the synaptic
capacity of the model, a recently proposed measure where only the functional
subset of synapses is taken into account. We find that in terms of network
capacity, Willshaw learning is strongly affected by the pattern coding rates,
which have to be kept fixed and very low at any time to achieve a non-zero
capacity in the large network limit. The information carried per functional
synapse, however, diverges and is comparable to that of the pattern association
case, even for more realistic moderately low activity levels that are a
function of network size.
</summary>
    <author>
      <name>João Sacramento</name>
    </author>
    <author>
      <name>Andreas Wichert</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00422-012-0488-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00422-012-0488-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Biological Cybernetics, vol. 106, no. 2, pp. 123-133, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.7196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.7196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.0566v2</id>
    <updated>2011-07-20T15:57:22Z</updated>
    <published>2011-02-02T21:10:02Z</published>
    <title>Model Cortical Association Fields Account for the Time Course and
  Dependence on Target Complexity of Human Contour Perception</title>
    <summary>  Can lateral connectivity in the primary visual cortex account for the time
dependence and intrinsic task difficulty of human contour detection? To answer
this question, we created a synthetic image set that prevents sole reliance on
either low-level visual features or high-level context for the detection of
target objects. Rendered images consist of smoothly varying, globally aligned
contour fragments (amoebas) distributed among groups of randomly rotated
fragments (clutter). The time course and accuracy of amoeba detection by humans
was measured using a two-alternative forced choice protocol with self-reported
confidence and variable image presentation time (20-200 ms), followed by an
image mask optimized so as to interrupt visual processing. Measured
psychometric functions were well fit by sigmoidal functions with exponential
time constants of 30-91 ms, depending on amoeba complexity. Key aspects of the
psychophysical experiments were accounted for by a computational network model,
in which simulated responses across retinotopic arrays of orientation-selective
elements were modulated by cortical association fields, represented as
multiplicative kernels computed from the differences in pairwise edge
statistics between target and distractor images. Comparing the experimental and
the computational results suggests that each iteration of the lateral
interactions takes at least 37.5 ms of cortical processing time. Our results
provide evidence that cortical association fields between orientation selective
elements in early visual areas can account for important temporal and
task-dependent aspects of the psychometric curves characterizing human contour
perception, with the remaining discrepancies postulated to arise from the
influence of higher cortical areas.
</summary>
    <author>
      <name>Vadas Gintautas</name>
    </author>
    <author>
      <name>Michael I. Ham</name>
    </author>
    <author>
      <name>Benjamin Kunsberg</name>
    </author>
    <author>
      <name>Shawn Barr</name>
    </author>
    <author>
      <name>Steven P. Brumby</name>
    </author>
    <author>
      <name>Craig Rasmussen</name>
    </author>
    <author>
      <name>John S. George</name>
    </author>
    <author>
      <name>Ilya Nemenman</name>
    </author>
    <author>
      <name>Luis M. A. Bettencourt</name>
    </author>
    <author>
      <name>Garrett T. Kenyon</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002162</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002162" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput Biol 7(10): e1002162, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.0566v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.0566v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6573v1</id>
    <updated>2011-11-28T20:23:29Z</updated>
    <published>2011-11-28T20:23:29Z</published>
    <title>Neural integrators for decision making: A favorable tradeoff between
  robustness and sensitivity</title>
    <summary>  A key step in many perceptual decision tasks is the integration of sensory
inputs over time, but fundamental questions remain about how this is
accomplished in neural circuits. One possibility is to balance decay modes of
membranes and synapses with recurrent excitation. To allow integration over
long timescales, however, this balance must be precise; this is known as the
fine tuning problem. The need for fine tuning can be overcome via a
ratchet-like mechanism, in which momentary inputs must be above a preset limit
to be registered by the circuit. The degree of this ratcheting embodies a
tradeoff between sensitivity to the input stream and robustness against
parameter mistuning.
  The goal of our study is to analyze the consequences of this tradeoff for
decision making performance. For concreteness, we focus on the well-studied
random dot motion discrimination task. For stimulus parameters constrained by
experimental data, we find that loss of sensitivity to inputs has surprisingly
little cost for decision performance. This leads robust integrators to
performance gains when feedback becomes mistuned. Moreover, we find that
substantially robust and mistuned integrator models remain consistent with
chronometric and accuracy functions found in experiments. We explain our
findings via sequential analysis of the momentary and integrated signals, and
discuss their implication: robust integrators may be surprisingly well-suited
to subserve the basic function of evidence integration in many cognitive tasks.
</summary>
    <author>
      <name>Nicholas Cain</name>
    </author>
    <author>
      <name>Andrea K. Barreiro</name>
    </author>
    <author>
      <name>Michael Shadlen</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5279v1</id>
    <updated>2011-03-28T04:22:50Z</updated>
    <published>2011-03-28T04:22:50Z</published>
    <title>Event-driven simulations of a plastic, spiking neural network</title>
    <summary>  We consider a fully-connected network of leaky integrate-and-fire neurons
with spike-timing-dependent plasticity. The plasticity is controlled by a
parameter representing the expected weight of a synapse between neurons that
are firing randomly with the same mean frequency. For low values of the
plasticity parameter, the activities of the system are dominated by noise,
while large values of the plasticity parameter lead to self-sustaining activity
in the network. We perform event-driven simulations on finite-size networks
with up to 128 neurons to find the stationary synaptic weight conformations for
different values of the plasticity parameter. In both the low and high activity
regimes, the synaptic weights are narrowly distributed around the plasticity
parameter value consistent with the predictions of mean-field theory. However,
the distribution broadens in the transition region between the two regimes,
representing emergent network structures. Using a pseudophysical approach for
visualization, we show that the emergent structures are of "path" or "hub"
type, observed at different values of the plasticity parameter in the
transition region.
</summary>
    <author>
      <name>Chun-Chung Chen</name>
    </author>
    <author>
      <name>David Jasnow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.84.031908</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.84.031908" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 84, 031908 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.5279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5434v1</id>
    <updated>2012-02-24T12:38:09Z</updated>
    <published>2012-02-24T12:38:09Z</published>
    <title>Can humans see beyond intensity images?</title>
    <summary>  The human's visual system detect intensity images. Quite interesting,
detector systems have shown the existence of different kind of images. Among
them, images obtained by two detectors (detector array or spatially scanning
detector) capturing signals within short window times may reveal a "hidden"
image not contained in either isolated detector: Information on this image
depend on the two detectors simultaneously. In general, they are called
"high-order" images because they may depend on more than two electric fields.
Intensity images depend on the square of magnitude of the light's electric
field. Can the human visual sensory system perceive high-order images as well?
This paper proposes a way to test this idea. A positive answer could give new
insights on the "visual-conscience" machinery, opening a new sensory channel
for humans. Applications could be devised, e.g., head position sensing, privacy
in communications at visual ranges and many others.
</summary>
    <author>
      <name>Geraldo A. Barbosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5688v1</id>
    <updated>2012-11-24T17:52:22Z</updated>
    <published>2012-11-24T17:52:22Z</published>
    <title>Neural networks with dynamical synapses: from mixed-mode oscillations
  and spindles to chaos</title>
    <summary>  Understanding of short-term synaptic depression (STSD) and other forms of
synaptic plasticity is a topical problem in neuroscience. Here we study the
role of STSD in the formation of complex patterns of brain rhythms. We use a
cortical circuit model of neural networks composed of irregular spiking
excitatory and inhibitory neurons having type 1 and 2 excitability and
stochastic dynamics. In the model, neurons form a sparsely connected network
and their spontaneous activity is driven by random spikes representing synaptic
noise. Using simulations and analytical calculations, we found that if the STSD
is absent, the neural network shows either asynchronous behavior or regular
network oscillations depending on the noise level. In networks with STSD,
changing parameters of synaptic plasticity and the noise level, we observed
transitions to complex patters of collective activity: mixed-mode and spindle
oscillations, bursts of collective activity, and chaotic behaviour.
Interestingly, these patterns are stable in a certain range of the parameters
and separated by critical boundaries. Thus, the parameters of synaptic
plasticity can play a role of control parameters or switchers between different
network states. However, changes of the parameters caused by a disease may lead
to dramatic impairment of ongoing neural activity. We analyze the chaotic
neural activity by use of the 0-1 test for chaos (Gottwald, G. &amp; Melbourne, I.,
2004) and show that it has a collective nature.
</summary>
    <author>
      <name>K. -E. Lee</name>
    </author>
    <author>
      <name>A. V. Goltsev</name>
    </author>
    <author>
      <name>M. A. Lopes</name>
    </author>
    <author>
      <name>J. F. F. Mendes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, Proceedings of 12th Granada Seminar, September 17-21, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.5688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3596v3</id>
    <updated>2012-06-08T01:26:57Z</updated>
    <published>2012-03-16T01:07:40Z</published>
    <title>Formation of antiwaves in gap-junction-coupled chains of neurons</title>
    <summary>  Using network models consisting of gap junction coupled Wang-Buszaki neurons,
we demonstrate that it is possible to obtain not only synchronous activity
between neurons but also a variety of constant phase shifts between 0 and \pi.
We call these phase shifts intermediate stable phaselocked states. These phase
shifts can produce a large variety of wave-like activity patterns in
one-dimensional chains and two-dimensional arrays of neurons, which can be
studied by reducing the system of equations to a phase model. The 2\pi periodic
coupling functions of these models are characterized by prominent higher order
terms in their Fourier expansion, which can be varied by changing model
parameters. We study how the relative contribution of the odd and even terms
affect what solutions are possible, the basin of attraction of those solutions
and their stability. These models may be applicable to the spinal central
pattern generators of the dogfish and also to the developing neocortex of the
neonatal rat.
</summary>
    <author>
      <name>Alexander Urban</name>
    </author>
    <author>
      <name>Bard Ermentrout</name>
    </author>
    <link href="http://arxiv.org/abs/1203.3596v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3596v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1800v1</id>
    <updated>2012-06-08T15:52:50Z</updated>
    <published>2012-06-08T15:52:50Z</published>
    <title>Compressive neural representation of sparse, high-dimensional
  probabilities</title>
    <summary>  This paper shows how sparse, high-dimensional probability distributions could
be represented by neurons with exponential compression. The representation is a
novel application of compressive sensing to sparse probability distributions
rather than to the usual sparse signals. The compressive measurements
correspond to expected values of nonlinear functions of the probabilistically
distributed variables. When these expected values are estimated by sampling,
the quality of the compressed representation is limited only by the quality of
sampling. Since the compression preserves the geometric structure of the space
of sparse probability distributions, probabilistic computation can be performed
in the compressed domain. Interestingly, functions satisfying the requirements
of compressive sensing can be implemented as simple perceptrons. If we use
perceptrons as a simple model of feedforward computation by neurons, these
results show that the mean activity of a relatively small number of neurons can
accurately represent a high-dimensional joint distribution implicitly, even
without accounting for any noise correlations. This comprises a novel
hypothesis for how neurons could encode probabilities in the brain.
</summary>
    <author>
      <name>Xaq Pitkow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5944v1</id>
    <updated>2012-01-28T11:13:54Z</updated>
    <published>2012-01-28T11:13:54Z</published>
    <title>A Neuron Based Switch: Application to Low Power Mixed Signal Circuits</title>
    <summary>  Human brain is functionally and physically complex. This 'complexity' can be
seen as a result of biological design process involving extensive use of
concepts such as modularity and hierarchy. Over the past decade, deeper
insights into the functioning of cortical neurons have led to the development
of models that can be implemented in hardware. The implementation of
biologically inspired spiking neuron networks in silicon can provide solutions
to difficult cognitive tasks. The work reported in this paper is an application
of a VLSI cortical neuron model for low power design. The VLSI implementation
shown in this paper is based on the spike and burst firing pattern of cortex
and follows the Izhikevich neuron model. This model is applied to a DC
differential amplifier as practical application of power reduction
</summary>
    <author>
      <name>Alex Pappachen James</name>
    </author>
    <author>
      <name>Fayaz Shariff</name>
    </author>
    <author>
      <name>Akshay Kumar Maan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2010 International Conference on Advances in Computer Engineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.5944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1621v1</id>
    <updated>2011-07-08T13:03:41Z</updated>
    <published>2011-07-08T13:03:41Z</published>
    <title>Competing synapses with two timescales: a basis for learning and
  forgetting</title>
    <summary>  Competitive dynamics are thought to occur in many processes of learning
involving synaptic plasticity. Here we show, in a game theory-inspired model of
synaptic interactions, that the competition between synapses in their weak and
strong states gives rise to a natural framework of learning, with the
prediction of memory inherent in a timescale for `forgetting' a learned signal.
Among our main results is the prediction that memory is optimized if the weak
synapses are really weak, and the strong synapses are really strong. Our work
admits of many extensions and possible experiments to test its validity, and in
particular might complement an existing model of reaching, which has strong
experimental support.
</summary>
    <author>
      <name>Gaurang Mahajan</name>
    </author>
    <author>
      <name>Anita Mehta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, to appear in Europhysics Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.1621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2512v2</id>
    <updated>2011-12-28T11:59:26Z</updated>
    <published>2011-05-12T15:53:56Z</published>
    <title>Coherent periodic activity in excitatory Erdos-Renyi neural networks:The
  role of network connectivity</title>
    <summary>  We consider an excitatory random network of leaky integrate-and-fire pulse
coupled neurons. The neurons are connected as in a directed Erd\"os-Renyi graph
with average connectivity $&lt;k&gt;$ scaling as a power law with the number of
neurons in the network. The scaling is controlled by a parameter $\gamma$,
which allows to pass from massively connected to sparse networks and therefore
to modify the topology of the system. At a macroscopic level we observe two
distinct dynamical phases: an Asynchronous State (AS) corresponding to a
desynchronized dynamics of the neurons and a Partial Synchronization (PS)
regime associated with a coherent periodic activity of the network. At low
connectivity the system is in an AS, while PS emerges above a certain critical
average connectivity $&lt;k&gt;_c$. For sufficiently large networks, $&lt;k&gt;_c$
saturates to a constant value suggesting that a minimal average connectivity is
sufficient to observe coherent activity in systems of any size irrespectively
of the kind of considered network: sparse or massively connected. However, this
value depends on the nature of the synapses: reliable or unreliable. For
unreliable synapses the critical value required to observe the onset of
macroscopic behaviors is noticeably smaller than for reliable synaptic
transmission. Due to the disorder present in the system, for finite number of
neurons we have inhomogeneities in the neuronal behaviors, inducing a weak form
of chaos, which vanishes in the thermodynamic limit. In such a limit the
disordered systems exhibit regular (non chaotic) dynamics and their properties
correspond to that of a homogeneous fully connected network for any
$\gamma$-value. Apart for the peculiar exception of sparse networks, which
remain intrinsically inhomogeneous at any system size.
</summary>
    <author>
      <name>Lorenzo Tattini</name>
    </author>
    <author>
      <name>Simona Olmi</name>
    </author>
    <author>
      <name>Alessandro Torcini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4723839</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4723839" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 11 figures, submitted to Chaos</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 22, 023133 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.2512v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2512v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5046v1</id>
    <updated>2012-09-23T09:59:56Z</updated>
    <published>2012-09-23T09:59:56Z</published>
    <title>Diversity and noise effects in a model of homeostatic regulation of the
  sleep-wake cycle</title>
    <summary>  Recent advances in sleep neurobiology have allowed development of
physiologically based mathematical models of sleep regulation that account for
the neuronal dynamics responsible for the regulation of sleep-wake cycles and
allow detailed examination of the underlying mechanisms. Neuronal systems in
general, and those involved in sleep regulation in particular, are noisy and
heterogeneous by their nature. It has been shown in various systems that
certain levels of noise and diversity can significantly improve signal
encoding. However, these phenomena, especially the effects of diversity, are
rarely considered in the models of sleep regulation. The present paper is
focused on a neuron-based physiologically motivated model of sleep-wake cycles
that proposes a novel mechanism of the homeostatic regulation of sleep based on
the dynamics of a wake-promoting neuropeptide orexin. Here this model is
generalized by the introduction of intrinsic diversity and noise in the
orexin-producing neurons in order to study the effect of their presence on the
sleep-wake cycle. A quantitative measure of the quality of a sleep-wake cycle
is introduced and used to systematically study the generalized model for
different levels of noise and diversity. The model is shown to exhibit a clear
diversity-induced resonance: that is, the best wake-sleep cycle turns out to
correspond to an intermediate level of diversity at the synapses of the
orexin-producing neurons. On the other hand only a mild evidence of stochastic
resonance is found when the level of noise is varied. These results show that
disorder, especially in the form of quenched diversity, can be a key-element
for an efficient or optimal functioning of the homeostatic regulation of the
sleep-wake cycle. Furthermore, this study provides an example of constructive
role of diversity in a neuronal system that can be extended beyond the system
studied here.
</summary>
    <author>
      <name>Marco Patriarca</name>
    </author>
    <author>
      <name>Svetlana Postnova</name>
    </author>
    <author>
      <name>Hans A. Braun</name>
    </author>
    <author>
      <name>Emilio Hernández-García</name>
    </author>
    <author>
      <name>Raúl Toral</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002650</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002650" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 12 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">M. Patriarca, S. Postnova, H.A. Braun, E. Hern\'andez-Garc\'ia, R.
  Toral, Diversity and Noise Effects in a Model of Homeostatic Regulation of
  the Sleep-Wake Cycle, PLoS Comput. Biol. 8(8): e1002650 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0426v2</id>
    <updated>2012-11-21T14:30:49Z</updated>
    <published>2012-09-03T18:37:36Z</published>
    <title>A biophysical observation model for field potentials of networks of
  leaky integrate-and-fire neurons</title>
    <summary>  We present a biophysical approach for the coupling of neural network activity
as resulting from proper dipole currents of cortical pyramidal neurons to the
electric field in extracellular fluid. Starting from a reduced threecompartment
model of a single pyramidal neuron, we derive an observation model for
dendritic dipole currents in extracellular space and thereby for the dendritic
field potential that contributes to the local field potential of a neural
population. This work aligns and satisfies the widespread dipole assumption
that is motivated by the "open-field" configuration of the dendritic field
potential around cortical pyramidal cells. Our reduced three-compartment scheme
allows to derive networks of leaky integrate-and-fire models, which facilitates
comparison with existing neural network and observation models. In particular,
by means of numerical simulations we compare our approach with an ad hoc model
by Mazzoni et al. [Mazzoni, A., S. Panzeri, N. K. Logothetis, and N. Brunel
(2008). Encoding of naturalistic stimuli by local field potential spectra in
networks of excitatory and inhibitory neurons. PLoS Computational Biology 4
(12), e1000239], and conclude that our biophysically motivated approach yields
substantial improvement.
</summary>
    <author>
      <name>Peter beim Graben</name>
    </author>
    <author>
      <name>Serafim Rodrigues</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fncom.2012.00100</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fncom.2012.00100" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.0426v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0426v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8295v1</id>
    <updated>2012-10-31T11:01:56Z</updated>
    <published>2012-10-31T11:01:56Z</published>
    <title>Identification of criticality in neuronal avalanches: I. A theoretical
  investigation of the non-driven case</title>
    <summary>  In this paper we study a simple model of a purely excitatory neural network
that, by construction, operates at a critical point. This model allows us to
consider various markers of criticality and illustrate how they should perform
in a finite-size system. By calculating the exact distribution of avalanche
sizes we are able to show that, over a limited range of avalanche sizes which
we precisely identify, the distribution has scale free properties but is not a
power law. This suggests that it would be inappropriate to dismiss a system as
not being critical purely based on an inability to rigorously fit a power law
distribution as has been recently advocated. In assessing whether a system,
especially a finite-size one, is critical it is thus important to consider
other possible markers. We illustrate one of these by showing the divergence of
susceptibility as the critical point of the system is approached. Finally, we
provide evidence that power laws may underlie other observables of the system,
that may be more amenable to robust experimental assessment.
</summary>
    <author>
      <name>Timothy J. Taylor</name>
    </author>
    <author>
      <name>Caroline Hartley</name>
    </author>
    <author>
      <name>Péter L. Simon</name>
    </author>
    <author>
      <name>Istvan Z Kiss</name>
    </author>
    <author>
      <name>Luc Berthouze</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/2190-8567-3-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/2190-8567-3-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 10 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Mathematical Neuroscience 2013, 3:5</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.8295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5428v1</id>
    <updated>2012-01-26T02:14:16Z</updated>
    <published>2012-01-26T02:14:16Z</published>
    <title>A point process framework for modeling electrical stimulation of the
  auditory nerve</title>
    <summary>  Model-based studies of auditory nerve responses to electrical stimulation can
provide insight into the functioning of cochlear implants. Ideally, these
studies can identify limitations in sound processing strategies and lead to
improved methods for providing sound information to cochlear implant users. To
accomplish this, models must accurately describe auditory nerve spiking while
avoiding excessive complexity that would preclude large-scale simulations of
populations of auditory nerve fibers and obscure insight into the mechanisms
that influence neural encoding of sound information. In this spirit, we develop
a point process model of the auditory nerve that provides a compact and
accurate description of neural responses to electric stimulation. Inspired by
the framework of generalized linear models, the proposed model consists of a
cascade of linear and nonlinear stages. We show how each of these stages can be
associated with biophysical mechanisms and related to models of neuronal
dynamics. Moreover, we derive a semi-analytical procedure that uniquely
determines each parameter in the model on the basis of fundamental statistics
from recordings of single fiber responses to electric stimulation, including
threshold, relative spread, jitter, and chronaxie. The model also accounts for
refractory and summation effects that influence the responses of auditory nerve
fibers to high pulse rate stimulation. Throughout, we compare model predictions
to published physiological data and explain differences in auditory nerve
responses to high and low pulse rate stimulation. We close by performing an
ideal observer analysis of simulated spike trains in response to sinusoidally
amplitude modulated stimuli and find that carrier pulse rate does not affect
modulation detection thresholds.
</summary>
    <author>
      <name>Joshua H. Goldwyn</name>
    </author>
    <author>
      <name>Jay T. Rubinstein</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 title page, 27 manuscript pages, 14 figures, 1 table, 1 appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.5428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3537v1</id>
    <updated>2012-06-15T18:34:43Z</updated>
    <published>2012-06-15T18:34:43Z</published>
    <title>Motif Statistics and Spike Correlations in Neuronal Networks</title>
    <summary>  Motifs are patterns of subgraphs of complex networks. We studied the impact
of such patterns of connectivity on the level of correlated, or synchronized,
spiking activity among pairs of cells in a recurrent network model of integrate
and fire neurons. For a range of network architectures, we find that the
pairwise correlation coefficients, averaged across the network, can be closely
approximated using only three statistics of network connectivity. These are the
overall network connection probability and the frequencies of two second-order
motifs: diverging motifs, in which one cell provides input to two others, and
chain motifs, in which two cells are connected via a third intermediary cell.
Specifically, the prevalence of diverging and chain motifs tends to increase
correlation. Our method is based on linear response theory, which enables us to
express spiking statistics using linear algebra, and a resumming technique,
which extrapolates from second order motifs to predict the overall effect of
coupling on network correlation. Our motif-based results seek to isolate the
effect of network architecture perturbatively from a known network state.
</summary>
    <author>
      <name>Yu Hu</name>
    </author>
    <author>
      <name>James Trousdale</name>
    </author>
    <author>
      <name>Kresimir Josic</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <link href="http://arxiv.org/abs/1206.3537v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3537v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3547v1</id>
    <updated>2011-10-17T00:55:18Z</updated>
    <published>2011-10-17T00:55:18Z</published>
    <title>A Theory of Consciousness Founded on Neurons That Behave Like Qubits</title>
    <summary>  This paper presents a hypothesis that consciousness is a natural result of
neurons that become connected recursively, and work synchronously between short
and long term memories. Such neurons demonstrate qubit-like properties, each
supporting a probabilistic combination of true and false at a given phase.
Advantages of qubits include probabilistic modifications of cues for searching
associations in long term memory, and controlled toggling for parallel,
reversible computations to prioritize multiple recalls and to facilitate
mathematical abilities.
</summary>
    <author>
      <name>John Robert Burger</name>
    </author>
    <link href="http://arxiv.org/abs/1110.3547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.0; I.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3229v2</id>
    <updated>2013-09-09T12:04:02Z</updated>
    <published>2012-10-11T13:28:23Z</published>
    <title>Firing statistics of inhibitory neuron with delayed feedback. II.
  Non-Markovian behavior</title>
    <summary>  The instantaneous state of a neural network consists of both the degree of
excitation of each neuron the network is composed of and positions of impulses
in communication lines between the neurons. In neurophysiological experiments,
the neuronal firing moments are registered, but not the state of communication
lines. But future spiking moments depend essentially on the past positions of
impulses in the lines. This suggests, that the sequence of intervals between
firing moments (inter-spike intervals, ISIs) in the network could be
non-Markovian.
  In this paper, we address this question for a simplest possible neural "net",
namely, a single inhibitory neuron with delayed feedback. The neuron receives
excitatory input from the driving Poisson stream and inhibitory impulses from
its own output through the feedback line. We obtain analytic expressions for
conditional probability density P(t_{n+1}| t_n,...,t_1,t_0), which gives the
probability to get an output ISI of duration t_{n+1} provided the previous
(n+1) output ISIs had durations t_n,...,t_1,t_0. It is proven exactly, that
P(t_{n+1}| t_n,...,t_1,t_0) does not reduce to P(t_{n+1}| t_n,...,t_1) for any
n&gt;=0. This means that the output ISIs stream cannot be represented as a Markov
chain of any finite order.
</summary>
    <author>
      <name>Kseniia Kravchuk</name>
    </author>
    <author>
      <name>Alexander Vidybida</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.biosystems.2013.02.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.biosystems.2013.02.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper was presented at the BIOCOMP2012 meeting at Vietri sul
  Mare, Italy. Paper contains 33 pages, including 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">BioSystems 112 (2013) 233-248</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.3229v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3229v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.1707v1</id>
    <updated>2011-02-08T20:10:46Z</updated>
    <published>2011-02-08T20:10:46Z</published>
    <title>Collinear features impair visual detection by rats</title>
    <summary>  We measure rats' ability to detect an oriented visual target grating located
between two flanking stimuli ("flankers"). Flankers varied in contrast,
orientation, angular position, and sign. Rats are impaired at detecting visual
targets with collinear flankers, compared to configurations where flankers
differ from the target in orientation or angular position. In particular, rats
are more likely to miss the target when flankers are collinear. The same
impairment is found even when the flanker luminance was sign-reversed relative
to the target. These findings suggest that contour alignment alters visual
processing in rats, despite their lack of orientation columns in visual cortex.
This is the first report that the arrangement of visual features relative to
each other affects visual behavior in rats. To provide a conceptual framework
for our findings, we relate our stimuli to a contrast normalization model of
early visual processing. We suggest a pattern-sensitive generalization of the
model which could account for a collinear deficit. These experiments were
performed using a novel method for automated high-throughput training and
testing of visual behavior in rodents.
</summary>
    <author>
      <name>Philip Meier</name>
    </author>
    <author>
      <name>Erik Flister</name>
    </author>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1167/11.3.22</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1167/11.3.22" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally; manuscript currently in
  peer review; this document includes main paper and supplementary materials</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Meier, P., Flister, E., &amp; Reinagel, P. (2011). Collinear features
  impair visual detection by rats. Journal of Vision,11(3):22,1-16</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.1707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.1707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3634v1</id>
    <updated>2011-03-18T14:41:39Z</updated>
    <published>2011-03-18T14:41:39Z</published>
    <title>Nonlocal mechanism for cluster synchronization in neural circuits</title>
    <summary>  The interplay between the topology of cortical circuits and synchronized
activity modes in distinct cortical areas is a key enigma in neuroscience. We
present a new nonlocal mechanism governing the periodic activity mode: the
greatest common divisor (GCD) of network loops. For a stimulus to one node, the
network splits into GCD-clusters in which cluster neurons are in zero-lag
synchronization. For complex external stimuli, the number of clusters can be
any common divisor. The synchronized mode and the transients to synchronization
pinpoint the type of external stimuli. The findings, supported by an
information mixing argument and simulations of Hodgkin Huxley population
dynamic networks with unidirectional connectivity and synaptic noise, call for
reexamining sources of correlated activity in cortex and shorter information
processing time scales.
</summary>
    <author>
      <name>I. Kanter</name>
    </author>
    <author>
      <name>E. Kopelowitz</name>
    </author>
    <author>
      <name>R. Vardi</name>
    </author>
    <author>
      <name>M. Zigzag</name>
    </author>
    <author>
      <name>W. Kinzel</name>
    </author>
    <author>
      <name>M. Abeles</name>
    </author>
    <author>
      <name>D. Cohen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/93/66001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/93/66001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pges, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPL 93, 66001 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.3634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0873v1</id>
    <updated>2012-03-05T11:51:23Z</updated>
    <published>2012-03-05T11:51:23Z</published>
    <title>Weber's law implies neural discharge more regular than a Poisson process</title>
    <summary>  Weber's law is one of the basic laws in psychophysics, but the link between
this psychophysical behavior and the neuronal response has not yet been
established. In this paper, we carried out an analysis on the spike train
statistics when Weber's law holds, and found that the efferent spike train of a
single neuron is less variable than a Poisson process. For population neurons,
Weber's law is satisfied only when the population size is small (&lt; 10 neurons).
However, if the population neurons share a weak correlation in their discharges
and individual neuronal spike train is more regular than a Poisson process,
Weber's law is true without any restriction on the population size. Biased
competition attractor network also demonstrates that the coefficient of
variation of interspike interval in the winning pool should be less than one
for the validity of Weber's law. Our work links Weber's law with neural firing
property quantitatively, shedding light on the relation between psychophysical
behavior and neuronal responses.
</summary>
    <author>
      <name>Jing Kang</name>
    </author>
    <author>
      <name>Jianhua Wu</name>
    </author>
    <author>
      <name>Anteo Smerieri</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures; European Journal of Neuroscience 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.0873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5862v1</id>
    <updated>2011-06-29T07:47:03Z</updated>
    <published>2011-06-29T07:47:03Z</published>
    <title>Comment on "Energy and information in Hodgkin-Huxley neurons"</title>
    <summary>  In a recent paper [A. Moujahid, A. d'Anjou, F. J. Torrealdea and F.
Torrealdea, Phys. Rev. E {\bf 83}, 031912 (2011)], the authors have calculated
the energy consumed in firing neurons by using the Hodgkin-Huxley (HH) model.
The energy consumption rate adopted for the HH model yields a {\it negative}
energy consumption meaning an energy transfer from an HH neuron to a source
which is physically strange, although they have interpreted it as a biochemical
energy cost. I propose an alternative expression for the power consumption
which leads to a {\it positive} energy consumed in an HH neuron, presenting
some model calculations which are compared to those in their paper.
</summary>
    <author>
      <name>Hideo Hasegawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Gakugei Univ.</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.5862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3632v1</id>
    <updated>2012-10-12T20:31:40Z</updated>
    <published>2012-10-12T20:31:40Z</published>
    <title>Critical brain dynamics at large scale</title>
    <summary>  Highly correlated brain dynamics produces synchronized states with no
behavioral value, while weakly correlated dynamics prevent information flow. In
between these states, the unique dynamical features of the critical state endow
the brain with properties which are fundamental for adaptive behavior. We
discuss the idea put forward two decades ago by Per Bak that the working brain
stays at an intermediate (critical) regime characterized by power-law
correlations. This proposal is now supported by a wide body of empirical
evidence at different scales demonstrating that the spatiotemporal brain
dynamics exhibit key signatures of critical dynamics, previously recognized in
other complex systems. The rationale behind this program is discussed in these
notes, followed by an account of the most recent results.
</summary>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In "Criticality in Neural Systems", Niebur E, Plenz D, Schuster HG.
  (eds.) 2013 (in press)</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6670v6</id>
    <updated>2013-07-01T20:48:29Z</updated>
    <published>2012-02-29T20:14:17Z</published>
    <title>Analysis of the stabilized supralinear network</title>
    <summary>  We study a rate-model neural network composed of excitatory and inhibitory
neurons in which neuronal input-output functions are power laws with a power
greater than 1, as observed in primary visual cortex. This supralinear
input-output function leads to supralinear summation of network responses to
multiple inputs for weak inputs. We show that for stronger inputs, which would
drive the excitatory subnetwork to instability, the network will dynamically
stabilize provided feedback inhibition is sufficiently strong. For a wide range
of network and stimulus parameters, this dynamic stabilization yields a
transition from supralinear to sublinear summation of network responses to
multiple inputs. We compare this to the dynamic stabilization in the "balanced
network", which yields only linear behavior. We more exhaustively analyze the
2-dimensional case of 1 excitatory and 1 inhibitory population. We show that in
this case dynamic stabilization will occur whenever the determinant of the
weight matrix is positive and the inhibitory time constant is sufficiently
small, and analyze the conditions for "supersaturation", or decrease of firing
rates with increasing stimulus contrast (which represents increasing input
firing rates). In work to be presented elsewhere, we have found that this
transition from supralinear to sublinear summation can explain a wide variety
of nonlinearities in cerebral cortical processing.
</summary>
    <author>
      <name>Yashar Ahmadian</name>
    </author>
    <author>
      <name>Daniel B. Rubin</name>
    </author>
    <author>
      <name>Kenneth D. Miller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">45 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation 25, 1994-2037 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.6670v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6670v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6489v1</id>
    <updated>2011-11-22T15:01:14Z</updated>
    <published>2011-11-22T15:01:14Z</published>
    <title>Stress hormones predict hyperbolic time-discount rates six months later
  in adults</title>
    <summary>  Objectives: Stress hormones have been associated with temporal discounting.
Although time-discount rate is shown to be stable over a long term, no study to
date examines whether individual differences in stress hormones could predict
individuals' time-discount rates in the relatively distant future (e.g., six
month later), which is of interest in neuroeconomics of stress-addiction
association.
  Methods: We assessed 87 participants' salivary stress hormone (cortisol,
cortisone, and alpha-amylase) levels and hyperbolic discounting of delayed
rewards consisting of three magnitudes, at the time-interval of six months. For
salivary steroid assays, we employed a liquid chromatography/ mass spectroscopy
(LC/MS) method. The correlations between the stress hormone levels and
time-discount rates were examined.
  Results: We observed that salivary alpha-amylase (sAA) levels were negatively
associated with time-discount rates in never-smokers. Notably, salivary levels
of stress steroids (i.e., cortisol and cortisone) negatively and positively
related to time-discount rates in men and women, respectively, in
never-smokers. Ever-smokers' discount rates were not predicted from these
stress hormone levels.
  Conclusions: Individual differences in stress hormone levels predict
impulsivity in temporal discounting in the future. There are sex differences in
the effect of stress steroids on temporal discounting; while there was no sex
defference in the relationship between sAA and temporal discounting.
</summary>
    <author>
      <name>Taiki Takahashi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Mizuho Shinada</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Keigo Inukai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Japan Society for the Promotion of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Shigehito Tanida</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Chisato Takahashi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Nobuhiro Mifune</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Japan Society for the Promotion of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Haruto Takagishi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Japan Society for the Promotion of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Yutaka Horita</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Japan Society for the Promotion of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Hirofumi Hashimoto</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Japan Society for the Promotion of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Kunihiro Yokota</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Tatsuya Kameda</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <author>
      <name>Toshio Yamagishi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuro Endocrinol Lett. 2010;31(5):616-621</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6488v1</id>
    <updated>2011-11-22T14:57:16Z</updated>
    <published>2011-11-22T14:57:16Z</published>
    <title>Neuroeconomics of suicide</title>
    <summary>  Suicidal behavior is a leading cause of injury and death worldwide. Suicide
has been associated with psychiatric illnesses such as depression and
schizophrenia, as well as economic uncertainty, and social/cultural factors.
This study proposes a neuroeconomic framework of suicide. Neuroeconomic
parameters (e.g., risk-attitude, probability weighting, time discounting in
intertemporal choice, and loss aversion) are predicted to be related to
suicidal behavior. Neurobiological and neuroendocrinological substrates such as
serotonin, dopamine, cortisol (HPA axis), nitric oxide, serum cholesterol,
epinephrine, norepinephrine, gonadal hormones (e.g., estradiol and
progesterone), dehydroepiandrosterone (DHEA) in brain regions such as the
orbitofrontal/dorsolateral prefrontal cortex and limbic regions (e.g., the
amygdala) may supposedly be related to the neuroeconomic parameters modulating
the risk of suicide. The present framework puts foundations for "molecular
neuroeconomics" of decision-making processes underlying suicidal behavior.
</summary>
    <author>
      <name>Taiki Takahashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages nofigure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuro Endocrinol Lett. 2011;32(4):400-404</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6471v1</id>
    <updated>2012-08-31T12:01:57Z</updated>
    <published>2012-08-31T12:01:57Z</published>
    <title>Motion-based prediction is sufficient to solve the aperture problem</title>
    <summary>  In low-level sensory systems, it is still unclear how the noisy information
collected locally by neurons may give rise to a coherent global percept. This
is well demonstrated for the detection of motion in the aperture problem: as
luminance of an elongated line is symmetrical along its axis, tangential
velocity is ambiguous when measured locally. Here, we develop the hypothesis
that motion-based predictive coding is sufficient to infer global motion. Our
implementation is based on a context-dependent diffusion of a probabilistic
representation of motion. We observe in simulations a progressive solution to
the aperture problem similar to physio-logy and behavior. We demonstrate that
this solution is the result of two underlying mechanisms. First, we demonstrate
the formation of a tracking behavior favoring temporally coherent features
independent of their texture. Second, we observe that incoherent features are
explained away, while coherent information diffuses progressively to the global
scale. Most previous models included ad hoc mechanisms such as end-stopped
cells or a selection layer to track specific luminance-based features as
necessary conditions to solve the aperture problem. Here, we have proved that
motion-based predictive coding, as it is implemented in this functional model,
is sufficient to solve the aperture problem. This solution may give insights
into the role of prediction underlying a large class of sensory computations.
</summary>
    <author>
      <name>Laurent U. Perrinet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INT</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume S. Masson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INT</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00332</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00332" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code to reproduce figures and supplementary material are available on
  the corresponding author's website at
  http://invibe.net/LaurentPerrinet/Publications/Perrinet12pred</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation 24, 10 (2012) 2726-50</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.6471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.5872v1</id>
    <updated>2011-07-29T05:18:38Z</updated>
    <published>2011-07-29T05:18:38Z</published>
    <title>Assessment of synchrony in multiple neural spike trains using loglinear
  point process models</title>
    <summary>  Neural spike trains, which are sequences of very brief jumps in voltage
across the cell membrane, were one of the motivating applications for the
development of point process methodology. Early work required the assumption of
stationarity, but contemporary experiments often use time-varying stimuli and
produce time-varying neural responses. More recently, many statistical methods
have been developed for nonstationary neural point process data. There has also
been much interest in identifying synchrony, meaning events across two or more
neurons that are nearly simultaneous at the time scale of the recordings. A
natural statistical approach is to discretize time, using short time bins, and
to introduce loglinear models for dependency among neurons, but previous use of
loglinear modeling technology has assumed stationarity. We introduce a succinct
yet powerful class of time-varying loglinear models by (a) allowing
individual-neuron effects (main effects) to involve time-varying intensities;
(b) also allowing the individual-neuron effects to involve autocovariation
effects (history effects) due to past spiking, (c) assuming excess synchrony
effects (interaction effects) do not depend on history, and (d) assuming all
effects vary smoothly across time.
</summary>
    <author>
      <name>Robert E. Kass</name>
    </author>
    <author>
      <name>Ryan C. Kelly</name>
    </author>
    <author>
      <name>Wei-Liem Loh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/10-AOAS429</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/10-AOAS429" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/10-AOAS429 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1262-1292</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.5872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.5872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2933v1</id>
    <updated>2012-01-13T20:54:03Z</updated>
    <published>2012-01-13T20:54:03Z</published>
    <title>A race model for singular olfactory receptor expression</title>
    <summary>  In vertebrates, olfactory sensory neurons choose only one olfactory receptor
to produce out of ~2000 possibilities. The mechanism for how this singular
receptor expression occurs is unknown. Here we propose a mechanism that can
stochastically select a single gene out of a large number of possibilities. In
this model, receptor genes compete for a limited pool of transcription factors
(TFs). The gene that recruits a target number of TFs is selected for
expression. To support this mechanism, we have attempted to detect repeated
motifs within known sequences of mouse olfactory receptor promoters. We find
motifs that are significantly overrepresented in olfactory versus other gene
promoters. We identify possible TFs that can target these motifs. Our model
suggests that a small number of TFs can control the selection of a single gene
out of ~2000 possibilities.
</summary>
    <author>
      <name>Brian E. Kolterman</name>
    </author>
    <author>
      <name>Ivan Iossifov</name>
    </author>
    <author>
      <name>Alexei A. Koulakov</name>
    </author>
    <link href="http://arxiv.org/abs/1201.2933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3555v2</id>
    <updated>2013-10-30T15:30:56Z</updated>
    <published>2012-10-12T15:50:47Z</published>
    <title>Task-Based Core-Periphery Organisation of Human Brain Dynamics</title>
    <summary>  As a person learns a new skill, distinct synapses, brain regions, and
circuits are engaged and change over time. In this paper, we develop methods to
examine patterns of correlated activity across a large set of brain regions.
Our goal is to identify properties that enable robust learning of a motor
skill. We measure brain activity during motor sequencing and characterize
network properties based on coherent activity between brain regions. Using
recently developed algorithms to detect time-evolving communities, we find that
the complex reconfiguration patterns of the brain's putative functional modules
that control learning can be described parsimoniously by the combined presence
of a relatively stiff temporal core that is composed primarily of sensorimotor
and visual regions whose connectivity changes little in time and a flexible
temporal periphery that is composed primarily of multimodal association regions
whose connectivity changes frequently. The separation between temporal core and
periphery changes over the course of training and, importantly, is a good
predictor of individual differences in learning success. The core of
dynamically stiff regions exhibits dense connectivity, which is consistent with
notions of core-periphery organization established previously in social
networks. Our results demonstrate that core-periphery organization provides an
insightful way to understand how putative functional modules are linked. This,
in turn, enables the prediction of fundamental human capacities, including the
production of complex goal-directed behavior.
</summary>
    <author>
      <name>Danielle S. Bassett</name>
    </author>
    <author>
      <name>Nicholas F. Wymbs</name>
    </author>
    <author>
      <name>M. Puck Rombach</name>
    </author>
    <author>
      <name>Mason A. Porter</name>
    </author>
    <author>
      <name>Peter J. Mucha</name>
    </author>
    <author>
      <name>Scott T. Grafton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 9 figures, and Supplementary Information</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3555v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3555v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4722v1</id>
    <updated>2012-09-21T07:00:13Z</updated>
    <published>2012-09-21T07:00:13Z</published>
    <title>Apparent extracellular current density and extracellular space: basis
  for the current source density analysis in neural tissue</title>
    <summary>  This article provides a theoretical basis for relating macroscopic electrical
signals recorded from biological tissue, such as electroencephalogram (EEG) and
local field potential (LFP), to the electrophysiological processes at the
cellular level in a manner consistent with Maxwell's equations. Concepts of the
apparent extracellular current density and the apparent extracellular space
with apparent permittivity and conductivity are introduced from the
conservation of current and Gauss's theorem. A general equation for the current
source density (CSD) analysis is derived for biological tissue with
frequency-dependent apparent permittivity and conductivity. An intuitive
account of the apparent extracellular space is given to relate the concept to
the dielectric dispersion of biological tissue.
</summary>
    <author>
      <name>Hiroyoshi Miyakawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Laboratory of Cellular Neurobiology, School of Life Sciences, Tokyo University of Pharmacy and Life Sciences, Tokyo, Japan</arxiv:affiliation>
    </author>
    <author>
      <name>Toru Aonishi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computational Intelligence and Systems Science, Tokyo Institute of Technology, Yokohama, Japan</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0318v2</id>
    <updated>2013-02-07T15:46:02Z</updated>
    <published>2012-11-01T22:02:13Z</published>
    <title>Control of synchronization patterns in neural-like Boolean networks</title>
    <summary>  We study experimentally the synchronization patterns in time-delayed directed
Boolean networks of excitable systems. We observe a transition in the network
dynamics when the refractory time of the individual systems is adjusted. When
the refractory time is on the same order-of-magnitude as the mean link time
delays or the heterogeneities of the link time delays, cluster synchronization
patterns change, or are suppressed entirely, respectively. We also show that
these transitions occur when we only change the properties of a small number of
nodes identified by their larger in-degree, hence the synchronization patterns
can be controlled locally by these nodes. Our findings have implications for
synchronization in biological neural networks.
</summary>
    <author>
      <name>David P. Rosin</name>
    </author>
    <author>
      <name>Damien Rontani</name>
    </author>
    <author>
      <name>Daniel J. Gauthier</name>
    </author>
    <author>
      <name>Eckehard Schöll</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.104102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.104102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in Phys. Rev. Lett</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. Lett. 110, 104102 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.0318v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0318v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5953v1</id>
    <updated>2012-11-26T13:53:04Z</updated>
    <published>2012-11-26T13:53:04Z</published>
    <title>Decision under ambiguity: Effects of sign and magnitude</title>
    <summary>  Decision under ambiguity (uncertainty with unknown probabilities) has been
attracting attention in behavioral and neuroeconomics. However, recent
neuroimaging studies have mainly focused on gain domains while little attention
has been paid to the magnitudes of outcomes. In this study, we examined the
effects of the sign (i.e. gain and loss) and magnitude of outcomes on ambiguity
aversion and the additivity of subjective probabilities in Ellsberg's urn
problem. We observed that (i) ambiguity aversion was observed in both signs,
and (ii) subadditivity of subjective probability was not observed in negative
outcomes.
</summary>
    <author>
      <name>Keigo Inukai</name>
    </author>
    <author>
      <name>Taiki Takahashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 figure, 16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Neuroscience Vol. 119, No. 8 , Pages
  1170-1178</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.5953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3766v1</id>
    <updated>2012-08-18T17:02:26Z</updated>
    <published>2012-08-18T17:02:26Z</published>
    <title>A blind deconvolution approach to recover effective connectivity brain
  networks from resting state fMRI data</title>
    <summary>  A great improvement to the insight on brain function that we can get from
fMRI data can come from effective connectivity analysis, in which the flow of
information between even remote brain regions is inferred by the parameters of
a predictive dynamical model. As opposed to biologically inspired models, some
techniques as Granger causality (GC) are purely data-driven and rely on
statistical prediction and temporal precedence. While powerful and widely
applicable, this approach could suffer from two main limitations when applied
to BOLD fMRI data: confounding effect of hemodynamic response function (HRF)
and conditioning to a large number of variables in presence of short time
series. For task-related fMRI, neural population dynamics can be captured by
modeling signal dynamics with explicit exogenous inputs; for resting-state fMRI
on the other hand, the absence of explicit inputs makes this task more
difficult, unless relying on some specific prior physiological hypothesis. In
order to overcome these issues and to allow a more general approach, here we
present a simple and novel blind-deconvolution technique for BOLD-fMRI signal.
Coming to the second limitation, a fully multivariate conditioning with short
and noisy data leads to computational problems due to overfitting. Furthermore,
conceptual issues arise in presence of redundancy. We thus apply partial
conditioning to a limited subset of variables in the framework of information
theory, as recently proposed. Mixing these two improvements we compare the
differences between BOLD and deconvolved BOLD level effective networks and draw
some conclusions.
</summary>
    <author>
      <name>G. Wu</name>
    </author>
    <author>
      <name>W. Liao</name>
    </author>
    <author>
      <name>S. Stramaglia</name>
    </author>
    <author>
      <name>J. Ding</name>
    </author>
    <author>
      <name>H. Chen</name>
    </author>
    <author>
      <name>D. Marinazzo</name>
    </author>
    <link href="http://arxiv.org/abs/1208.3766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6607v1</id>
    <updated>2012-09-28T18:59:30Z</updated>
    <published>2012-09-28T18:59:30Z</published>
    <title>Evidence for an additive inhibitory component of contrast adaptation</title>
    <summary>  The latency of visual responses generally decreases as contrast increases.
Recording in the lateral geniculate nucleus (LGN), we find that response
latency increases with increasing contrast in ON cells for some visual stimuli.
We propose that this surprising latency trend can be explained if ON cells rest
further from threshold at higher contrasts. Indeed, while contrast changes
caused a combination of multiplicative gain change and additive shift in LGN
cells, the additive shift predominated in ON cells. Modeling results supported
this theory: the ON cell latency trend was found when the distance-to-threshold
shifted with contrast, but not when distance-to-threshold was fixed across
contrasts. In the model, latency also increases as surround-to-center ratios
increase, which has been shown to occur at higher contrasts. We propose that
higher-contrast full-field stimuli can evoke more surround inhibition, shifting
the potential further from spiking threshold and thereby increasing response
latency.
</summary>
    <author>
      <name>Kate S. Gaudry</name>
    </author>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <link href="http://arxiv.org/abs/1209.6607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6604v2</id>
    <updated>2012-12-08T01:59:20Z</updated>
    <published>2012-09-28T18:54:45Z</published>
    <title>Monitoring spike train synchrony</title>
    <summary>  Recently, the SPIKE-distance has been proposed as a parameter-free and
time-scale independent measure of spike train synchrony. This measure is
time-resolved since it relies on instantaneous estimates of spike train
dissimilarity. However, its original definition led to spuriously high
instantaneous values for event-like firing patterns. Here we present a
substantial improvement of this measure which eliminates this shortcoming. The
reliability gained allows us to track changes in instantaneous clustering,
i.e., time-localized patterns of (dis)similarity among multiple spike trains.
Additional new features include selective and triggered temporal averaging as
well as the instantaneous comparison of spike train groups. In a second step, a
causal SPIKE-distance is defined such that the instantaneous values of
dissimilarity rely on past information only so that time-resolved spike train
synchrony can be estimated in real-time. We demonstrate that these methods are
capable of extracting valuable information from field data by monitoring the
synchrony between neuronal spike trains during an epileptic seizure. Finally,
the applicability of both the regular and the real-time SPIKE-distance to
continuous data is illustrated on model electroencephalographic (EEG)
recordings.
</summary>
    <author>
      <name>Thomas Kreuz</name>
    </author>
    <author>
      <name>Daniel Chicharro</name>
    </author>
    <author>
      <name>Conor Houghton</name>
    </author>
    <author>
      <name>Ralph G Andrzejak</name>
    </author>
    <author>
      <name>Florian Mormann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 10 figures, 35 references; 1 supplementary figure, 1
  supplementary movie (see author's webpage
  http://www.fi.isc.cnr.it/users/thomas.kreuz/sourcecode.html)</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.6604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2945v1</id>
    <updated>2012-04-13T10:37:50Z</updated>
    <published>2012-04-13T10:37:50Z</published>
    <title>Nonnormal amplification in random balanced neuronal networks</title>
    <summary>  In dynamical models of cortical networks, the recurrent connectivity can
amplify the input given to the network in two distinct ways. One is induced by
the presence of near-critical eigenvalues in the connectivity matrix W,
producing large but slow activity fluctuations along the corresponding
eigenvectors (dynamical slowing). The other relies on W being nonnormal, which
allows the network activity to make large but fast excursions along specific
directions. Here we investigate the tradeoff between nonnormal amplification
and dynamical slowing in the spontaneous activity of large random neuronal
networks composed of excitatory and inhibitory neurons. We use a Schur
decomposition of W to separate the two amplification mechanisms. Assuming
linear stochastic dynamics, we derive an exact expression for the expected
amount of purely nonnormal amplification. We find that amplification is very
limited if dynamical slowing must be kept weak. We conclude that, to achieve
strong transient amplification with little slowing, the connectivity must be
structured. We show that unidirectional connections between neurons of the same
type together with reciprocal connections between neurons of different types,
allow for amplification already in the fast dynamical regime. Finally, our
results also shed light on the differences between balanced networks in which
inhibition exactly cancels excitation, and those where inhibition dominates.
</summary>
    <author>
      <name>Guillaume Hennequin</name>
    </author>
    <author>
      <name>Tim P. Vogels</name>
    </author>
    <author>
      <name>Wulfram Gerstner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.86.011909</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.86.011909" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review E (2012) 86:011909</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.2945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6388v1</id>
    <updated>2012-02-28T21:44:22Z</updated>
    <published>2012-02-28T21:44:22Z</published>
    <title>A structural model of emotions of cognitive dissonances</title>
    <summary>  Cognitive dissonance is the stress that comes from holding two conflicting
thoughts simultaneously in the mind, usually arising when people are asked to
choose between two detrimental or two beneficial options. In view of the
well-established role of emotions in decision making, here we investigate
whether the conventional structural models used to represent the relationships
among basic emotions, such as the Circumplex model of affect, can describe the
emotions of cognitive dissonance as well. We presented a questionnaire to 34
anonymous participants, where each question described a decision to be made
among two conflicting motivations and asked the participants to rate
analogically the pleasantness and the intensity of the experienced emotion. We
found that the results were compatible with the predictions of the Circumplex
model for basic emotions.
</summary>
    <author>
      <name>Jose F. Fontanari</name>
    </author>
    <author>
      <name>Marie-Claude Bonniot-Cabanac</name>
    </author>
    <author>
      <name>Michel Cabanac</name>
    </author>
    <author>
      <name>Leonid I. Perlovsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neunet.2012.04.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neunet.2012.04.007" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Networks 32 (2012) 57-64</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.6388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4393v2</id>
    <updated>2012-05-16T14:09:55Z</updated>
    <published>2012-04-19T16:01:02Z</published>
    <title>Decorrelation of neural-network activity by inhibitory feedback</title>
    <summary>  Correlations in spike-train ensembles can seriously impair the encoding of
information by their spatio-temporal structure. An inevitable source of
correlation in finite neural networks is common presynaptic input to pairs of
neurons. Recent theoretical and experimental studies demonstrate that spike
correlations in recurrent neural networks are considerably smaller than
expected based on the amount of shared presynaptic input. By means of a linear
network model and simulations of networks of leaky integrate-and-fire neurons,
we show that shared-input correlations are efficiently suppressed by inhibitory
feedback. To elucidate the effect of feedback, we compare the responses of the
intact recurrent network and systems where the statistics of the feedback
channel is perturbed. The suppression of spike-train correlations and
population-rate fluctuations by inhibitory feedback can be observed both in
purely inhibitory and in excitatory-inhibitory networks. The effect is fully
understood by a linear theory and becomes already apparent at the macroscopic
level of the population averaged activity. At the microscopic level,
shared-input correlations are suppressed by spike-train correlations: In purely
inhibitory networks, they are canceled by negative spike-train correlations. In
excitatory-inhibitory networks, spike-train correlations are typically
positive. Here, the suppression of input correlations is not a result of the
mere existence of correlations between excitatory (E) and inhibitory (I)
neurons, but a consequence of a particular structure of correlations among the
three possible pairings (EE, EI, II).
</summary>
    <author>
      <name>Tom Tetzlaff</name>
    </author>
    <author>
      <name>Moritz Helias</name>
    </author>
    <author>
      <name>Gaute T. Einevoll</name>
    </author>
    <author>
      <name>Markus Diesmann</name>
    </author>
    <link href="http://arxiv.org/abs/1204.4393v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4393v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0335v1</id>
    <updated>2012-05-02T06:36:56Z</updated>
    <published>2012-05-02T06:36:56Z</published>
    <title>Rapid, parallel path planning by propagating wavefronts of spiking
  neural activity</title>
    <summary>  Efficient path planning and navigation is critical for animals, robotics,
logistics and transportation. We study a model in which spatial navigation
problems can rapidly be solved in the brain by parallel mental exploration of
alternative routes using propagating waves of neural activity. A wave of
spiking activity propagates through a hippocampus-like network, altering the
synaptic connectivity. The resulting vector field of synaptic change then
guides a simulated animal to the appropriate selected target locations. We
demonstrate that the navigation problem can be solved using realistic, local
synaptic plasticity rules during a single passage of a wavefront. Our model can
find optimal solutions for competing possible targets or learn and navigate in
multiple environments. The model provides a hypothesis on the possible
computational mechanisms for optimal path planning in the brain, at the same
time it is useful for neuromorphic implementations, where the parallelism of
information processing proposed here can fully be harnessed in hardware.
</summary>
    <author>
      <name>Filip Ponulak</name>
    </author>
    <author>
      <name>John J. Hopfield</name>
    </author>
    <link href="http://arxiv.org/abs/1205.0335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6554v2</id>
    <updated>2013-01-17T11:20:34Z</updated>
    <published>2012-10-24T14:50:34Z</published>
    <title>Neuronal functional connectivity among multiple areas of the rat
  somatosensory system during spontaneous and evoked activities</title>
    <summary>  Small-World Networks (SWNs) represent a fundamental model for the
comprehension of many complex man-made and biological networks. In the central
nervous system, SWN models have been shown to fit well both anatomical and
functional maps at the macroscopic level. However the functional microscopic
level, where the nodes of a network are composed of single neurons, is still
poorly understood. At this level, although recent evidences suggest that
functional connectivity maps exhibit small-world organization, it is not known
whether and how these maps, distributed in multiple brain regions, change
across different conditions. We addressed these questions by simultaneous
multi-array extracellular recordings in three brain regions diversely involved
in somatosensory information processing: the ventropostero-lateral thalamic
nuclei (VPL), the primary somatosensory cortex (S1) and the centro-median
thalamic nuclei (CM). From both spike and Local Field Potential (LFP)
recordings, we estimated the functional connectivity maps by using the
Normalized Compression Similarity (spikes) and the Phase Synchrony (LFPs).
Then, by using graph-theoretical statistics, we characterized the functional
map topology both during spontaneous activity and sensory stimulation. Our main
results show that: (i) spikes and LFPs show SWN organization during spontaneous
activity; (ii) After stimulation onset, while substantial functional map
reconfigurations occur both in spike and LFPs, small-worldness is nonetheless
preserved (iii) The stimulus triggers a significant increase of inter-area LFP
connections without modifying the topology of intra-area functional
connections; (iv) Through computer simulations of the fundamental concept of
cell assemblies, transient groups of activating neurons can be described by
small-world networks.
</summary>
    <author>
      <name>Antonio G. Zippo</name>
    </author>
    <author>
      <name>Riccardo Storchi</name>
    </author>
    <author>
      <name>Giuliana Gelsomino</name>
    </author>
    <author>
      <name>Sara Nencini</name>
    </author>
    <author>
      <name>Gian Carlo Caramenti</name>
    </author>
    <author>
      <name>Maurizio Valente</name>
    </author>
    <author>
      <name>Gabriele E. M. Biella</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1003104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1003104" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Computational Biology 06/2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6554v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6554v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5116v1</id>
    <updated>2011-12-21T18:08:39Z</updated>
    <published>2011-12-21T18:08:39Z</published>
    <title>Evolution of sustained foraging in 3D environments with physics</title>
    <summary>  Artificially evolving foraging behavior in simulated legged animals has
proved to be a notoriously difficult task. Here, we co-evolve the morphology
and controller for virtual organisms in a three-dimensional physically
realistic environment to produce goal-directed legged locomotion. We show that
following and reaching multiple food sources can evolve de novo, by evaluating
each organism on multiple food sources placed on a basic pattern that is
gradually randomized across generations. We devised a strategy of evolutionary
"staging", where the best organism from a set of evolutionary experiments using
a particular fitness function is used to seed a new set, with a fitness
function that is progressively altered to better challenge organisms as
evolution improves them. We find that an organism's efficiency at reaching the
first food source does not predict its ability at finding subsequent ones
because foraging efficiency crucially depends on the position of the last food
source reached, an effect illustrated by "foraging maps" that capture the
organism's controller state, body position, and orientation. Our best evolved
foragers are able to reach multiple food sources over 90% of the time on
average, a behavior that is key to any biologically realistic simulation where
a self-sustaining population has to survive by collecting food sources in
three-dimensional, physical environments.
</summary>
    <author>
      <name>Nicolas Chaumont</name>
    </author>
    <author>
      <name>Christoph Adami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures. Supplementary Materials available at
  http://tinyurl.com/autonomous-foragers-supplement</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.5116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4931v2</id>
    <updated>2011-08-31T09:40:53Z</updated>
    <published>2011-04-26T14:21:23Z</published>
    <title>State sampling dependence of the Hopfield network inference</title>
    <summary>  The fully connected Hopfield network is inferred based on observed
magnetizations and pairwise correlations. We present the system in the glassy
phase with low temperature and high memory load. We find that the inference
error is very sensitive to the form of state sampling. When a single state is
sampled to compute magnetizations and correlations, the inference error is
almost indistinguishable irrespective of the sampled state. However, the error
can be greatly reduced if the data is collected with state transitions. Our
result holds for different disorder samples and accounts for the previously
observed large fluctuations of inference error at low temperatures.
</summary>
    <author>
      <name>Haiping Huang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/0253-6102/57/1/27</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/0253-6102/57/1/27" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, further discussions added and relevant references
  added</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Commun. Theor. Phys. 57 (2012) 169-172</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.4931v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4931v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4705v1</id>
    <updated>2011-05-24T08:22:36Z</updated>
    <published>2011-05-24T08:22:36Z</published>
    <title>A Tutorial in Connectome Analysis: Topological and Spatial Features of
  Brain Networks</title>
    <summary>  High-throughput methods for yielding the set of connections in a neural
system, the connectome, are now being developed. This tutorial describes ways
to analyze the topological and spatial organization of the connectome at the
macroscopic level of connectivity between brain regions as well as the
microscopic level of connectivity between neurons. We will describe topological
features at three different levels: the local scale of individual nodes, the
regional scale of sets of nodes, and the global scale of the complete set of
nodes in a network. Such features can be used to characterize components of a
network and to compare different networks, e.g. the connectome of patients and
control subjects for clinical studies. At the global scale, different types of
networks can be distinguished and we will describe Erd\"os-R\'enyi random,
scale-free, small-world, modular, and hierarchical archetypes of networks.
Finally, the connectome also has a spatial organization and we describe methods
for analyzing wiring lengths of neural systems. As an introduction for new
researchers in the field of connectome analysis, we discuss the benefits and
limitations of each analysis approach.
</summary>
    <author>
      <name>Marcus Kaiser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neuroimage.2011.05.025</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neuroimage.2011.05.025" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Neuroimage, in press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuroimage. 2011 Aug 1;57(3):892-907</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.4705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0872v1</id>
    <updated>2012-03-05T11:45:39Z</updated>
    <published>2012-03-05T11:45:39Z</published>
    <title>Diversity of Intrinsic Frequency Encoding Patterns in Rat Cortical
  Neurons -Mechanisms and Possible Functions</title>
    <summary>  Extracellular recordings of single neurons in primary and secondary
somatosensory cortices of monkeys in vivo have shown that their firing rate can
increase, decrease, or remain constant in different cells, as the external
stimulus frequency increases. We observed similar intrinsic firing patterns
(increasing, decreasing or constant) in rat somatosensory cortex in vitro, when
stimulated with oscillatory input using conductance injection (dynamic clamp).
The underlying mechanism of this observation is not obvious, and presents a
challenge for mathematical modelling. We propose a simple principle for
describing this phenomenon using a leaky integrate-and-fire model with
sinusoidal input, an intrinsic oscillation and Poisson noise. Additional
enhancement of the gain of encoding could be achieved by local network
connections amongst diverse intrinsic response patterns. Our work sheds light
on the possible cellular and network mechanisms underlying these opposing
neuronal responses, which serve to enhance signal detection.
</summary>
    <author>
      <name>Jing Kang</name>
    </author>
    <author>
      <name>Hugh P. C. Robinson</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0009608</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0009608" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures; PloS One 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.0872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.4140v4</id>
    <updated>2013-04-27T21:32:06Z</updated>
    <published>2011-09-18T03:19:08Z</published>
    <title>Neuron as a reward-modulated combinatorial switch and a model of
  learning behavior</title>
    <summary>  This paper proposes a neuronal circuitry layout and synaptic plasticity
principles that allow the (pyramidal) neuron to act as a "combinatorial
switch". Namely, the neuron learns to be more prone to generate spikes given
those combinations of firing input neurons for which a previous spiking of the
neuron had been followed by a positive global reward signal. The reward signal
may be mediated by certain modulatory hormones or neurotransmitters, e.g., the
dopamine. More generally, a trial-and-error learning paradigm is suggested in
which a global reward signal triggers long-term enhancement or weakening of a
neuron's spiking response to the preceding neuronal input firing pattern. Thus,
rewards provide a feedback pathway that informs neurons whether their spiking
was beneficial or detrimental for a particular input combination. The neuron's
ability to discern specific combinations of firing input neurons is achieved
through a random or predetermined spatial distribution of input synapses on
dendrites that creates synaptic clusters that represent various permutations of
input neurons. The corresponding dendritic segments, or the enclosed individual
spines, are capable of being particularly excited, due to local sigmoidal
thresholding involving voltage-gated channel conductances, if the segment's
excitatory and absence of inhibitory inputs are temporally coincident. Such
nonlinear excitation corresponds to a particular firing combination of input
neurons, and it is posited that the excitation strength encodes the
combinatorial memory and is regulated by long-term plasticity mechanisms. It is
also suggested that the spine calcium influx that may result from the
spatiotemporal synaptic input coincidence may cause the spine head actin
filaments to undergo mechanical (muscle-like) contraction, with the ensuing
cytoskeletal deformation transmitted to the axon initial segment where it
may...
</summary>
    <author>
      <name>Marat M. Rvachev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neunet.2013.04.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neunet.2013.04.010" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 15 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Networks 46 (2013) 62-74</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.4140v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.4140v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0921v1</id>
    <updated>2012-08-04T12:45:46Z</updated>
    <published>2012-08-04T12:45:46Z</published>
    <title>Fractal analysis of resting state functional connectivity of the brain</title>
    <summary>  A variety of resting state neuroimaging data tend to exhibit fractal behavior
where its power spectrum follows power-law scaling. Resting state functional
connectivity is significantly influenced by fractal behavior which may not
directly originate from neuronal population activities of the brain. To
describe the fractal behavior, we adopted the fractionally integrated process
(FIP) model instead of the fractional Gaussian noise (FGN) since the FIP model
covers more general aspects of fractality than the FGN model. We also introduce
a novel concept called the nonfractal connectivity which is defined as the
correlation of short memory independent of fractal behavior, and compared it
with the fractal connectivity which is an asymptotic wavelet correlation. We
propose several wavelet-based estimators of fractal connectivity and nonfractal
connectivity for a multivariate fractionally integrated noise (mFIN). The
performance of these estimators was evaluated through simulation studies and
the analyses of resting state functional MRI data of the rat brain.
</summary>
    <author>
      <name>Wonsang You</name>
    </author>
    <author>
      <name>Sophie Achard</name>
    </author>
    <author>
      <name>Jörg Stadler</name>
    </author>
    <author>
      <name>Bernd Brückner</name>
    </author>
    <author>
      <name>Udo Seiffert</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/IJCNN.2012.6252657</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/IJCNN.2012.6252657" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 2012 International Joint Conference on Neural Networks</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 2012 International Joint Conference on Neural Networks,
  pp.1-8, 10-15 June 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.0921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2464v1</id>
    <updated>2011-12-12T07:43:33Z</updated>
    <published>2011-12-12T07:43:33Z</published>
    <title>Gibbs distribution analysis of temporal correlations structure in retina
  ganglion cells</title>
    <summary>  We present a method to estimate Gibbs distributions with
\textit{spatio-temporal} constraints on spike trains statistics. We apply this
method to spike trains recorded from ganglion cells of the salamander retina,
in response to natural movies. Our analysis, restricted to a few neurons,
performs more accurately than pairwise synchronization models (Ising) or the
1-time step Markov models (\cite{marre-boustani-etal:09}) to describe the
statistics of spatio-temporal spike patterns and emphasizes the role of higher
order spatio-temporal interactions.
</summary>
    <author>
      <name>J. C. Vasquez</name>
    </author>
    <author>
      <name>O. Marre</name>
    </author>
    <author>
      <name>A. G. Palacios</name>
    </author>
    <author>
      <name>M. J. Berry II</name>
    </author>
    <author>
      <name>B. Cessac</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jphysparis.2011.11.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jphysparis.2011.11.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in J. Physiol. Paris</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Physiology Paris, Vol. 106, Issue 3-4, pp 120-127,
  (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0924v1</id>
    <updated>2012-08-04T13:00:33Z</updated>
    <published>2012-08-04T13:00:33Z</published>
    <title>Fractal-driven distortion of resting state functional networks in fMRI:
  a simulation study</title>
    <summary>  Fractals are self-similar and scale-invariant patterns found ubiquitously in
nature. A lot of evidences implying fractal properties such as 1/f power
spectrums have been also observed in resting state fMRI time series. To explain
the fractal behavior in rs-fMRI, we have proposed the fractal-based model of
resting state hemodynamic response function (rs-HRF) whose properties can be
summarized by a fractal exponent. Here we show, through a simulation studies,
that the fractal behavior of cerebral hemodynamics may cause significant
distortion of network properties between neuronal activities and BOLD signals.
We simulated neuronal population activities based on the stochastic neural
field model from the Macaque brain network, and then obtained their
corresponding BOLD signals by convolving them with the rs-HRF filter. The
precision of centrality estimated in each node was deteriorated overall in
three networks based on transfer entropy, mutual information, and Pearson
correlation; particularly the distortion of transfer entropy was more sensitive
to the standard deviation of fractal exponents. A node with high centrality was
resilient to desynchronized fractal dynamics over all frequencies while a node
with small centrality exhibited huge distortion of both wavelet correlation and
centrality over low frequencies. This theoretical expectation indicates that
the difference of fractal exponents between brain regions leads to discrepancy
of statistical network properties, especially at nodes with small centrality,
between neuronal activities and BOLD signals, and that the traditional
definitions of resting state functional connectivity may not effectively
reflect the dynamics of spontaneous neuronal activities.
</summary>
    <author>
      <name>Wonsang You</name>
    </author>
    <author>
      <name>Jörg Stadler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 3rd Biennial Conference on Resting State Brain Connectivity</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 3rd Biennial Conference on Resting State Brain Connectivity,
  5-7 September 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.0924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0257v1</id>
    <updated>2012-09-03T07:12:28Z</updated>
    <published>2012-09-03T07:12:28Z</published>
    <title>Achieving Control of Lesion Growth in CNS with Minimal Damage</title>
    <summary>  Lesions in central nervous system (CNS) and their growth leads to
debilitating diseases like Multiple Sclerosis (MS), Alzheimer's etc. We
developed a model earlier which shows how the lesion growth can be arrested
through a beneficial auto-immune mechanism. The success of the approach depends
on a set of control parameters and their phase space was shown to have a smooth
manifold separating the uncontrolled lesion growth region from the controlled.
Here we show that an optimal set of parameter values exist which minimizes
system damage while achieving control of lesion growth.
</summary>
    <author>
      <name>Mathankumar Raja</name>
    </author>
    <author>
      <name>T. R. Krishna Mohan</name>
    </author>
    <link href="http://arxiv.org/abs/1209.0257v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0257v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5528v2</id>
    <updated>2011-07-26T21:42:27Z</updated>
    <published>2011-02-27T17:48:50Z</published>
    <title>Two-photon imaging and analysis of neural network dynamics</title>
    <summary>  The glow of a starry night sky, the smell of a freshly brewed cup of coffee
or the sound of ocean waves breaking on the beach are representations of the
physical world that have been created by the dynamic interactions of thousands
of neurons in our brains. How the brain mediates perceptions, creates thoughts,
stores memories and initiates actions remains one of the most profound puzzles
in biology, if not all of science. A key to a mechanistic understanding of how
the nervous system works is the ability to analyze the dynamics of neuronal
networks in the living organism in the context of sensory stimulation and
behaviour. Dynamic brain properties have been fairly well characterized on the
microscopic level of individual neurons and on the macroscopic level of whole
brain areas largely with the help of various electrophysiological techniques.
However, our understanding of the mesoscopic level comprising local populations
of hundreds to thousands of neurons (so called 'microcircuits') remains
comparably poor. In large parts, this has been due to the technical
difficulties involved in recording from large networks of neurons with
single-cell spatial resolution and near- millisecond temporal resolution in the
brain of living animals. In recent years, two-photon microscopy has emerged as
a technique which meets many of these requirements and thus has become the
method of choice for the interrogation of local neural circuits. Here, we
review the state-of-research in the field of two-photon imaging of neuronal
populations, covering the topics of microscope technology, suitable fluorescent
indicator dyes, staining techniques, and in particular analysis techniques for
extracting relevant information from the fluorescence data. We expect that
functional analysis of neural networks using two-photon imaging will help to
decipher fundamental operational principles of neural microcircuits.
</summary>
    <author>
      <name>Henry Lütcke</name>
    </author>
    <author>
      <name>Fritjof Helmchen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/0034-4885/74/8/086602</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/0034-4885/74/8/086602" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 4 figures, accepted for publication in Reports on Progress
  in Physics</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.5528v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5528v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.3968v1</id>
    <updated>2011-12-16T21:00:42Z</updated>
    <published>2011-12-16T21:00:42Z</published>
    <title>Dynamic effective connectivity of inter-areal brain circuits</title>
    <summary>  Anatomic connections between brain areas affect information flow between
neuronal circuits and the synchronization of neuronal activity. However, such
structural connectivity does not coincide with effective connectivity, related
to the more elusive question "Which areas cause the present activity of which
others?". Effective connectivity is directed and depends flexibly on contexts
and tasks. Here we show that a dynamic effective connectivity can emerge from
transitions in the collective organization of coherent neural activity.
Integrating simulation and semi-analytic approaches, we study mesoscale network
motifs of interacting cortical areas, modeled as large random networks of
spiking neurons or as simple rate units. Through a causal analysis of
time-series of model neural activity, we show that different dynamical states
generated by a same structural connectivity motif correspond to distinct
effective connectivity motifs. Such effective motifs can display a dominant
directionality, due to spontaneous symmetry breaking and effective entrainment
between local brain rhythms, although all connections in the considered
structural motifs are reciprocal [...] Finally, we analyze how the information
encoded in spiking patterns of a local neuronal population is propagated across
a fixed structural connectivity motif, demonstrating that changes in the active
effective connectivity regulate both the efficiency and the directionality of
information transfer [...] Going beyond these early proposals, we advance here
that dynamic interactions between brain rhythms provide as well the basis for
the self-organized control of this "communication-through-coherence", making
thus possible a fast "on-demand" reconfiguration of global information routing
modalities.
</summary>
    <author>
      <name>Demian Battaglia</name>
    </author>
    <author>
      <name>Annette Witt</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <author>
      <name>Theo Geisel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">53 pages, including 9 main Figures, 4 supporting figures and 1
  supporting appendix; submitted for publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.3968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.3968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6348v1</id>
    <updated>2012-11-27T16:26:15Z</updated>
    <published>2012-11-27T16:26:15Z</published>
    <title>Statistical modelling of higher-order correlations in pools of neural
  activity</title>
    <summary>  Simultaneous recordings from multiple neural units allow us to investigate
the activity of very large neural ensembles. To understand how large ensembles
of neurons process sensory information, it is necessary to develop suitable
statistical models to describe the response variability of the recorded spike
trains. Using the information geometry framework, it is possible to estimate
higher-order correlations by assigning one interaction parameter to each degree
of correlation, leading to a $(2^N-1)$-dimensional model for a population with
$N$ neurons. However, this model suffers greatly from a combinatorial
explosion, and the number of parameters to be estimated from the available
sample size constitutes the main intractability reason of this approach. To
quantify the extent of higher than pairwise spike correlations in pools of
multiunit activity, we use an information-geometric approach within the
framework of the extended central limit theorem considering all possible
contributions from high-order spike correlations. The identification of a
deformation parameter allows us to provide a statistical characterisation of
the amount of high-order correlations in the case of a very large neural
ensemble, significantly reducing the number of parameters, avoiding the
sampling problem, and inferring the underlying dynamical properties of the
network within pools of multiunit neural activity.
</summary>
    <author>
      <name>Fernando Montani</name>
    </author>
    <author>
      <name>Elena Phoka</name>
    </author>
    <author>
      <name>Mariela Portesi</name>
    </author>
    <author>
      <name>Simon R. Schultz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2013.03.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2013.03.012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 12 Figures; Submitted to Physica A</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 392 (2013) 3066-3086</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4766v1</id>
    <updated>2012-11-20T15:04:40Z</updated>
    <published>2012-11-20T15:04:40Z</published>
    <title>State-dependent changes of connectivity patterns and functional brain
  network topology in Autism Spectrum Disorder</title>
    <summary>  Anatomical and functional brain studies have converged to the hypothesis that
Autism Spectrum Disorders (ASD) are associated with atypical connectivity.
Using a modified resting-state paradigm to drive subjects' attention, we
provide evidence of a very marked interaction between ASD brain functional
connectivity and cognitive state. We show that functional connectivity changes
in opposite ways in ASD and typicals as attention shifts from external world
towards one's body generated information. Furthermore, ASD subject alter more
markedly than typicals their connectivity across cognitive states. Using
differences in brain connectivity across conditions, we classified ASD subjects
at a performance around 80% while classification based on the connectivity
patterns in any given cognitive state were close to chance. Connectivity
between the Anterior Insula and dorsal-anterior Cingulate Cortex showed the
highest classification accuracy and its strength increased with ASD severity.
These results pave the path for diagnosis of mental pathologies based on
functional brain networks obtained from a library of mental states.
</summary>
    <author>
      <name>Pablo Barttfeld</name>
    </author>
    <author>
      <name>Bruno Wicker</name>
    </author>
    <author>
      <name>Sebastián Cukier</name>
    </author>
    <author>
      <name>Silvana Navarta</name>
    </author>
    <author>
      <name>Sergio Lew</name>
    </author>
    <author>
      <name>Ramón Leiguarda</name>
    </author>
    <author>
      <name>Mariano Sigman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neuropsychologia.2012.09.047</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neuropsychologia.2012.09.047" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuropsychologia. 2012 Oct 5;50(14):3653-3662</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4872v1</id>
    <updated>2012-08-23T22:00:23Z</updated>
    <published>2012-08-23T22:00:23Z</published>
    <title>Functional Imaging of Conceptual Representations</title>
    <summary>  A concept is a mental representation that encompasses multiple aspects of an
item, but what is the neurological substrate of this representation? One
hypothesis states that such representations depend upon multimodal binding
processes within a single region. Convergent evidence suggests that such a
region may exist within the temporal lobe(see Patterson 2007). To test these
hypotheses we utilized two established paradigms, behavioral priming and
physiological suppression, to examine response to the repetition of concepts
across perceptual modalities.
  Typically, examinations of the relationship between behavioral priming and
suppression have queried the extent to which suppression effects in different
brain regions correlate with single measures of behavioral priming. In
contrast, we were interested in the extent to which suppression effects within
a single brain region would correlate with multiple measures of behavioral
priming. While many sensory regions show suppression effects to specific
perceptual repetitions, we hypothesized that a region engaged in conceptual
representation would show suppression effects to conceptual repetitions, even
when the stimuli were perceptually distinct.
  Using BOLD (Blood Oxygenation Level Dependent) data, we determined that
suppression effects in perirhinal cortex, a temporal lobe region, significantly
correlate with behavioral priming in a multimodal manner. This result provides
evidence that perirhinal cortex is engaged in conceptual representation.
</summary>
    <author>
      <name>Tarimotimi Awipi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 6 figures, human fMRI</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.4872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0448v1</id>
    <updated>2012-03-02T13:01:39Z</updated>
    <published>2012-03-02T13:01:39Z</published>
    <title>On a Model of Superconductivity and Biology</title>
    <summary>  The paper deals with a semilinear integrodifferential equation that
characterizes several dissipative models of Viscoelasticity, Biology and
Superconductivity. The initial - boundary problem with Neumann conditions is
analyzed. When the source term F is a linear function, then the explicit
solution is obtained. When F is non linear, some results on existence,
uniqueness and a priori estimates are deduced. As example of physical model the
reaction - diffusion system of Fitzhugh Nagumo is considered.
</summary>
    <author>
      <name>Monica De Angelis</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances and Appications in Mathematical Sciences, vol 7, Issue 1,
  2010, pages 41-50</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="78A70.82D55.35K25.35E05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.6927v1</id>
    <updated>2011-10-31T19:56:09Z</updated>
    <published>2011-10-31T19:56:09Z</published>
    <title>Statistical-Mechanical Measure of Stochastic Spiking Coherence in A
  Population of Inhibitory Subthreshold Neurons</title>
    <summary>  By varying the noise intensity, we study stochastic spiking coherence (i.e.,
collective coherence between noise-induced neural spikings) in an inhibitory
population of subthreshold neurons (which cannot fire spontaneously without
noise). This stochastic spiking coherence may be well visualized in the raster
plot of neural spikes. For a coherent case, partially-occupied "stripes"
(composed of spikes and indicating collective coherence) are formed in the
raster plot. This partial occupation occurs due to "stochastic spike skipping"
which is well shown in the multi-peaked interspike interval histogram. The main
purpose of our work is to quantitatively measure the degree of stochastic
spiking coherence seen in the raster plot. We introduce a new spike-based
coherence measure $M_s$ by considering the occupation pattern and the pacing
pattern of spikes in the stripes. In particular, the pacing degree between
spikes is determined in a statistical-mechanical way by quantifying the average
contribution of (microscopic) individual spikes to the (macroscopic)
ensemble-averaged global potential. This "statistical-mechanical" measure $M_s$
is in contrast to the conventional measures such as the "thermodynamic" order
parameter (which concerns the time-averaged fluctuations of the macroscopic
global potential), the "microscopic" correlation-based measure (based on the
cross-correlation between the microscopic individual potentials), and the
measures of precise spike timing (based on the peri-stimulus time histogram).
In terms of $M_s$, we quantitatively characterize the stochastic spiking
coherence, and find that $M_s$ reflects the degree of collective spiking
coherence seen in the raster plot very well. Hence, the
"statistical-mechanical" spike-based measure $M_s$ may be used usefully to
quantify the degree of stochastic spiking coherence in a statistical-mechanical
way.
</summary>
    <author>
      <name>Woochang Lim</name>
    </author>
    <author>
      <name>Sang-Yoon Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10827-011-0330-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10827-011-0330-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures, to appear in the J. Comput. Neurosci</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.6927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.6927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5307v2</id>
    <updated>2012-05-15T11:18:01Z</updated>
    <published>2012-04-24T08:50:14Z</published>
    <title>A first passage problem for a bivariate diffusion process: numerical
  solution with an application to neuroscience</title>
    <summary>  We consider a bivariate diffusion process and we study the first passage time
of one component through a boundary. We prove that its probability density is
the unique solution of a new integral equation and we propose a numerical
algorithm for its solution. Convergence properties of this algorithm are
discussed and the method is applied to the study of the integrated Brownian
Motion and to the integrated Ornstein Uhlenbeck process. Finally a model of
neuroscience interest is also discussed.
</summary>
    <author>
      <name>Elisa Benedetto</name>
    </author>
    <author>
      <name>Laura Sacerdote</name>
    </author>
    <author>
      <name>Cristina Zucca</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5307v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5307v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6789v1</id>
    <updated>2012-10-25T10:40:05Z</updated>
    <published>2012-10-25T10:40:05Z</published>
    <title>Associative memory of phase-coded spatiotemporal patterns in leaky
  Integrate and Fire networks</title>
    <summary>  We study the collective dynamics of a Leaky Integrate and Fire network in
which precise relative phase relationship of spikes among neurons are stored,
as attractors of the dynamics, and selectively replayed at differentctime
scales. Using an STDP-based learning process, we store in the connectivity
several phase-coded spike patterns, and we find that, depending on the
excitability of the network, different working regimes are possible, with
transient or persistent replay activity induced by a brief signal. We introduce
an order parameter to evaluate the similarity between stored and recalled
phase-coded pattern, and measure the storage capacity. Modulation of spiking
thresholds during replay changes the frequency of the collective oscillation or
the number of spikes per cycle, keeping preserved the phases relationship. This
allows a coding scheme in which phase, rate and frequency are dissociable.
Robustness with respect to noise and heterogeneity of neurons parameters is
studied, showing that, since dynamics is a retrieval process, neurons preserve
stablecprecise phase relationship among units, keeping a unique frequency of
oscillation, even in noisy conditions and with heterogeneity of internal
parameters of the units.
</summary>
    <author>
      <name>Silvia Scarpetta</name>
    </author>
    <author>
      <name>Ferdinando Giacco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10827-012-0423-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10827-012-0423-7" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Neuroscience. Publication date:
  03.10.2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1983v1</id>
    <updated>2012-10-06T18:19:11Z</updated>
    <published>2012-10-06T18:19:11Z</published>
    <title>Reply to Comments on Neuroelectrodynamics: Where are the Real Conceptual
  Pitfalls?</title>
    <summary>  The fundamental, powerful process of computation in the brain has been widely
misunderstood. The paper [1] associates the general failure to build
intelligent thinking machines with current reductionist principles of temporal
coding and advocates for a change in paradigm regarding the brain analogy.
Since fragments of information are stored in proteins which can shift between
several structures to perform their function, the biological substrate is
actively involved in physical computation. The intrinsic nonlinear dynamics of
action potentials and synaptic activities maintain physical interactions within
and between neurons in the brain. During these events the required information
is exchanged between molecular structures (proteins) which store fragments of
information and the generated electric flux which carries and integrates
information in the brain. The entire process of physical interaction explains
how the brain actively creates or experiences meaning. This process of
interaction during an action potential generation can be simply seen as the
moment when the neuron solves a many-body problem. A neuroelectrodynamic theory
shows that the neuron solves equations rather than exclusively computes
functions. With the main focus on temporal patterns, the spike timing dogma
(STD) has neglected important forms of computation which do occur inside
neurons. In addition, artificial neural models have missed the most important
part since the real super-computing power of the brain has its origins in
computations that occur within neurons.
</summary>
    <author>
      <name>Dorian Aur</name>
    </author>
    <link href="http://arxiv.org/abs/1210.1983v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1983v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3062v1</id>
    <updated>2011-11-13T21:10:40Z</updated>
    <published>2011-11-13T21:10:40Z</published>
    <title>Automated Seizure Detection: Unrecognized Challenges, Unexpected
  Insights</title>
    <summary>  One of epileptology's fundamental aims is the formulation of a universal,
internally consistent seizure definition. To assess this aim's feasibility,
three signal analysis methods were applied to a seizure time series and
performance comparisons were undertaken among them and with respect to a
validated algorithm. One of the methods uses a Fisher's matrix weighted measure
of the rate of parameters change of a 2n order auto-regressive model, another
is based on the Wavelet Transform Maximum Modulus for quantification of changes
in the logarithm of the standard deviation of ECoG power and yet another
employs the ratio of short-to-long term averages computed from cortical
signals. The central finding, fluctuating concordance among all methods' output
as a function of seizure duration, uncovers unexpected hurdles in the path to a
universal definition, while furnishing relevant knowledge in the dynamical
(spectral non-stationarity and varying ictal signal complexity) and clinical
(probable attainability of consensus) domains.
</summary>
    <author>
      <name>Ivan Osorio</name>
    </author>
    <author>
      <name>Alexey Lyubushin</name>
    </author>
    <author>
      <name>Didier Sornette</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.yebeh.2011.09.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.yebeh.2011.09.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages with 8 figures and 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Epilepsy &amp; Behavior 22, S7-S17 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.3062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3065v1</id>
    <updated>2011-11-13T21:35:50Z</updated>
    <published>2011-11-13T21:35:50Z</published>
    <title>Towards a Probabilistic Definition of Seizures</title>
    <summary>  This writing: a) Draws attention to the intricacies inherent to the pursuit
of a universal seizure definition even when powerful, well understood signal
analysis methods are utilized to this end; b) Identifies this aim as a
multi-objective optimization problem and discusses the advantages and
disadvantages of adopting or rejecting a unitary seizure definition; c)
Introduces a Probabilistic Measure of Seizure Activity to manage this thorny
issue. The challenges posed by the attempt to define seizures unitarily may be
partly related to their fractal properties and understood through a simplistic
analogy to the so-called "Richardson effect". A revision of the time-honored
conceptualization of seizures may be warranted to further advance epileptology.
</summary>
    <author>
      <name>Ivan Osorio</name>
    </author>
    <author>
      <name>Alexey Lyubushin</name>
    </author>
    <author>
      <name>Didier Sornette</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.yebeh.2011.09.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.yebeh.2011.09.009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages with 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Epilepsy &amp; Behavior 22, S18-S28 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.3065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3680v2</id>
    <updated>2011-04-13T19:15:09Z</updated>
    <published>2011-02-17T20:29:17Z</published>
    <title>Foundations for Understanding and Building Conscious Systems using
  Stable Parallel Looped Dynamics</title>
    <summary>  The problem of consciousness faced several challenges for a few reasons: (a)
a lack of necessary and sufficient conditions, without which we would not know
how close we are to the solution, (b) a lack of a synthesis framework to build
conscious systems and (c) a lack of mechanisms explaining the transition
between the lower-level chemical dynamics and the higher-level abstractions. In
this paper, I address these issues using a new framework. The central result is
that a person is 'minimally' conscious if and only if he knows at least one
truth. This lets us move away from the vagueness surrounding consciousness and
instead focus equivalently on: (i) what truths are and how our brain
represents/relates them to each other and (ii) how we attain a feeling of
knowing for a truth. For the former problem, since truths are things that do
not change, I replace the abstract notion with a dynamical one called fixed
sets. These sets are guaranteed to exist for our brain and other stable
parallel looped systems. The relationships between everyday events are now
built using relationships between fixed sets, until our brain creates a unique
dynamical state called the self-sustaining threshold 'membrane' of fixed sets.
For the latter problem, I present necessary and sufficient conditions for
attaining a feeling of knowing using a definition of continuity applied to
abstractions. Combining these results, I now say that a person is minimally
conscious if and only if his brain has a self-sustaining dynamical membrane
with abstract continuous paths. A synthetic system built to satisfy this
equivalent self-sustaining membrane condition appears indistinguishable from
human consciousness.
</summary>
    <author>
      <name>Muralidhar Ravuri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 9 figures - revised for clarity</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3680v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3680v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3072v1</id>
    <updated>2012-05-14T16:00:32Z</updated>
    <published>2012-05-14T16:00:32Z</published>
    <title>Wandering bumps in stochastic neural fields</title>
    <summary>  We study the effects of noise on stationary pulse solutions (bumps) in
spatially extended neural fields. The dynamics of a neural field is described
by an integrodifferential equation whose integral term characterizes synaptic
interactions between neurons in different spatial locations of the network.
Translationally symmetric neural fields support a continuum of stationary bump
solutions, which may be centered at any spatial location. Random fluctuations
are introduced by modeling the system as a spatially extended Langevin equation
whose noise term we take to be multiplicative or additive. For nonzero noise,
these bumps are shown to wander about the domain in a purely diffusive way. We
can approximate the effective diffusion coefficient using a small noise
expansion. Upon breaking the (continuous) translation symmetry of the system
using a spatially heterogeneous inputs or synapses, bumps in the stochastic
neural field can become temporarily pinned to a finite number of locations in
the network. In the case of spatially heterogeneous synaptic weights, as the
modulation frequency of this heterogeneity increases, the effective diffusion
of bumps in the network approaches that of the network with spatially
homogeneous weights.
</summary>
    <author>
      <name>Zachary P. Kilpatrick</name>
    </author>
    <author>
      <name>Bard Ermentrout</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.3072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.2879v1</id>
    <updated>2011-11-11T22:55:50Z</updated>
    <published>2011-11-11T22:55:50Z</published>
    <title>Anti-phase synchronization of phase-reduced oscillators using open-loop
  control</title>
    <summary>  In this letter, we present an elegant method to build and maintain an
anti-phase configuration of two nonlinear oscillators with different natural
frequencies and dynamics described by the sinusoidal phase-reduced model. The
anti-phase synchronization is achieved using a common input that couples the
oscillators and consists of a sequence of square pulses of appropriate
amplitude and duration. This example provides a proof of principle that
open-loop control can be used to create desired synchronization patterns for
nonlinear oscillators, when feedback is expensive or impossible to obtain.
</summary>
    <author>
      <name>Dionisis Stefanatos</name>
    </author>
    <author>
      <name>Jr-Shin Li</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E, Vol. 85, 037201, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.2879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.2879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.6185v1</id>
    <updated>2011-06-30T11:08:05Z</updated>
    <published>2011-06-30T11:08:05Z</published>
    <title>Effects of Compensation, Connectivity and Tau in a Computational Model
  of Alzheimer's Disease</title>
    <summary>  This work updates an existing, simplistic computational model of Alzheimer's
Disease (AD) to investigate the behaviour of synaptic compensatory mechanisms
in neural networks with small-world connectivity, and varying methods of
calculating compensation. It additionally introduces a method for simulating
tau neurofibrillary pathology, resulting in a more dramatic damage profile.
Small-world connectivity is shown to have contrasting effects on capacity,
retrieval time, and robustness to damage, whilst the use of more
easily-obtained remote memories rather than recent memories for synaptic
compensation is found to lead to rapid network damage.
</summary>
    <author>
      <name>Mark Rowan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, submitted to International Joint Conference on Neural
  Networks 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 2011 International Joint Conference on Neural Networks
  (IJCNN), (2011) 543--550</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.6185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.6185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4572v1</id>
    <updated>2011-07-22T16:52:47Z</updated>
    <published>2011-07-22T16:52:47Z</published>
    <title>Point process analysis of large-scale brain fMRI dynamics</title>
    <summary>  Functional magnetic resonance imaging (fMRI) techniques have contributed
significantly to our understanding of brain function. Current methods are based
on the analysis of \emph{gradual and continuous} changes in the brain blood
oxygenated level dependent (BOLD) signal. Departing from that approach, recent
work has shown that equivalent results can be obtained by inspecting only the
relatively large amplitude BOLD signal peaks, suggesting that relevant
information can be condensed in \emph{discrete} events. This idea is further
explored here to demonstrate how brain dynamics at resting state can be
captured just by the timing and location of such events, i.e., in terms of a
spatiotemporal point process. As a proof of principle, we show that the resting
state networks (RSN) maps can be extracted from such point processes.
Furthermore, the analysis uncovers avalanches of activity which are ruled by
the same dynamical and statistical properties described previously for neuronal
events at smaller scales. Given the demonstrated functional relevance of the
resting state brain dynamics, its representation as a discrete process might
facilitate large scale analysis of brain function both in health and disease.
</summary>
    <author>
      <name>Enzo Tagliazucchi</name>
    </author>
    <author>
      <name>Pablo Balenzuela</name>
    </author>
    <author>
      <name>Daniel Fraiman</name>
    </author>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <link href="http://arxiv.org/abs/1107.4572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3838v1</id>
    <updated>2012-04-17T16:50:25Z</updated>
    <published>2012-04-17T16:50:25Z</published>
    <title>Energy cost reduction in the synchronization of a pair of nonidentical
  coupled Hindmarsh-Rose neurons</title>
    <summary>  Many biological processes involve synchronization between nonequivalent
systems, i.e, systems where the difference is limited to a rather small
parameter mismatch. The maintenance of the synchronized regime in this cases is
energetically costly \cite{1}. This work studies the energy implications of
synchronization phenomena in a pair of structurally flexible coupled neurons
that interact through electrical coupling. We show that the forced
synchronization between two nonidentical neurons creates appropriate conditions
for an efficient actuation of adaptive laws able to make the neurons
structurally approach their behaviours in order to decrease the flow of energy
required to maintain the synchronization regime.
</summary>
    <author>
      <name>A. Moujahid</name>
    </author>
    <author>
      <name>A. D'Anjou</name>
    </author>
    <author>
      <name>F. J. Torrealdea</name>
    </author>
    <author>
      <name>C. Sarasola</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-12433-4_77</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-12433-4_77" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Intelligent and Soft Computing, 2010, Volume 71/2010,
  657-664</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3838v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3838v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4784v1</id>
    <updated>2012-10-17T16:23:12Z</updated>
    <published>2012-10-17T16:23:12Z</published>
    <title>Open-source tools for dynamical analysis of Liley's mean-field cortex
  model</title>
    <summary>  Mean-field models of the mammalian cortex treat this part of the brain as a
two-dimensional excitable medium. The electrical potentials, generated by the
excitatory and inhibitory neuron populations, are described by nonlinear,
coupled, partial differential equations, that are known to generate complicated
spatio-temporal behaviour. We focus on the model by Liley {\sl et al.}
(Network: Comput. Neural Syst. (2002) 13, 67-113). Several reductions of this
model have been studied in detail, but a direct analysis of its spatio-temporal
dynamics has, to the best of our knowledge, never been attempted before. Here,
we describe the implementation of implicit time-stepping of the model and the
tangent linear model, and solving for equilibria and time-periodic solutions,
using the open-source library PETSc. By using domain decomposition for
parallelization, and iterative solving of linear problems, the code is capable
of parsing some dynamics of a macroscopic slice of cortical tissue with a
sub-millimetre resolution.
</summary>
    <author>
      <name>Kevin R. Green</name>
    </author>
    <author>
      <name>Lennaert van Veen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.4784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37M05, 35B32" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2036v2</id>
    <updated>2012-01-13T20:10:34Z</updated>
    <published>2011-09-09T15:03:09Z</published>
    <title>Statistical Physics approach to dendritic computation: The
  excitable-wave mean-field approximation</title>
    <summary>  We analytically study the input-output properties of a neuron whose active
dendritic tree, modeled as a Cayley tree of excitable elements, is subjected to
Poisson stimulus. Both single-site and two-site mean-field approximations
incorrectly predict a non-equilibrium phase transition which is not allowed in
the model. We propose an excitable-wave mean-field approximation which shows
good agreement with previously published simulation results [Gollo et al., PLoS
Comput. Biol. 5(6) e1000402 (2009)] and accounts for finite-size effects. We
also discuss the relevance of our results to experiments in neuroscience,
emphasizing the role of active dendrites in the enhancement of dynamic range
and in gain control modulation.
</summary>
    <author>
      <name>Leonardo L. Gollo</name>
    </author>
    <author>
      <name>Osame Kinouchi</name>
    </author>
    <author>
      <name>Mauro Copelli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.85.011911</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.85.011911" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E, 85, 011911 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.2036v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2036v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5901v1</id>
    <updated>2012-01-27T21:31:31Z</updated>
    <published>2012-01-27T21:31:31Z</published>
    <title>Homoclinic Orbits of the FitzHugh-Nagumo Equation: The Singular-Limit</title>
    <summary>  The FitzHugh-Nagumo equation has been investigated with a wide array of
different methods in the last three decades. Recently a version of the
equations with an applied current was analyzed by Champneys, Kirk, Knobloch,
Oldeman and Sneyd using numerical continuation methods. They obtained a
complicated bifurcation diagram in parameter space featuring a C-shaped curve
of homoclinic bifurcations and a U-shaped curve of Hopf bifurcations. We use
techniques from multiple time-scale dynamics to understand the structures of
this bifurcation diagram based on geometric singular perturbation analysis of
the FitzHugh-Nagumo equation. Numerical and analytical techniques show that if
the ratio of the time-scales in the FitzHugh-Nagumo equation tends to zero,
then our singular limit analysis correctly represents the observed
CU-structure. Geometric insight from the analysis can even be used to compute
bifurcation curves which are inaccessible via continuation methods. The results
of our analysis are summarized in a singular bifurcation diagram.
</summary>
    <author>
      <name>John Guckenheimer</name>
    </author>
    <author>
      <name>Christian Kuehn</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3934/dcdss.2009.2.851</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3934/dcdss.2009.2.851" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint version - for final version see journal reference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Discrete and Continuous Dynamical Systems - Series S, Vol. 2, No.
  4, pp. 851-872, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.5901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0695v1</id>
    <updated>2011-05-03T21:30:46Z</updated>
    <published>2011-05-03T21:30:46Z</published>
    <title>Modelling hippocampal neurogenesis across the lifespan in seven species</title>
    <summary>  The aim of this study was to estimate the number of new cells and neurons
added to the dentate gyrus across the lifespan, and to compare the rate of
age-associated decline in neurogenesis across species. Data from mice (Mus
musculus), rats (Rattus norvegicus), lesser hedgehog tenrecs (Echinops
telfairi), macaques (Macaca mulatta), marmosets (Callithrix jacchus), tree
shrews (Tupaia belangeri), and humans (Homo sapiens) were extracted from twenty
one data sets published in fourteen different papers. ANOVA, exponential,
Weibull, and power models were fit to the data to determine which best
described the relationship between age and neurogenesis. Exponential models
provided a suitable fit and were used to estimate the relevant parameters. The
rate of decrease of neurogenesis correlated with species longevity r = 0.769, p
= 0.043), but not body mass or basal metabolic rate. Of all the cells added
postnatally to the mouse dentate gyrus, only 8.5% (95% CI = 1.0% to 14.7%) of
these will be added after middle age. In addition, only 5.7% (95% CI = 0.7% to
9.9%) of the existing cell population turns over from middle age onwards. Thus,
relatively few new cells are added for much of an animal's life, and only a
proportion of these will mature into functional neurons.
</summary>
    <author>
      <name>Stanley E. Lazic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neurobiolaging.2011.03.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neurobiolaging.2011.03.008" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In press at Neurobiology of Aging</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.2414v5</id>
    <updated>2014-05-05T13:42:57Z</updated>
    <published>2011-08-11T14:26:25Z</published>
    <title>Propagation of chaos in neural fields</title>
    <summary>  We consider the problem of the limit of bio-inspired spatially extended
neuronal networks including an infinite number of neuronal types (space
locations), with space-dependent propagation delays modeling neural fields. The
propagation of chaos property is proved in this setting under mild assumptions
on the neuronal dynamics, valid for most models used in neuroscience, in a
mesoscopic limit, the neural-field limit, in which we can resolve the quite
fine structure of the neuron's activity in space and where averaging effects
occur. The mean-field equations obtained are of a new type: they take the form
of well-posed infinite-dimensional delayed integro-differential equations with
a nonlocal mean-field term and a singular spatio-temporal Brownian motion. We
also show how these intricate equations can be used in practice to uncover
mathematically the precise mesoscopic dynamics of the neural field in a
particular model where the mean-field equations exactly reduce to deterministic
nonlinear delayed integro-differential equations. These results have several
theoretical implications in neuroscience we review in the discussion.
</summary>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/13-AAP950</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/13-AAP950" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/13-AAP950 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2014, Vol. 24, No. 3, 1298-1328</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.2414v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.2414v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5449v1</id>
    <updated>2011-12-22T20:47:12Z</updated>
    <published>2011-12-22T20:47:12Z</published>
    <title>Evolution and development of Brain Networks: From Caenorhabditis elegans
  to Homo sapiens</title>
    <summary>  Neural networks show a progressive increase in complexity during the time
course of evolution. From diffuse nerve nets in Cnidaria to modular,
hierarchical systems in macaque and humans, there is a gradual shift from
simple processes involving a limited amount of tasks and modalities to complex
functional and behavioral processing integrating different kinds of information
from highly specialized tissue. However, studies in a range of species suggest
that fundamental similarities, in spatial and topological features as well as
in developmental mechanisms for network formation, are retained across
evolution. 'Small-world' topology and highly connected regions (hubs) are
prevalent across the evolutionary scale, ensuring efficient processing and
resilience to internal (e.g. lesions) and external (e.g. environment) changes.
Furthermore, in most species, even the establishment of hubs, long-range
connections linking distant components, and a modular organization, relies on
similar mechanisms. In conclusion, evolutionary divergence leads to greater
complexity while following essential developmental constraints.
</summary>
    <author>
      <name>Marcus Kaiser</name>
    </author>
    <author>
      <name>Sreedevi Varier</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3109/0954898X.2011.638968</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3109/0954898X.2011.638968" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Network: Computation in Neural Systems, 2011, Vol. 22, No. 1-4 :
  Pages 143-147</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.5449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.6158v2</id>
    <updated>2012-08-13T11:00:46Z</updated>
    <published>2012-05-28T16:53:38Z</published>
    <title>Group Analysis of Self-organizing Maps based on Functional MRI using
  Restricted Frechet Means</title>
    <summary>  Studies of functional MRI data are increasingly concerned with the estimation
of differences in spatio-temporal networks across groups of subjects or
experimental conditions. Unsupervised clustering and independent component
analysis (ICA) have been used to identify such spatio-temporal networks. While
these approaches have been useful for estimating these networks at the
subject-level, comparisons over groups or experimental conditions require
further methodological development. In this paper, we tackle this problem by
showing how self-organizing maps (SOMs) can be compared within a Frechean
inferential framework. Here, we summarize the mean SOM in each group as a
Frechet mean with respect to a metric on the space of SOMs. We consider the use
of different metrics, and introduce two extensions of the classical sum of
minimum distance (SMD) between two SOMs, which take into account the
spatio-temporal pattern of the fMRI data. The validity of these methods is
illustrated on synthetic data. Through these simulations, we show that the
three metrics of interest behave as expected, in the sense that the ones
capturing temporal, spatial and spatio-temporal aspects of the SOMs are more
likely to reach significance under simulated scenarios characterized by
temporal, spatial and spatio-temporal differences, respectively. In addition, a
re-analysis of a classical experiment on visually-triggered emotions
demonstrates the usefulness of this methodology. In this study, the
multivariate functional patterns typical of the subjects exposed to pleasant
and unpleasant stimuli are found to be more similar than the ones of the
subjects exposed to emotionally neutral stimuli. Taken together, these results
indicate that our proposed methods can cast new light on existing data by
adopting a global analytical perspective on functional MRI paradigms.
</summary>
    <author>
      <name>Arnaud P. Fournel</name>
    </author>
    <author>
      <name>Emanuelle Reynaud</name>
    </author>
    <author>
      <name>Michael J. Brammer</name>
    </author>
    <author>
      <name>Andrew Simmons</name>
    </author>
    <author>
      <name>Cedric E. Ginestet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 5 figures, 4 tables. Submitted to Neuroimage</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.6158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.6158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1090v1</id>
    <updated>2011-04-06T13:20:03Z</updated>
    <published>2011-04-06T13:20:03Z</published>
    <title>The Narrow Escape problem in a flat cylindrical microdomain with
  application to diffusion in the synaptic cleft</title>
    <summary>  The mean first passage time (MFPT) for a Brownian particle to reach a small
target in cellular microdomains is a key parameter for chemical activation.
Although asymptotic estimations of the MFPT are available for various
geometries, these formula cannot be applied to degenerated structures where one
dimension of is much smaller compared to the others. Here we study the narrow
escape time (NET) problem for a Brownian particle to reach a small target
located on the surface of a flat cylinder, where the cylinder height is
comparable to the target size, and much smaller than the cylinder radius. When
the cylinder is sealed, we estimate the MFPT for a Brownian particle to hit a
small disk located centrally on the lower surface. For a laterally open
cylinder, we estimate the conditional probability and the conditional MFPT to
reach the small disk before exiting through the lateral opening. We apply our
results to diffusion in the narrow synaptic cleft, and compute the fraction and
the mean time for neurotransmitters to find their specific receptors located on
the postsynaptic terminal. Finally, we confirm our formulas with Brownian
simulations.
</summary>
    <author>
      <name>Juergen Reingruber</name>
    </author>
    <author>
      <name>David Holcman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5411v1</id>
    <updated>2012-09-24T20:23:06Z</updated>
    <published>2012-09-24T20:23:06Z</published>
    <title>A decaying factor accounts for contained activity in neuronal networks
  with no need of hierarchical or modular organization</title>
    <summary>  The mechanisms responsible for contention of activity in systems represented
by networks are crucial in various phenomena, as in diseases such as epilepsy
that affects the neuronal networks, and for information dissemination in social
networks. The first models to account for contained activity included
triggering and inhibition processes, but they cannot be applied to social
networks where inhibition is clearly absent. A recent model showed that
contained activity can be achieved with no need of inhibition processes
provided that the network is subdivided in modules (communities). In this
paper, we introduce a new concept inspired in the Hebbian theory through which
activity contention is reached by incorporating a dynamics based on a decaying
activity in a random walk mechanism preferential to the node activity. Upon
selecting the decay coefficient within a proper range, we observed sustained
activity in all the networks tested, viz. random, Barabasi-Albert and
geographical networks. The generality of this finding was confirmed by showing
that modularity is no longer needed if the dynamics based on the
integrate-and-fire dynamics incorporated the decay factor. Taken together,
these results provide a proof of principle that persistent, restrained network
activation might occur in the absence of any particular topological structure.
This may be the reason why neuronal activity does not outspread to the entire
neuronal network, even when no special topological organization exists.
</summary>
    <author>
      <name>Diego R. Amancio</name>
    </author>
    <author>
      <name>Osvaldo N. Oliveira Jr.</name>
    </author>
    <author>
      <name>Luciano da F. Costa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2012/11/P11018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2012/11/P11018" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2012) P11018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5080v1</id>
    <updated>2012-02-23T03:02:49Z</updated>
    <published>2012-02-23T03:02:49Z</published>
    <title>Optimal Entrainment of Neural Oscillator Ensembles</title>
    <summary>  In this paper, we derive the minimum-energy periodic control that entrains an
ensemble of structurally similar neural oscillators to a desired frequency. The
state space representation of a nominal oscillator is reduced to a phase model
by computing its limit cycle and phase response curve, from which the optimal
control is derived by using formal averaging and the calculus of variations. We
focus on the case of a 1:1 entrainment ratio, and introduce a numerical method
for approximating the optimal controls. The method is applied to asymptotically
control the spiking frequency of neural oscillators modeled using the
Hodgkin-Huxley equations. This illustrates the optimality of entrainment
controls derived using phase models when applied to the original state space
system, which is a crucial requirement for using phase models in control
synthesis for practical applications. The results of this work can be used to
design low energy signals for deep brain stimulation therapies for
neuropathologies, and can be generalized for optimal frequency control of
large-scale complex oscillating systems with parameter uncertainty.
</summary>
    <author>
      <name>Anatoly Zlotnik</name>
    </author>
    <author>
      <name>Jr-Shin Li</name>
    </author>
    <link href="http://arxiv.org/abs/1202.5080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.5047v1</id>
    <updated>2012-07-20T16:04:26Z</updated>
    <published>2012-07-20T16:04:26Z</published>
    <title>Dynamic Network Centrality Summarizes Learning in the Human Brain</title>
    <summary>  We study functional activity in the human brain using functional Magnetic
Resonance Imaging and recently developed tools from network science. The data
arise from the performance of a simple behavioural motor learning task.
Unsupervised clustering of subjects with respect to similarity of network
activity measured over three days of practice produces significant evidence of
`learning', in the sense that subjects typically move between clusters (of
subjects whose dynamics are similar) as time progresses. However, the high
dimensionality and time-dependent nature of the data makes it difficult to
explain which brain regions are driving this distinction. Using network
centrality measures that respect the arrow of time, we express the data in an
extremely compact form that characterizes the aggregate activity of each brain
region in each experiment using a single coefficient, while reproducing
information about learning that was discovered using the full data set. This
compact summary allows key brain regions contributing to centrality to be
visualized and interpreted. We thereby provide a proof of principle for the use
of recently proposed dynamic centrality measures on temporal network data in
neuroscience.
</summary>
    <author>
      <name>Alexander V. Mantzaris</name>
    </author>
    <author>
      <name>Danielle S. Bassett</name>
    </author>
    <author>
      <name>Nicholas F. Wymbs</name>
    </author>
    <author>
      <name>Ernesto Estrada</name>
    </author>
    <author>
      <name>Mason A. Porter</name>
    </author>
    <author>
      <name>Peter J. Mucha</name>
    </author>
    <author>
      <name>Scott T. Grafton</name>
    </author>
    <author>
      <name>Desmond J. Higham</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/comnet/cnt001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/comnet/cnt001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">jcomplexnetw (2013) 1(1): 83-92</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.5047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.5047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2083v1</id>
    <updated>2011-09-09T18:21:04Z</updated>
    <published>2011-09-09T18:21:04Z</published>
    <title>Anticipated Synchronization in a Biologically Plausible Model of
  Neuronal Motifs</title>
    <summary>  Two identical autonomous dynamical systems coupled in a master-slave
configuration can exhibit anticipated synchronization (AS) if the slave also
receives a delayed negative self-feedback. Recently, AS was shown to occur in
systems of simplified neuron models, requiring the coupling of the neuronal
membrane potential with its delayed value. However, this coupling has no
obvious biological correlate. Here we propose a canonical neuronal microcircuit
with standard chemical synapses, where the delayed inhibition is provided by an
interneuron. In this biologically plausible scenario, a smooth transition from
delayed synchronization (DS) to AS typically occurs when the inhibitory
synaptic conductance is increased. The phenomenon is shown to be robust when
model parameters are varied within physiological range. Since the DS-AS
transition amounts to an inversion in the timing of the pre- and post-synaptic
spikes, our results could have a bearing on spike-timing-dependent-plasticity
models.
</summary>
    <author>
      <name>Fernanda S. Matias</name>
    </author>
    <author>
      <name>Pedro V. Carelli</name>
    </author>
    <author>
      <name>Claudio R. Mirasso</name>
    </author>
    <author>
      <name>Mauro Copelli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.84.021922</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.84.021922" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review E 84, 021922 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.2083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0076v2</id>
    <updated>2012-12-04T03:15:35Z</updated>
    <published>2012-12-01T07:10:50Z</published>
    <title>Short term synaptic depression improves information transfer in
  perceptual multistability</title>
    <summary>  Competitive neural networks are often used to model the dynamics of
perceptual bistability. Switching between percepts can occur through
fluctuations and/or a slow adaptive process. Here, we analyze switching
statistics in competitive networks with short term synaptic depression and
noise. We start by analyzing a ring model that yields spatially structured
solutions and complement this with a study of a space-free network whose
populations are coupled with mutual inhibition. Dominance times arising from
depression driven switching can be approximated using a separation of
timescales in the ring and space-free model. For purely noise-driven switching,
we use energy arguments to justify how dominance times are exponentially
related to input strength. We also show that a combination of depression and
noise generates realistic distributions of dominance times. Unimodal functions
of dominance times are more easily differentiated from one another using
Bayesian sampling, suggesting synaptic depression induced switching transfers
more information about stimuli than noise-driven switching. Finally, we analyze
a competitive network model of perceptual tristability, showing depression
generates a memory of previous percepts based on the ordering of percepts.
</summary>
    <author>
      <name>Zachary P Kilpatrick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0076v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0076v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5841v1</id>
    <updated>2012-04-26T06:38:39Z</updated>
    <published>2012-04-26T06:38:39Z</published>
    <title>Recognition of Words from the EEG Laplacian</title>
    <summary>  Recent works on the relationship between the electro-encephalogram (EEG) data
and psychological stimuli show that EEG recordings can be used to recognize an
auditory stimulus presented to a subject. The recognition rate is, however,
strongly affected by technical and physiological artifacts. In this work,
subjects were presented seven auditory simuli in the form of English words
(first, second, third, left, right, yes, and no), and the time-locked electric
field was recorded with a 64 channel Neuroscan EEG system. We used the surface
Laplacian operator to eliminate artifacts due to sources located at regions far
from the electrode. Our intent with the Laplacian was to improve the
recognition rates of auditory stimuli from the electric field. To compute the
Laplacian, we used a spline interpolation from spherical harmonics. The EEG
Laplacian of the electric field were average over trials for the same auditory
stimulus, and with those averages we constructed prototypes and test samples.
In addition to the Laplacian, we applied Butterworth bandpass digital filters
to the averaged prototypes and test samples, and compared the filtered test
samples against the prototypes using a least squares metric in the time domain.
We also analyzed the effects of the spline interpolation order and bandpass
filter parameters in the recognition rates. Our results show that the use of
the Laplacian improves the recognition rates and suggests a spatial isomorphism
between both subjects.
</summary>
    <author>
      <name>J. Acacio de Barros</name>
    </author>
    <author>
      <name>C. G. Carvalhaes</name>
    </author>
    <author>
      <name>J. P. R. F. de Mendonça</name>
    </author>
    <author>
      <name>P. Suppes</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Revista Brasileira de Engenharia Biom\'edica 21, 45-59 (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.5841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.1167v3</id>
    <updated>2011-05-06T15:16:57Z</updated>
    <published>2011-03-06T21:56:07Z</published>
    <title>Prime numbers and spontaneous neuron activity</title>
    <summary>  Logarithmic gaps have been used in order to find a periodic component of the
sequence of prime numbers, hidden by a random noise (stochastic or chaotic). It
is shown that multiplicative nature of the noise is the main reason for the
successful application of the logarithmic gaps transforming the multiplicative
noise into an additive one. A relation of this phenomenon to spontaneous neuron
activity and to chaotic brain computations has been discussed.
</summary>
    <author>
      <name>A. Bershadskii</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1155/2011/519178</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1155/2011/519178" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">extended</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Adv. Math. Phys., 519178, (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.1167v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.1167v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5619v1</id>
    <updated>2012-12-21T22:09:04Z</updated>
    <published>2012-12-21T22:09:04Z</published>
    <title>Odor response features of projection neurons and local interneurons in
  the honeybee antennal lobe</title>
    <summary>  Local computation in microcircuits is an essential feature of distributed
information processing in vertebrate and invertebrate brains. The insect
antennal lobe represents a spatially confined local network that processes
high-dimensional and redundant peripheral input to compute an efficient odor
code. Social insects can rely on a particularly rich olfactory receptor
repertoire and they exhibit complex odor-guided behaviors. This corresponds
with a high anatomical complexity of their AL network. In the honeybee, a large
number of glomeruli that receive sensory input are interconnected by a dense
network of local interneurons (LNs). Uniglomerular projection neurons (PNs)
integrate sensory and recurrent network input into an efficient spatio-temporal
odor code. To investigate the specific computational roles of LNs and PNs we
measured eleven features of sub- and suprathreshold single cell responses to in
vivo odor stimulation. Using a semi-supervised cluster analysis we identified a
combination of five characteristic features that enabled the accurate
separation of morphologically identified LNs and PNs. The two clusters differed
significantly in all five features. In the absence of stimulation PNs showed a
higher subthreshold activation, assumed higher peak response rates and more
regular spiking pattern. LNs reacted considerably faster to the onset of a
stimulus and their responses were more reliable across stimulus repetitions. We
discuss possible mechanisms that can explain our results, and we interpret
cell-type specific characteristics with respect to their functional relevance.
</summary>
    <author>
      <name>Anneke Meyer</name>
    </author>
    <author>
      <name>Giovanni Galizia</name>
    </author>
    <author>
      <name>Martin P. Nawrot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5619v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5619v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4987v1</id>
    <updated>2012-01-24T14:36:34Z</updated>
    <published>2012-01-24T14:36:34Z</published>
    <title>Effect of synaptic plasticity in the structure and dynamics of
  disordered networks of coupled neurons</title>
    <summary>  In an all-to-all network of integrate-fire oscillators in which there is a
disorder in the intrinsic firing rates of the neurons, we show that through
spike timing-dependent plasticity the links which have the faster oscillators
as presynaptic, tend to be strengthened while the links originated from the
slow spiking neurons are weakened. The emergent effective flow of directed
connections, introduces the faster neurons as the more influent elements in the
network and facilitates synchronization by decreasing the synaptic cost for
onset of synchronization.
</summary>
    <author>
      <name>Mehdi Bayati</name>
    </author>
    <author>
      <name>Alireza Valizadeh</name>
    </author>
    <link href="http://arxiv.org/abs/1201.4987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2605v1</id>
    <updated>2011-03-14T09:02:42Z</updated>
    <published>2011-03-14T09:02:42Z</published>
    <title>The effect of neural adaptation of population coding accuracy</title>
    <summary>  Most neurons in the primary visual cortex initially respond vigorously when a
preferred stimulus is presented, but adapt as stimulation continues. The
functional consequences of adaptation are unclear. Typically a reduction of
firing rate would reduce single neuron accuracy as less spikes are available
for decoding, but it has been suggested that on the population level,
adaptation increases coding accuracy. This question requires careful analysis
as adaptation not only changes the firing rates of neurons, but also the neural
variability and correlations between neurons, which affect coding accuracy as
well. We calculate the coding accuracy using a computational model that
implements two forms of adaptation: spike frequency adaptation and synaptic
adaptation in the form of short-term synaptic plasticity. We find that the net
effect of adaptation is subtle and heterogeneous. Depending on adaptation
mechanism and test stimulus, adaptation can either increase or decrease coding
accuracy. We discuss the neurophysiological and psychophysical implications of
the findings and relate it to published experimental data.
</summary>
    <author>
      <name>J. M. Cortes</name>
    </author>
    <author>
      <name>D. Marinazzo</name>
    </author>
    <author>
      <name>P. Series</name>
    </author>
    <author>
      <name>M. W. Oram</name>
    </author>
    <author>
      <name>T. J. Sejnowski</name>
    </author>
    <author>
      <name>M. C. W. van Rossum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4586v1</id>
    <updated>2012-07-19T09:18:05Z</updated>
    <published>2012-07-19T09:18:05Z</published>
    <title>Persistent and anti-persistent pattern in stride-to-stride variability
  of treadmill walking: influence of rhythmic auditory cueing</title>
    <summary>  It has been observed that long time series of Stride Time (ST), Stride Length
(SL) and Stride Speed (SS=SL/ST) exhibited statistical persistence (long-range
auto-correlation) in overground walking. Rhythmic auditory cueing induced
anti-persistent (or anti-correlated) pattern in ST series, while SL and SS
remained persistent. On the other hand, it has been shown that SS became
anti-persistent in treadmill walking, while ST and SL remained persistent. The
aim of this study was to analyze the effect of the combination of treadmill
walking (imposed speed) and auditory cueing (imposed cadence) on gait dynamics.
Twenty middle-aged subjects performed 6 x 5min walking trials at various
imposed speeds on an instrumented treadmill. Freely-chosen walking cadences
were measured during the first three trials, and then imposed accordingly in
the last three trials by using a metronome. Detrended fluctuation analysis
(DFA) was performed on the times series of ST, SL, and SS. Treadmill induced
anti-persistent dynamics in the time series of SS, but preserved the
persistence of ST and SL. On the contrary, all the three parameters were
anti-persistent under dual-constraints condition. Anti-persistent dynamics may
be related to a tighter control: deviations are followed by a rapid
over-correction, what produces oscillations around target values. Under single
constraint condition, while SS is tightly regulated in order to follow the
treadmill speed, redundancy between ST and SL would likely allow persistent
pattern to occur. Conversely, under dual constraint conditions, the absence of
redundancy among SL, ST and SS would explain the generalized anti-persistent
pattern.
</summary>
    <author>
      <name>Philippe Terrier</name>
    </author>
    <author>
      <name>Olivier Dériaz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.humov.2012.05.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.humov.2012.05.004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint version of an article accepted in Human Movement Science</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Human Movement Science, 2012, 31(6):1585-97</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.4586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1067v1</id>
    <updated>2012-03-05T22:31:32Z</updated>
    <published>2012-03-05T22:31:32Z</published>
    <title>Cortical free association dynamics: distinct phases of a latching
  network</title>
    <summary>  A Potts associative memory network has been proposed as a simplified model of
macroscopic cortical dynamics, in which each Potts unit stands for a patch of
cortex, which can be activated in one of S local attractor states. The internal
neuronal dynamics of the patch is not described by the model, rather it is
subsumed into an effective description in terms of graded Potts units, with
adaptation effects both specific to each attractor state and generic to the
patch. If each unit, or patch, receives effective (tensor) connections from C
other units, the network has been shown to be able to store a large number p of
global patterns, or network attractors, each with a fraction a of the units
active, where the critical load p_c scales roughly like p_c ~ (C S^2)/(a
ln(1/a)) (if the patterns are randomly correlated). Interestingly, after
retrieving an externally cued attractor, the network can continue jumping, or
latching, from attractor to attractor, driven by adaptation effects. The
occurrence and duration of latching dynamics is found through simulations to
depend critically on the strength of local attractor states, expressed in the
Potts model by a parameter w. Here we describe with simulations and then
analytically the boundaries between distinct phases of no latching, of
transient and sustained latching, deriving a phase diagram in the plane w-T,
where T parametrizes thermal noise effects. Implications for real cortical
dynamics are briefly reviewed in the conclusions.
</summary>
    <author>
      <name>Eleonora Russo</name>
    </author>
    <author>
      <name>Alessandro Treves</name>
    </author>
    <link href="http://arxiv.org/abs/1203.1067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.6438v1</id>
    <updated>2012-05-29T18:03:26Z</updated>
    <published>2012-05-29T18:03:26Z</published>
    <title>Stimulus-dependent maximum entropy models of neural population codes</title>
    <summary>  Neural populations encode information about their stimulus in a collective
fashion, by joint activity patterns of spiking and silence. A full account of
this mapping from stimulus to neural activity is given by the conditional
probability distribution over neural codewords given the sensory input. To be
able to infer a model for this distribution from large-scale neural recordings,
we introduce a stimulus-dependent maximum entropy (SDME) model---a minimal
extension of the canonical linear-nonlinear model of a single neuron, to a
pairwise-coupled neural population. The model is able to capture the
single-cell response properties as well as the correlations in neural spiking
due to shared stimulus and due to effective neuron-to-neuron connections. Here
we show that in a population of 100 retinal ganglion cells in the salamander
retina responding to temporal white-noise stimuli, dependencies between cells
play an important encoding role. As a result, the SDME model gives a more
accurate account of single cell responses and in particular outperforms
uncoupled models in reproducing the distributions of codewords emitted in
response to a stimulus. We show how the SDME model, in conjunction with static
maximum entropy models of population vocabulary, can be used to estimate
information-theoretic quantities like surprise and information transmission in
a neural population.
</summary>
    <author>
      <name>Einat Granot-Atedgi</name>
    </author>
    <author>
      <name>Gašper Tkačik</name>
    </author>
    <author>
      <name>Ronen Segev</name>
    </author>
    <author>
      <name>Elad Schneidman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002922</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002922" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput Biol 9 (2013): e1002922</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.6438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.6438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1189v1</id>
    <updated>2012-02-06T16:21:21Z</updated>
    <published>2012-02-06T16:21:21Z</published>
    <title>A hybrid bio-organic interface for neuronal photo-activation</title>
    <summary>  Interfacing artificial functional materials and living neuronal tissues is at
the forefront of bio-nano-technology. Attempts have been so far based onto
microscale processing of metals and inorganic semiconductors as electrodes or
photoactive layers in biased devices. More recently, also nanomaterials
properties have been investigated. In spite of extensive research however, the
communication between biological tissues and artificial sensors is still a
challenge. Constraints consist in the complexity of the fabrication processes
(i.e. metal and semiconductor lithography), the mechanical properties (e.g.
flexibility and mechanical invasiveness) and chemical influence (e.g.
inflammatory reactions). In addition, electrodes have fixed geometries that
limit the location in space of the stimulus and often electrical currents are
detrimental for the overall system. To this respect organic soft matter offers
a chance in terms of biological affinity and mechanical properties. In
particular conjugated polymers have appealing optoelectronic features which
could lead to a new generation of neuronal communication and photo-manipulation
techniques. So far conjugated polymers have being only tested as coatings of
electrodes for neuronal activity recording. Here we report an up-scale of their
use: the successful interfacing of an organic semiconductor to a network of
cultured primary neurons, through optical excitation. This allows to a new
paradigm for the optical stimulation of neurons which could have important
implications for the development of an artificial retina based on organic
photodetectors.
</summary>
    <author>
      <name>Maria Rosa Antognazza</name>
    </author>
    <author>
      <name>Diego Ghezzi</name>
    </author>
    <author>
      <name>Marco Dal Maschio</name>
    </author>
    <author>
      <name>Erica Lanzarini</name>
    </author>
    <author>
      <name>Fabio Benfenati</name>
    </author>
    <author>
      <name>Guglielmo Lanzani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/ncomms1164</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/ncomms1164" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">about 9 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature Communications, 1164, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.1189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3470v1</id>
    <updated>2012-12-14T13:40:43Z</updated>
    <published>2012-12-14T13:40:43Z</published>
    <title>A Behavioural Perspective on the Early Evolution of Nervous Systems: A
  Computational Model of Excitable Myoepithelia</title>
    <summary>  How the very first nervous systems evolved remains a fundamental open
question. Molecular and genomic techniques have revolutionized our knowledge of
the molecular ingredients behind this transition but not yet provided a clear
picture of the morphological and tissue changes involved. Here we focus on a
behavioural perspective that centres on movement by muscle contraction.
Building on the finding that molecules for chemical neural signalling predate
multicellular animals, we investigate a gradual evolutionary scenario for
nervous systems that consists of two stages: A) Chemically transmission of
electrical activity between adjacent cells provided a primitive form of muscle
coordination in a contractile epithelial tissue. B) This primitive form of
coordination was subsequently improved upon by evolving the axodendritic
processes of modern neurons. We use computer simulations to investigate the
first stage. The simulations show that chemical transmission across a
contractile sheet can indeed produce useful body scale patterns, but only for
small-sized animals. For larger animals the noise in chemical neural signalling
interferes. Our results imply that a two-stage scenario is a viable approach to
nervous system evolution. The first stage could provide an initial behavioural
advantage, as well as a clear scaffold for subsequent improvements in
behavioural coordination.
</summary>
    <author>
      <name>Ronald A. J. van Elburg</name>
    </author>
    <author>
      <name>Oltman O. de Wiljes</name>
    </author>
    <author>
      <name>Michael Biehl</name>
    </author>
    <author>
      <name>Fred A. Keijzer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 8 figures and 8 model tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6989v1</id>
    <updated>2012-10-25T20:01:51Z</updated>
    <published>2012-10-25T20:01:51Z</published>
    <title>The impact of short term synaptic depression and stochastic vesicle
  dynamics on neural variability</title>
    <summary>  Neural variability plays a central role in neural coding and neuronal network
dynamics. Unreliability of synaptic transmission is a major source of neural
variability: synaptic neurotransmitter vesicles are released probabilistically
in response to presynaptic spikes and are recovered stochastically in time. The
stochastic dynamics of this process interacts with variability in the arrival
times of presynaptic spikes to shape the variability of the postsynaptic
response. We use continuous time Markov chain methods to analyze a model of
short term synaptic depression with stochastic vesicle dynamics coupled with
three different models of presynaptic spiking: one model in which the timing of
presynaptic spikes are modeled as a Poisson process, one in which spikes occur
more regularly than a Poisson process and one in which spikes occur more
irregularly. We use this analysis to investigate how variability in a
presynaptic spike train is transformed by short term synaptic depression and
stochastic vesicle dynamics to determine the variability of the postsynaptic
response to a presynaptic spike train. We find that regular presynaptic spiking
increases the average rate at which vesicles are released, that the number of
vesicles released over a time window is more variable for smaller time windows
than for larger time windows, and that fast presynaptic spiking gives rise to
Poisson-like variability of the postsynaptic response even when presynaptic
spike times are highly non-Poisson. Our results complement and extend
previously reported theoretical results and provide possible explanations for
some trends observed in recorded data.
</summary>
    <author>
      <name>Steven Reich</name>
    </author>
    <author>
      <name>Robert Rosenbaum</name>
    </author>
    <link href="http://arxiv.org/abs/1210.6989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.7228v2</id>
    <updated>2012-08-07T12:29:49Z</updated>
    <published>2012-07-31T12:51:28Z</published>
    <title>Noise Suppression and Surplus Synchrony by Coincidence Detection</title>
    <summary>  The functional significance of correlations between action potentials of
neurons is still a matter of vivid debates. In particular it is presently
unclear how much synchrony is caused by afferent synchronized events and how
much is intrinsic due to the connectivity structure of cortex. The available
analytical approaches based on the diffusion approximation do not allow to
model spike synchrony, preventing a thorough analysis. Here we theoretically
investigate to what extent common synaptic afferents and synchronized inputs
each contribute to closely time-locked spiking activity of pairs of neurons. We
employ direct simulation and extend earlier analytical methods based on the
diffusion approximation to pulse-coupling, allowing us to introduce precisely
timed correlations in the spiking activity of the synaptic afferents. We
investigate the transmission of correlated synaptic input currents by pairs of
integrate-and-fire model neurons, so that the same input covariance can be
realized by common inputs or by spiking synchrony. We identify two distinct
regimes: In the limit of low correlation linear perturbation theory accurately
determines the correlation transmission coefficient, which is typically smaller
than unity, but increases sensitively even for weakly synchronous inputs. In
the limit of high afferent correlation, in the presence of synchrony a
qualitatively new picture arises. As the non-linear neuronal response becomes
dominant, the output correlation becomes higher than the total correlation in
the input. This transmission coefficient larger unity is a direct consequence
of non-linear neural processing in the presence of noise, elucidating how
synchrony-coded signals benefit from these generic properties present in
cortical networks.
</summary>
    <author>
      <name>Matthias Schultze-Kraft</name>
    </author>
    <author>
      <name>Markus Diesmann</name>
    </author>
    <author>
      <name>Sonja Grün</name>
    </author>
    <author>
      <name>Moritz Helias</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002904</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002904" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Schultze-Kraft M, Diesmann M, Gr\"un S, Helias M (2013) Noise
  Suppression and Surplus Synchrony by Coincidence Detection. PLoS Comput Biol
  9(4): e1002904</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.7228v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.7228v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0094v3</id>
    <updated>2014-04-25T10:32:43Z</updated>
    <published>2012-06-01T06:34:03Z</published>
    <title>System level mechanisms of adaptation, learning, memory formation and
  evolvability: the role of chaperone and other networks</title>
    <summary>  During the last decade, network approaches became a powerful tool to describe
protein structure and dynamics. Here, we describe first the protein structure
networks of molecular chaperones, then characterize chaperone containing
sub-networks of interactomes called as chaperone-networks or chaperomes. We
review the role of molecular chaperones in short-term adaptation of cellular
networks in response to stress, and in long-term adaptation discussing their
putative functions in the regulation of evolvability. We provide a general
overview of possible network mechanisms of adaptation, learning and memory
formation. We propose that changes of network rigidity play a key role in
learning and memory formation processes. Flexible network topology provides
"learning competent" state. Here, networks may have much less modular
boundaries than locally rigid, highly modular networks, where the learnt
information has already been consolidated in a memory formation process. Since
modular boundaries are efficient filters of information, in the "learning
competent" state information filtering may be much smaller, than after memory
formation. This mechanism restricts high information transfer to the "learning
competent" state. After memory formation, modular boundary-induced segregation
and information filtering protect the stored information. The flexible networks
of young organisms are generally in a "learning competent" state. On the
contrary, locally rigid networks of old organisms have lost their "learning
competent" state, but store and protect their learnt information efficiently.
We anticipate that the above mechanism may operate at the level of both
protein-protein interaction and neuronal networks.
</summary>
    <author>
      <name>David M. Gyurko</name>
    </author>
    <author>
      <name>Csaba Soti</name>
    </author>
    <author>
      <name>Attila Stetak</name>
    </author>
    <author>
      <name>Peter Csermely</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2174/1389203715666140331110522</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2174/1389203715666140331110522" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 2 Figures, 1 Table, 173 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Current Protein and Peptide Science (2014) 15: 171-188</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.0094v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0094v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3600v1</id>
    <updated>2011-06-18T00:26:40Z</updated>
    <published>2011-06-18T00:26:40Z</published>
    <title>How Insight Emerges in a Distributed, Content-addressable Memory</title>
    <summary>  We begin this chapter with the bold claim that it provides a neuroscientific
explanation of the magic of creativity. Creativity presents a formidable
challenge for neuroscience. Neuroscience generally involves studying what
happens in the brain when someone engages in a task that involves responding to
a stimulus, or retrieving information from memory and using it the right way,
or at the right time. If the relevant information is not already encoded in
memory, the task generally requires that the individual make systematic use of
information that is encoded in memory. But creativity is different. It
paradoxically involves studying how someone pulls out of their brain something
that was never put into it! Moreover, it must be something both new and useful,
or appropriate to the task at hand. The ability to pull out of memory something
new and appropriate that was never stored there in the first place is what we
refer to as the magic of creativity. Even if we are so fortunate as to
determine which areas of the brain are active and how these areas interact
during creative thought, we will not have an answer to the question of how the
brain comes up with solutions and artworks that are new and appropriate. On the
other hand, since the representational capacity of neurons emerges at a level
that is higher than that of the individual neurons themselves, the inner
workings of neurons is too low a level to explain the magic of creativity. Thus
we look to a level that is midway between gross brain regions and neurons.
Since creativity generally involves combining concepts from different domains,
or seeing old ideas from new perspectives, we focus our efforts on the neural
mechanisms underlying the representation of concepts and ideas. Thus we ask
questions about the brain at the level that accounts for its representational
capacity, i.e. at the level of distributed aggregates of neurons.
</summary>
    <author>
      <name>Liane Gabora</name>
    </author>
    <author>
      <name>Apara Ranjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in press; 17 pages; 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Gabora, L. &amp; Ranjan, A. (2012). How insight emerges in a
  distributed, content-addressable memory. In A. Bristol, O. Vartanian, &amp; J.
  Kaufman (Eds.) The Neuroscience of Creativity. New York: Oxford University
  Press</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.3600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4401v2</id>
    <updated>2012-10-02T07:49:10Z</updated>
    <published>2012-07-17T16:43:21Z</published>
    <title>How to suppress undesired synchronization</title>
    <summary>  It is delightful to observe the emergence of synchronization in the blinking
of fireflies to attract partners and preys. Other charming examples of
synchronization can also be found in a wide range of phenomena such as, e.g.,
neurons firing, lasers cascades, chemical reactions, and opinion formation.
However, in many situations the formation of a coherent state is not pleasant
and should be mitigated. For example, the onset of synchronization can be the
root of epileptic seizures, traffic congestion in communication networks, and
the collapse of constructions. Here we propose the use of contrarians to
suppress undesired synchronization. We perform a comparative study of different
strategies, either requiring local or total knowledge of the system, and show
that the most efficient one solely requires local information. Our results also
reveal that, even when the distribution of neighboring interactions is narrow,
significant improvement in mitigation is observed when contrarians sit at the
highly connected elements. The same qualitative results are obtained for
artificially generated networks as well as two real ones, namely, the Routers
of the Internet and a neuronal network.
</summary>
    <author>
      <name>V. H. P. Louzada</name>
    </author>
    <author>
      <name>N. A. M. Araújo</name>
    </author>
    <author>
      <name>J. S. Andrade Jr</name>
    </author>
    <author>
      <name>H. J. Herrmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep00658</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep00658" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Louzada, V.H.P., Ara\'ujo, N.A.M., Andrade, J.S., Jr. &amp; Herrmann,
  H.J. How to suppress undesired synchronization. Sci. Rep. 2, 658;
  DOI:10.1038/srep00658 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.4401v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4401v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4796v2</id>
    <updated>2011-10-18T14:16:19Z</updated>
    <published>2011-08-24T09:54:35Z</published>
    <title>Learning with a network of competing synapses</title>
    <summary>  Competition between synapses arises in some forms of correlation-based
plasticity. Here we propose a game theory-inspired model of synaptic
interactions whose dynamics is driven by competition between synapses in their
weak and strong states, which are characterized by different timescales. The
learning of inputs and memory are meaningfully definable in an effective
description of networked synaptic populations. We study, numerically and
analytically, the dynamic responses of the effective system to various signal
types, particularly with reference to an existing empirical motor adaptation
model. The dependence of the system-level behavior on the synaptic parameters,
and the signal strength, is brought out in a clear manner, thus illuminating
issues such as those of optimal performance, and the functional role of
multiple timescales.
</summary>
    <author>
      <name>Ajaz Ahmad Bhat</name>
    </author>
    <author>
      <name>Gaurang Mahajan</name>
    </author>
    <author>
      <name>Anita Mehta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0025048</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0025048" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 9 figures; published in PLoS ONE</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 6(9) (2011): e25048</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.4796v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4796v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0296v1</id>
    <updated>2010-12-31T20:32:57Z</updated>
    <published>2010-12-31T20:32:57Z</published>
    <title>A Graphical Approach to a Model of Neuronal Tree with Variable Diameter</title>
    <summary>  We propose a simple graphical approach to steady state solutions of the cable
equation for a general model of dendritic tree with tapering. A simple case of
transient solutions is also briefly discussed.
</summary>
    <author>
      <name>Marco Herrera-Valdez</name>
    </author>
    <author>
      <name>Sergei K. Suslov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6217v2</id>
    <updated>2012-01-05T01:59:35Z</updated>
    <published>2011-11-27T02:18:31Z</published>
    <title>A cell-type based model explaining co-expression patterns of genes in
  the brain</title>
    <summary>  Much of the genome is expressed in the vertebrate brain, with individual
genes exhibiting different spatially-varying patterns of expression. These
variations are not independent, with pairs of genes exhibiting complex patterns
of co-expression, such that two genes may be similarly expressed in one region,
but differentially expressed in other regions. These correlations have been
previously studied quantitatively, particularly for the gene expression atlas
of the mouse brain, but the biological meaning of the co-expression patterns
remains obscure. We propose a simple model of the co-expression patterns in
terms of spatial distributions of underlying cell types. We establish the
plausibility of the model in terms of a test set of cell types for which both
the gene expression profiles and the spatial distributions are known.
</summary>
    <author>
      <name>Pascal Grange</name>
    </author>
    <author>
      <name>Jason Bohland</name>
    </author>
    <author>
      <name>Hemant Bokil</name>
    </author>
    <author>
      <name>Sacha Nelson</name>
    </author>
    <author>
      <name>Benjamin Okaty</name>
    </author>
    <author>
      <name>Ken Sugino</name>
    </author>
    <author>
      <name>Lydia Ng</name>
    </author>
    <author>
      <name>Michael Hawrylycz</name>
    </author>
    <author>
      <name>Partha P. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages; v2: typos corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6217v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6217v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4017v1</id>
    <updated>2012-09-15T16:24:33Z</updated>
    <published>2012-09-15T16:24:33Z</published>
    <title>Mozart Effect, Cognitive Dissonance, and the Pleasure of Music</title>
    <summary>  The Mozart effect refers to scientific data on short-term improvement on
certain mental tasks after listening to Mozart, and also to its popularized
version that listening to Mozart makes you smarter (Tomatis, 1991; Wikipedia,
2012). Does Mozart effect point to a fundamental cognitive function of music?
Would such an effect of music be due to the hedonicity, a fundamental dimension
of mental experience? The present paper explores a recent hypothesis that music
helps to tolerate cognitive dissonances and thus enabled accumulation of
knowledge and human cultural evolution (Perlovsky, 2010, 2012). We studied
whether the influence of music is related to its hedonicity and whether
pleasant or unpleasant music would influence scholarly test performance and
cognitive dissonance. Specific hypotheses evaluated here are that during a test
students experience contradictory cognitions that cause cognitive dissonances.
If some music helps to tolerate cognitive dissonances, then first, this music
should increase the duration during which participants can tolerate stressful
conditions while evaluating test choices. Second, this should result in
improved performance. These hypotheses are tentatively confirmed in the
reported experiments as the agreeable music was correlated with better
performance above that under indifferent or unpleasant music. It follows that
music likely performs a fundamental cognitive function explaining the origin
and evolution of musical ability considered previously a mystery.
</summary>
    <author>
      <name>Leonid Perlovsky</name>
    </author>
    <author>
      <name>Arnaud Cabanac</name>
    </author>
    <author>
      <name>Marie-Claude Bonniot-Cabanac</name>
    </author>
    <author>
      <name>Michel Cabanac</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5559v1</id>
    <updated>2012-09-25T09:51:33Z</updated>
    <published>2012-09-25T09:51:33Z</published>
    <title>Dynamic State Estimation Based on Poisson Spike Trains: Towards a Theory
  of Optimal Encoding</title>
    <summary>  Neurons in the nervous system convey information to higher brain regions by
the generation of spike trains. An important question in the field of
computational neuroscience is how these sensory neurons encode environmental
information in a way which may be simply analyzed by subsequent systems. Many
aspects of the form and function of the nervous system have been understood
using the concepts of optimal population coding. Most studies, however, have
neglected the aspect of temporal coding. Here we address this shortcoming
through a filtering theory of inhomogeneous Poisson processes. We derive exact
relations for the minimal mean squared error of the optimal Bayesian filter and
by optimizing the encoder, obtain optimal codes for populations of neurons. We
also show that a class of non-Markovian, smooth stimuli are amenable to the
same treatment, and provide results for the filtering and prediction error
which hold for a general class of stochastic processes. This sets a sound
mathematical framework for a population coding theory that takes temporal
aspects into account. It also formalizes a number of studies which discussed
temporal aspects of coding using time-window paradigms, by stating them in
terms of correlation times and firing rates. We propose that this kind of
analysis allows for a systematic study of temporal coding and will bring
further insights into the nature of the neural code.
</summary>
    <author>
      <name>Alex Susemihl</name>
    </author>
    <author>
      <name>Ron Meir</name>
    </author>
    <author>
      <name>Manfred Opper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2013/03/P03009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2013) P03009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5006v1</id>
    <updated>2012-09-22T17:30:53Z</updated>
    <published>2012-09-22T17:30:53Z</published>
    <title>Implicit embedding of prior probabilities in optimally efficient neural
  populations</title>
    <summary>  We examine how the prior probability distribution of a sensory variable in
the environment influences the optimal allocation of neurons and spikes in a
population that represents that variable. We start with a conventional response
model, in which the spikes of each neuron are drawn from a Poisson distribution
with a mean rate governed by an associated tuning curve. For this model, we
approximate the Fisher information in terms of the density and amplitude of the
tuning curves, under the assumption that tuning width varies inversely with
cell density. We consider a family of objective functions based on the expected
value, over the sensory prior, of a functional of the Fisher information. This
family includes lower bounds on mutual information and perceptual
discriminability as special cases. For all cases, we obtain a closed form
expression for the optimum, in which the density and gain of the cells in the
population are power law functions of the stimulus prior. Thus, the allocation
of these resources is uniquely specified by the prior. Since perceptual
discriminability may be expressed directly in terms of the Fisher information,
it too will be a power law function of the prior. We show that these results
hold for tuning curves of arbitrary shape and correlated neuronal variability.
This framework thus provides direct and experimentally testable predictions
regarding the relationship between sensory priors, tuning properties of neural
representations, and perceptual discriminability.
</summary>
    <author>
      <name>Deep Ganguli</name>
    </author>
    <author>
      <name>Eero Simoncelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, generalizes and extends Ganguli &amp; Simoncelli,
  NIPS 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.5006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2491v1</id>
    <updated>2012-02-12T06:22:12Z</updated>
    <published>2012-02-12T06:22:12Z</published>
    <title>Analysis of inverse stochastic resonance and the long-term firing of
  Hodgkin-Huxley neurons with Gaussian white noise</title>
    <summary>  In previous articles we have investigated the firing properties of the
standard Hodgkin-Huxley (HH) systems of ordinary and partial differential
equations in response to input currents composed of a drift (mean) and additive
Gaussian white noise. For certain values of the mean current, as the noise
amplitude increased from zero, the firing rate exhibited a minimum and this
phenomenon was called inverse stochastic resonance (ISR). Here we analyse the
underlying transitions from a stable equilibrium point to the limit cycle and
vice-versa. Focusing on the case of a mean input current density $\mu=6.8$ at
which repetitive firing occurs and ISR had been found to be pronounced, some of
the properties of the corresponding stable equilibrium point are found. A
linearized approximation around this point has oscillatory solutions from whose
maxima spikes tend to occur. A one dimensional diffusion is also constructed
for small noise based on the correlations between the pairs of HH variables and
the small magnitudes of the fluctuations in two of them.
  Properties of the basin of attraction of the limit cycle (spike) are
investigated heuristically and also the nature of distribution of spikes at
very small noise corresponding to trajectories which do not ever enter the
basin of attraction of the equilibrium point. Long term trials of duration
500000 ms are carried out for values of the noise parameter $\sigma$ from 0 to
2.0, with results appearing in Section 3. The graph of mean spike count versus
$\sigma$ is divided into 4 regions $R_1,...,R_4,$ where $R_3$ contains the
minimum associated with ISR.
</summary>
    <author>
      <name>Henry C. Tuckwell</name>
    </author>
    <author>
      <name>Jürgen Jost</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.2491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.0836v1</id>
    <updated>2012-02-03T22:31:39Z</updated>
    <published>2012-02-03T22:31:39Z</published>
    <title>Markov models for fMRI correlation structure: is brain functional
  connectivity small world, or decomposable into networks?</title>
    <summary>  Correlations in the signal observed via functional Magnetic Resonance Imaging
(fMRI), are expected to reveal the interactions in the underlying neural
populations through hemodynamic response. In particular, they highlight
distributed set of mutually correlated regions that correspond to brain
networks related to different cognitive functions. Yet graph-theoretical
studies of neural connections give a different picture: that of a highly
integrated system with small-world properties: local clustering but with short
pathways across the complete structure. We examine the conditional independence
properties of the fMRI signal, i.e. its Markov structure, to find realistic
assumptions on the connectivity structure that are required to explain the
observed functional connectivity. In particular we seek a decomposition of the
Markov structure into segregated functional networks using decomposable graphs:
a set of strongly-connected and partially overlapping cliques. We introduce a
new method to efficiently extract such cliques on a large, strongly-connected
graph. We compare methods learning different graph structures from functional
connectivity by testing the goodness of fit of the model they learn on new
data. We find that summarizing the structure as strongly-connected networks can
give a good description only for very large and overlapping networks. These
results highlight that Markov models are good tools to identify the structure
of brain connectivity from fMRI signals, but for this purpose they must reflect
the small-world properties of the underlying neural systems.
</summary>
    <author>
      <name>Gaël Varoquaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Alexandre Gramfort</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Baptiste Poline</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Bertrand Thirion</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jphysparis.2012.01.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jphysparis.2012.01.001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Physiology - Paris (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.0836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.0836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3169v2</id>
    <updated>2012-09-29T07:50:47Z</updated>
    <published>2012-07-13T08:43:17Z</published>
    <title>The law of brevity in macaque vocal communication is not an artifact of
  analyzing mean call durations</title>
    <summary>  Words follow the law of brevity, i.e. more frequent words tend to be shorter.
From a statistical point of view, this qualitative definition of the law states
that word length and word frequency are negatively correlated. Here the recent
finding of patterning consistent with the law of brevity in Formosan macaque
vocal communication (Semple et al., 2010) is revisited. It is shown that the
negative correlation between mean duration and frequency of use in the
vocalizations of Formosan macaques is not an artifact of the use of a mean
duration for each call type instead of the customary 'word' length of studies
of the law in human language. The key point demonstrated is that the total
duration of calls of a particular type increases with the number of calls of
that type. The finding of the law of brevity in the vocalizations of these
macaques therefore defies a trivial explanation.
</summary>
    <author>
      <name>Stuart Semple</name>
    </author>
    <author>
      <name>Minna J. Hsu</name>
    </author>
    <author>
      <name>Govindasamy Agoramoorthy</name>
    </author>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/09296174.2013.799917</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/09296174.2013.799917" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Little improvements of the statistical arguments</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Quantitative Linguistics, 20 (3), 209-217 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.3169v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3169v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0271v1</id>
    <updated>2010-12-31T16:34:58Z</updated>
    <published>2010-12-31T16:34:58Z</published>
    <title>Fast dynamics of odor rate coding in the insect antennal lobe</title>
    <summary>  Insects identify and evaluate behaviorally relevant odorants in complex
natural scenes where odor concentrations and mixture composition can change
rapidly. In the honeybee, a combinatorial code of activated and inactivated
projection neurons (PNs) develops rapidly within tens of milliseconds at the
first level of neural integration, the antennal lobe (AL). The phasic-tonic
stimulus-response dynamics observed in the neural population code and in the
firing rate profiles of single neurons is faithfully captured by two
alternative models which rely either on short-term synaptic depression, or on
spike frequency adaptation. Both mechanisms work independently and possibly in
parallel to lateral inhibition. Short response latencies in local interneurons
indicate that local processing within the AL network relies on fast lateral
inhibition that can suppress effectively and specifically odor responses in
single PNs. Reviewing recent findings obtained in different insect species, we
conclude that the insect olfactory system implements a fast and reliable coding
scheme optimized for time-varying input within the behaviorally relevant
dynamic range.
</summary>
    <author>
      <name>Martin Paul Nawrot</name>
    </author>
    <author>
      <name>Sabine Krofczik</name>
    </author>
    <author>
      <name>Farzad Farkhooi</name>
    </author>
    <author>
      <name>Randolf Menzel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures; keywords: combinatorial code, latency code,
  lateral inhibition, short term depression, spike frequency adaptation,
  olfaction, honeybee</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4239v3</id>
    <updated>2013-12-11T23:05:11Z</updated>
    <published>2012-12-18T06:36:34Z</published>
    <title>Local paths to global coherence: cutting networks down to size</title>
    <summary>  How does connectivity impact network dynamics? We address this question by
linking network characteristics on two scales. On the global scale we consider
the coherence of overall network dynamics. We show that such \emph{global
coherence} in activity can often be predicted from the \emph{local structure}
of the network. To characterize local network structure we use "motif
cumulants," a measure of the deviation of pathway counts from those expected in
a minimal probabilistic network model.
  We extend previous results in three ways. First, we give a new combinatorial
formulation of motif cumulants that relates to the allied concept in
probability theory. Second, we show that the link between global network
dynamics and local network architecture is strongly affected by heterogeneity
in network connectivity. However, we introduce a network-partitioning method
that recovers a tight relationship between architecture and dynamics. Third,
for a particular set of models we generalize the underlying theory to treat
dynamical coherence at arbitrary orders (i.e. triplet correlations, and
beyond). We show that at any order only a highly restricted set of motifs
impact dynamical correlations.
</summary>
    <author>
      <name>Yu Hu</name>
    </author>
    <author>
      <name>James Trousdale</name>
    </author>
    <author>
      <name>Krešimir Josić</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.4239v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4239v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.0166v1</id>
    <updated>2011-02-01T14:32:38Z</updated>
    <published>2011-02-01T14:32:38Z</published>
    <title>Hebbian learning of recurrent connections: a geometrical perspective</title>
    <summary>  We show how a Hopfield network with modifiable recurrent connections
undergoing slow Hebbian learning can extract the underlying geometry of an
input space. First, we use a slow/fast analysis to derive an averaged system
whose dynamics derives from an energy function and therefore always converges
to equilibrium points. The equilibria reflect the correlation structure of the
inputs, a global object extracted through local recurrent interactions only.
Second, we use numerical methods to illustrate how learning extracts the hidden
geometrical structure of the inputs. Indeed, multidimensional scaling methods
make it possible to project the final connectivity matrix on to a distance
matrix in a high-dimensional space, with the neurons labelled by spatial
position within this space. The resulting network structure turns out to be
roughly convolutional. The residual of the projection defines the
non-convolutional part of the connectivity which is minimized in the process.
Finally, we show how restricting the dimension of the space where the neurons
live gives rise to patterns similar to cortical maps. We motivate this using an
energy efficiency argument based on wire length minimization. Finally, we show
how this approach leads to the emergence of ocular dominance or orientation
columns in primary visual cortex. In addition, we establish that the
non-convolutional (or long-range) connectivity is patchy, and is co-aligned in
the case of orientation learning.
</summary>
    <author>
      <name>Mathieu N. Galtier</name>
    </author>
    <author>
      <name>Olivier D. Faugeras</name>
    </author>
    <author>
      <name>Paul C. Bressloff</name>
    </author>
    <link href="http://arxiv.org/abs/1102.0166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.0166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3570v1</id>
    <updated>2011-01-17T20:38:38Z</updated>
    <published>2011-01-17T20:38:38Z</published>
    <title>Processes of the correlation of space (lengths) and time (duration)in
  human perception</title>
    <summary>  To study the processes and mechanisms of the correlation between space and
time, particularly between lengths and durations in human perception, a special
method (device and procedure) to conduct this experiment was designed and
called LDR (Length Duration Relation) In the present study a pilot and three
series of the primary experiment were conducted under conditions of different
levels of uncertainty. In all types of experiments, signals of a certain
duration and modality were presented twice in random order to the subjects.
Subjects had to respond to time signals of different durations by choosing a
corresponding space interval. The data which were obtained during the 1st and
the 2nd time signal presentations were examined separately. The comparative
data analysis of the experiment showed significant differences between the 1st
and 2nd presentation of signals in the quantity of correct responses, the
responses distribution along the scale of stimuli, the phenomena which occurred
during the experiment. The higher level of uncertainty condition under which a
certain type of the experiment was conducted, the more clearly this difference
was manifested.
  Based on results of the experiments comparative data analysis, one can
suppose that the perceptive mechanism, named by us as an innate mechanism of
proportionality, performed the correlation of these intervals into two stages:
adaptation and activation
</summary>
    <author>
      <name>Lev Isaakovich Soyfer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The text of this work, which totals of 183 pages, consists of seven
  chapters, references, and four appendices. Major part of the work includes 30
  tables and 3 figures. Appendices consist of 37 tables and 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.3570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4339v1</id>
    <updated>2012-01-20T17:04:18Z</updated>
    <published>2012-01-20T17:04:18Z</published>
    <title>Recognizing recurrent neural networks (rRNN): Bayesian inference for
  recurrent neural networks</title>
    <summary>  Recurrent neural networks (RNNs) are widely used in computational
neuroscience and machine learning applications. In an RNN, each neuron computes
its output as a nonlinear function of its integrated input. While the
importance of RNNs, especially as models of brain processing, is undisputed, it
is also widely acknowledged that the computations in standard RNN models may be
an over-simplification of what real neuronal networks compute. Here, we suggest
that the RNN approach may be made both neurobiologically more plausible and
computationally more powerful by its fusion with Bayesian inference techniques
for nonlinear dynamical systems. In this scheme, we use an RNN as a generative
model of dynamic input caused by the environment, e.g. of speech or kinematics.
Given this generative RNN model, we derive Bayesian update equations that can
decode its output. Critically, these updates define a 'recognizing RNN' (rRNN),
in which neurons compute and exchange prediction and prediction error messages.
The rRNN has several desirable features that a conventional RNN does not have,
for example, fast decoding of dynamic stimuli and robustness to initial
conditions and noise. Furthermore, it implements a predictive coding scheme for
dynamic inputs. We suggest that the Bayesian inversion of recurrent neural
networks may be useful both as a model of brain function and as a machine
learning tool. We illustrate the use of the rRNN by an application to the
online decoding (i.e. recognition) of human kinematics.
</summary>
    <author>
      <name>Sebastian Bitzer</name>
    </author>
    <author>
      <name>Stefan J. Kiebel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00422-012-0490-x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00422-012-0490-x" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Biological Cybernetics 106(4): 201-217, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.4339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3933v1</id>
    <updated>2011-10-18T10:47:38Z</updated>
    <published>2011-10-18T10:47:38Z</published>
    <title>About the Neuronal Mechanism of Lateral Hypothalamic Self-Stimulation
  Response</title>
    <summary>  The experimental part of this study has shown that hunger motivation may be
evoked by a long-term (10=180 s) continuous electrical stimulation of the
"hunger center" at a current of 133.6{\pm}8.1 mkA. Positive emotions were
caused by electrostimulation at the same current intensity but short-term
duration (0.3-0.5 s). A positive feeling elicited by electrostimulation of the
motivation center can be explained in terms of the adaptation (polarization)
theory of motivation and emotion (Murik, 2001, 2005).
</summary>
    <author>
      <name>Sergey E. Murik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures; Journal article in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bulletin of Irkutsk State University. A Biology and Ecology
  series. 2010, vol.,3, No.2, pp.65-74</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.3933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92C20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5952v1</id>
    <updated>2011-03-30T14:56:50Z</updated>
    <published>2011-03-30T14:56:50Z</published>
    <title>Visible light induced ocular delayed bioluminescence as a possible
  origin of negative afterimage</title>
    <summary>  The delayed luminescence of biological tissues is an ultraweak reemission of
absorbed photons after exposure to external monochromatic or white light
illumination. Recently, Wang, B\'okkon, Dai and Antal (Brain Res. 2011)
presented the first experimental proof of the existence of spontaneous
ultraweak biophoton emission and visible light induced delayed ultraweak photon
emission from in vitro freshly isolated rat's whole eye, lens, vitreous humor
and retina. Here, we suggest that the photobiophysical source of negative
afterimage can also occur within the eye by delayed bioluminescent photons. In
other words, when we stare at a colored (or white) image for few seconds,
external photons can induce excited electronic states within different parts of
the eye that is followed by a delayed reemission of absorbed photons for
several seconds. Finally, these reemitted photons can be absorbed by
nonbleached photoreceptors that produce a negative afterimage. Although this
suggests the photobiophysical source of negative afterimages is related retinal
mechanisms, cortical neurons have also essential contribution in the
interpretation and modulation of negative afterimages.
</summary>
    <author>
      <name>I. Bokkon</name>
    </author>
    <author>
      <name>R. L. P. Vimal</name>
    </author>
    <author>
      <name>C. Wang</name>
    </author>
    <author>
      <name>J. Dai</name>
    </author>
    <author>
      <name>V. Salari</name>
    </author>
    <author>
      <name>F. Grass</name>
    </author>
    <author>
      <name>I. Antal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted to be published in J. Photochem. Photobiol. B</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J Photochem Photobiol B , 103 , 192-199, (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.5952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2659v3</id>
    <updated>2012-10-20T14:49:10Z</updated>
    <published>2012-08-13T18:38:52Z</published>
    <title>A power-law distribution of phase-locking intervals does not imply
  critical interaction</title>
    <summary>  Neural synchronisation plays a critical role in information processing,
storage and transmission. Characterising the pattern of synchronisation is
therefore of great interest. It has recently been suggested that the brain
displays broadband criticality based on two measures of synchronisation - phase
locking intervals and global lability of synchronisation - showing power law
statistics at the critical threshold in a classical model of synchronisation.
In this paper, we provide evidence that, within the limits of the model
selection approach used to ascertain the presence of power law statistics, the
pooling of pairwise phase-locking intervals from a non-critically interacting
system can produce a distribution that is similarly assessed as being power
law. In contrast, the global lability of synchronisation measure is shown to
better discriminate critical from non critical interaction.
</summary>
    <author>
      <name>Maria Botcharova</name>
    </author>
    <author>
      <name>Simon F. Farmer</name>
    </author>
    <author>
      <name>Luc Berthouze</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.86.051920</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.86.051920" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">(v3) Fixed error in Figure 1; (v2) Added references. Minor edits
  throughout. Clarified relationship between theoretical critical coupling for
  infinite size system and 'effective' critical coupling system for finite size
  system. Improved presentation and discussion of results; results unchanged.
  Revised Figure 1 to include error bars on r and N; results unchanged; (v1) 11
  pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 86, 051920 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.2659v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2659v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4526v1</id>
    <updated>2011-11-19T02:36:39Z</updated>
    <published>2011-11-19T02:36:39Z</published>
    <title>Signal Propagation in Feedforward Neuronal Networks with Unreliable
  Synapses</title>
    <summary>  In this paper, we systematically investigate both the synfire propagation and
firing rate propagation in feedforward neuronal network coupled in an
all-to-all fashion. In contrast to most earlier work, where only reliable
synaptic connections are considered, we mainly examine the effects of
unreliable synapses on both types of neural activity propagation in this work.
We first study networks composed of purely excitatory neurons. Our results show
that both the successful transmission probability and excitatory synaptic
strength largely influence the propagation of these two types of neural
activities, and better tuning of these synaptic parameters makes the considered
network support stable signal propagation. It is also found that noise has
significant but different impacts on these two types of propagation. The
additive Gaussian white noise has the tendency to reduce the precision of the
synfire activity, whereas noise with appropriate intensity can enhance the
performance of firing rate propagation. Further simulations indicate that the
propagation dynamics of the considered neuronal network is not simply
determined by the average amount of received neurotransmitter for each neuron
in a time instant, but also largely influenced by the stochastic effect of
neurotransmitter release. Second, we compare our results with those obtained in
corresponding feedforward neuronal networks connected with reliable synapses
but in a random coupling fashion. We confirm that some differences can be
observed in these two different feedforward neuronal network models. Finally,
we study the signal propagation in feedforward neuronal networks consisting of
both excitatory and inhibitory neurons, and demonstrate that inhibition also
plays an important role in signal propagation in the considered networks.
</summary>
    <author>
      <name>Daqing Guo</name>
    </author>
    <author>
      <name>Chunguang Li</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10827-010-0279-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10827-010-0279-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33pages, 16 figures; Journal of Computational Neuroscience
  (published)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4386v2</id>
    <updated>2013-08-02T17:06:46Z</updated>
    <published>2012-06-20T05:38:06Z</published>
    <title>An Evolutionary Framework for Culture: Selectionism versus Communal
  Exchange</title>
    <summary>  Dawkins' replicator-based conception of evolution has led to widespread
mis-application selectionism across the social sciences because it does not
address the paradox that inspired the theory of natural selection in the first
place: how do organisms accumulate change when traits acquired over their
lifetime are obliterated? This is addressed by von Neumann's concept of a
self-replicating automaton (SRA). A SRA consists of a self-assembly code that
is used in two distinct ways: (1) actively deciphered during development to
construct a self-similar replicant, and (2) passively copied to the replicant
to ensure that it can reproduce. Information that is acquired over a lifetime
is not transmitted to offspring, whereas information that is inherited during
copying is transmitted. In cultural evolution there is no mechanism for
discarding acquired change. Acquired change can accumulate orders of magnitude
faster than, and quickly overwhelm, inherited change due to differential
replication of variants in response to selection. This prohibits a selectionist
but not an evolutionary framework for culture. Recent work on the origin of
life suggests that early life evolved through a non-Darwinian process referred
to as communal exchange that does not involve a self-assembly code, and that
natural selection emerged from this more haphazard, ancestral evolutionary
process. It is proposed that communal exchange provides a more appropriate
evolutionary framework for culture than selectionism. This is supported by a
computational model of cultural evolution and a network-based program for
documenting material cultural history, and it is consistent with high levels of
human cooperation.
</summary>
    <author>
      <name>Liane Gabora</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.plrev.2013.03.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.plrev.2013.03.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages; 2 tables and 11 figures embedded in text</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physics of Life Reviews, 10(2), 117-145</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4386v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4386v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1395v1</id>
    <updated>2012-04-06T02:04:55Z</updated>
    <published>2012-04-06T02:04:55Z</published>
    <title>mGluR5 Knockout mice exhibit normal conditioned place-preference to
  cocaine</title>
    <summary>  Metabotropic glutamate receptor 5 (mGluR5) null mutant (-/-) mice have been
reported to totally lack the rein- forcing or locomotor stimulating effects of
cocaine. We tested mGluR5 -/- and +/+ mice for their locomotor and conditioned
place- preference response to cocaine. Unlike the previous finding, here we
show that compared to mGluR5 +/+ mice, -/- mice exhibit no difference in the
locomotor response to low to moderate doses of cocaine (10 or 20 mg/kg). A high
dose of cocaine (40 mg/kg) resulted in a blunted rather than absent locomo- tor
response. We tested mGluR5 -/- and +/+ mice for conditioned place-preference to
cocaine and found no group differences at a conditioning dose of 10 mg/kg,
suggesting normal conditioned rewarding properties of cocaine. These results
differ substantially from Chiamulera et al. (2001) and replicates Olsen et al.,
(2010), who found normal cocaine place-preference in mGluR5 -/- mice at 5
mg/kg. Our results indicate mGluR5 receptors exert a modulatory rather than
necessary role in cocaine-induced locomotor stimulation and exert no effect on
the conditioned rewarding effects of cocaine.
</summary>
    <author>
      <name>Melissa A. Fowler</name>
    </author>
    <author>
      <name>Andrew L. Varnell</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/npre.2011.6180.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/npre.2011.6180.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages,2 figures Nature Precedings
  http://precedings.nature.com/documents/6180/version/2</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6062v1</id>
    <updated>2011-11-25T17:35:01Z</updated>
    <published>2011-11-25T17:35:01Z</published>
    <title>Simple, Fast and Accurate Implementation of the Diffusion Approximation
  Algorithm for Stochastic Ion Channels with Multiple States</title>
    <summary>  The phenomena that emerge from the interaction of the stochastic opening and
closing of ion channels (channel noise) with the non-linear neural dynamics are
essential to our understanding of the operation of the nervous system. The
effects that channel noise can have on neural dynamics are generally studied
using numerical simulations of stochastic models. Algorithms based on discrete
Markov Chains (MC) seem to be the most reliable and trustworthy, but even
optimized algorithms come with a non-negligible computational cost. Diffusion
Approximation (DA) methods use Stochastic Differential Equations (SDE) to
approximate the behavior of a number of MCs, considerably speeding up
simulation times. However, model comparisons have suggested that DA methods did
not lead to the same results as in MC modeling in terms of channel noise
statistics and effects on excitability. Recently, it was shown that the
difference arose because MCs were modeled with coupled activation subunits,
while the DA was modeled using uncoupled activation subunits. Implementations
of DA with coupled subunits, in the context of a specific kinetic scheme,
yielded similar results to MC. However, it remained unclear how to generalize
these implementations to different kinetic schemes, or whether they were faster
than MC algorithms. Additionally, a steady state approximation was used for the
stochastic terms, which, as we show here, can introduce significant
inaccuracies. We derived the SDE explicitly for any given ion channel kinetic
scheme. The resulting generic equations were surprisingly simple and
interpretable - allowing an easy and efficient DA implementation. The algorithm
was tested in a voltage clamp simulation and in two different current clamp
simulations, yielding the same results as MC modeling. Also, the simulation
efficiency of this DA method demonstrated considerable superiority over MC
methods.
</summary>
    <author>
      <name>Patricio Orio</name>
    </author>
    <author>
      <name>Daniel Soudry</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0036670</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0036670" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 text pages, 10 figures, 1 supplementary text + figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 7(2012) e36670</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4085v1</id>
    <updated>2012-07-17T18:51:17Z</updated>
    <published>2012-07-17T18:51:17Z</published>
    <title>A Simple Probabilistic and Point-process Response Model for Predicting
  Every Spike in Optogenetics</title>
    <summary>  Optogenetics is a new tool to stimulate genetically targeted neuronal
circuits using light flashes that can be delivered at high frequencies. It has
shown promise for studying neural circuits that are critically involved in
normal behavior as well as neuropsychiatric disorders. The data from
experiments in which circuits are stimulated by optogenetics presents the
statistical challenge of modeling a high frequency point process (neuronal
spikes) while the input is another high frequency point process (light
flashes). We propose a new simple probabilistic approach to model the
relationships between two point processes which employs additive point-process
response functions on the logit scale. The resulting model, Point-process
Responses for Optogenetics (PRO), provides explicit nonlinear transformations
to link the input point process with the output one. Such response functions
may provide important and interpretable scientific insights into properties of
the biophysical process that govern neural spiking in response to optogenetics
stimulation. We validate the PRO model via out-of-sample prediction on a large
dataset from optogenetics experiments. Compared with other statistical and
biophysical models, the PRO model yields a superior area-under-the-curve value
as high as 93% for predicting every future spike within a 5ms interval. Another
advantage of the PRO model is its efficient computation via standard logistic
regression procedures. We also demonstrate by simulation that the PRO model
performs well for neurons following the classical Leaky Integrate and Fire
(LIF) model. A spline extension of the PRO approach is also illustrated.
Finally, the PRO model outputs a few simple parameters summarizing how neurons
integrate specific patterns of light inputs.
</summary>
    <author>
      <name>Xi Luo</name>
    </author>
    <author>
      <name>Steven Gee</name>
    </author>
    <author>
      <name>Vikaas S. Sohal</name>
    </author>
    <author>
      <name>Dylan S. Small</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures. Presented at Sixth International Workshop on
  Statistical Analysis of Neuronal Data (SAND6) by University of Pittsburgh and
  Carneigie Mellon University on June 1 2012, and Brown Institute of Brain
  Sciences of Brown University on December 8 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.4085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2104v1</id>
    <updated>2012-10-07T21:02:16Z</updated>
    <published>2012-10-07T21:02:16Z</published>
    <title>Complexity without chaos: Plasticity within random recurrent networks
  generates robust timing and motor control</title>
    <summary>  It is widely accepted that the complex dynamics characteristic of recurrent
neural circuits contributes in a fundamental manner to brain function. Progress
has been slow in understanding and exploiting the computational power of
recurrent dynamics for two main reasons: nonlinear recurrent networks often
exhibit chaotic behavior and most known learning rules do not work in robust
fashion in recurrent networks. Here we address both these problems by
demonstrating how random recurrent networks (RRN) that initially exhibit
chaotic dynamics can be tuned through a supervised learning rule to generate
locally stable neural patterns of activity that are both complex and robust to
noise. The outcome is a novel neural network regime that exhibits both
transiently stable and chaotic trajectories. We further show that the recurrent
learning rule dramatically increases the ability of RRNs to generate complex
spatiotemporal motor patterns, and accounts for recent experimental data
showing a decrease in neural variability in response to stimulus onset.
</summary>
    <author>
      <name>Rodrigo Laje</name>
    </author>
    <author>
      <name>Dean V. Buonomano</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/nn.3405</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/nn.3405" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nat. Neurosci. 16 (2013) 925-933</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.2104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6524v1</id>
    <updated>2011-09-29T13:37:34Z</updated>
    <published>2011-09-29T13:37:34Z</published>
    <title>Role of correlations in population coding</title>
    <summary>  Correlations among spikes, both on the same neuron and across neurons, are
ubiquitous in the brain. For example cross-correlograms can have large peaks,
at least in the periphery, and smaller -- but still non-negligible -- ones in
cortex, and auto-correlograms almost always exhibit non-trivial temporal
structure at a range of timescales. Although this has been known for over forty
years, it's still not clear what role these correlations play in the brain --
and, indeed, whether they play any role at all. The goal of this chapter is to
shed light on this issue by reviewing some of the work on this subject.
</summary>
    <author>
      <name>Peter E. Latham</name>
    </author>
    <author>
      <name>Yasser Roudi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in "Principles of Neural Coding", edited by Stefano Panzeri
  and Rodrigo Quian Quiroga</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.6524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3411v1</id>
    <updated>2012-09-15T14:28:54Z</updated>
    <published>2012-09-15T14:28:54Z</published>
    <title>A Computational Model of the Effects of Drug Addiction on Neural
  Population Dynamics</title>
    <summary>  Reward processing and derangements thereof, such as drug addiction, involve
the coordinated activity of many brain areas. Prior work has identified many
behavioral, molecular biological and single neuron changes throughout the
mesocorticolimbic system that reflect and drive addictive behavior.
Subpopulations in the ventral tegemental area (VTA) encode positive reward
prediction error, negative reward prediction error, and the magnitude of the
reward. Phasic activity in VTA dopaminergic neurons correlates with hedonic
value. Tonic activity of groups in the dorsomedial prefrontal cortex (dmPFC)
can encode antidepressant states. However, little is known about how drug
addiction might affect population encoding across larger brain regions. Here,
we compare the information content associated with network patterns in naive,
acutely intoxicated and chronically addicted states in a plastic attractor
network. We found that addiction decreases the network's ability to store and
discriminate among patterns of activity. Altered dopaminergic tone flattens the
energy landscape and decreases the entropy associated with each network
pattern. Altered dmPFC activity produces signal-to-noise deficits similar to
computational models of schizophrenia. Our results provide a conceptual
framework for interpreting altered neural population dynamics in
psychopathological states based on information theory. They also suggest a view
of the subtypes of depression as on a continuum of combinations of cortical and
subcortical dysfunction. This suggests that patients who suffer from depression
with psychotic features will have more cortical than mesolimbic dysfunction.
Furthermore, our framework can be applied to other psychiatric illnesses and so
may help us, in general, quantitatively understand psychiatric illnesses as
disorders in the representation and processing of information by distributed
brain networks.
</summary>
    <author>
      <name>Michael Chary</name>
    </author>
    <link href="http://arxiv.org/abs/1209.3411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8406v1</id>
    <updated>2012-10-31T17:29:31Z</updated>
    <published>2012-10-31T17:29:31Z</published>
    <title>Neutral stability, rate propagation, and critical branching in
  feedforward networks</title>
    <summary>  Recent experimental and computational evidence suggests that several
dynamical properties may characterize the operating point of functioning neural
networks: critical branching, neutral stability, and production of a wide range
of firing patterns. We seek the simplest setting in which these properties
emerge, clarifying their origin and relationship in random, feedforward
networks of McCullochs-Pitts neurons. Two key parameters are the thresholds at
which neurons fire spikes, and the overall level of feedforward connectivity.
When neurons have low thresholds, we show that there is always a connectivity
for which the properties in question all occur: that is, these networks
preserve overall firing rates from layer to layer and produce broad
distributions of activity in each layer. This fails to occur, however, when
neurons have high thresholds. A key tool in explaining this difference is
eigenstructure of the resulting mean-field Markov chain, as this reveals which
activity modes will be preserved from layer to layer. We extend our analysis
from purely excitatory networks to more complex models that include inhibition
and 'local' noise, and find that both of these features extend the parameter
ranges over which networks produce the properties of interest.
</summary>
    <author>
      <name>Natasha Cayco Gajic</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <link href="http://arxiv.org/abs/1210.8406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5539v1</id>
    <updated>2011-01-28T14:41:05Z</updated>
    <published>2011-01-28T14:41:05Z</published>
    <title>Stochastic Integrate and Fire Models: a review on mathematical methods
  and their applications</title>
    <summary>  Mathematical models are an important tool for neuroscientists. During the
last thirty years many papers have appeared on single neuron description and
specifically on stochastic Integrate and Fire models. Analytical results have
been proved and numerical and simulation methods have been developed for their
study. Reviews appeared recently collect the main features of these models but
do not focus on the methodologies employed to obtain them. Aim of this paper is
to fill this gap by upgrading old reviews on this topic. The idea is to collect
the existing methods and the available analytical results for the most common
one dimensional stochastic Integrate and Fire models to make them available for
studies on networks. An effort to unify the mathematical notations is also
made. This review is divided in two parts: Derivation of the models with the
list of the available closed forms expressions for their characterization;
Presentation of the existing mathematical and statistical methods for the study
of these models.
</summary>
    <author>
      <name>Laura Sacerdote</name>
    </author>
    <author>
      <name>Maria Teresa Giraudo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">61 pages, 8 figures, submitted to Middelfart Summer School 2008,
  Springer Lecture Notes in Mathematics Biosciences</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G07, 92B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.5124v4</id>
    <updated>2012-03-12T14:02:54Z</updated>
    <published>2011-07-26T06:23:36Z</published>
    <title>A Mathematical model for Astrocytes mediated LTP at Single Hippocampal
  Synapses</title>
    <summary>  Many contemporary studies have shown that astrocytes play a significant role
in modulating both short and long form of synaptic plasticity. There are very
few experimental models which elucidate the role of astrocyte over Long-term
Potentiation (LTP). Recently, Perea &amp; Araque (2007) demonstrated a role of
astrocytes in induction of LTP at single hippocampal synapses. They suggested a
purely pre-synaptic basis for induction of this N-methyl-D- Aspartate (NMDA)
Receptor-independent LTP. Also, the mechanisms underlying this pre-synaptic
induction were not investigated. Here, in this article, we propose a
mathematical model for astrocyte modulated LTP which successfully emulates the
experimental findings of Perea &amp; Araque (2007). Our study suggests the role of
retrograde messengers, possibly Nitric Oxide (NO), for this pre-synaptically
modulated LTP.
</summary>
    <author>
      <name>Shivendra Tewari</name>
    </author>
    <author>
      <name>Kaushik Majumdar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10827-012-0389-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10827-012-0389-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">51 pages, 15 figures, Journal of Computational Neuroscience (to
  appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.5124v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.5124v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C20, 65C40, 92C05, 92C20, 92C37" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3966v1</id>
    <updated>2012-03-18T15:53:01Z</updated>
    <published>2012-03-18T15:53:01Z</published>
    <title>Grid Alignment in Entorhinal Cortex</title>
    <summary>  The spatial responses of many of the cells recorded in all layers of rodent
medial entorhinal cortex (mEC) show a triangular grid pattern, and once
established might be based in part on path-integration mechanisms. Grid axes
are tightly aligned across simultaneously recorded units. Recent experimental
findings have shown that grids can often be better described as elliptical
rather than purely circular and that, beyond the mutual alignment of their grid
axes, ellipses tend to also orient their long axis along preferred directions.
Are grid alignment and ellipse orientation the same phenomenon? Does the grid
alignment result from single-unit mechanisms or does it require network
interactions?
  We address these issues by refining our model, to describe specifically the
spontaneous emergence of conjunctive grid-by-head-direction cells in layers
III, V and VI of mEC. We find that tight alignment can be produced by recurrent
collateral interactions, but this requires head-direction modulation. Through a
competitive learning process driven by spatial inputs, grid fields then form
already aligned, and with randomly distributed spatial phases. In addition, we
find that the self-organization process is influenced by the behavior of the
simulated rat. The common grid alignment often orients along preferred running
directions. The shape of individual grids is distorted towards an ellipsoid
arrangement when some speed anisotropy is present in exploration behavior.
Speed anisotropy on its own also tends to align grids, even without
collaterals, but the alignment is seen to be loose. Finally, the alignment of
spatial grid fields in multiple environments shows that the network expresses
the same set of grid fields across environments, modulo a coherent rotation and
translation. Thus, an efficient metric encoding of space may emerge through
spontaneous pattern formation at the single-unit level.
</summary>
    <author>
      <name>Bailu Si</name>
    </author>
    <author>
      <name>Emilio Kropff</name>
    </author>
    <author>
      <name>Alessandro Treves</name>
    </author>
    <link href="http://arxiv.org/abs/1203.3966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0972v1</id>
    <updated>2012-08-05T01:24:00Z</updated>
    <published>2012-08-05T01:24:00Z</published>
    <title>Simultaneous Reduction of Two Common Autocalibration Errors in GRAPPA
  EPI Time Series Data</title>
    <summary>  The GRAPPA (GeneRalized Autocalibrating Partially Parallel Acquisitions)
method of parallel MRI makes use of an autocalibration scan (ACS) to determine
a set of synthesis coefficients to be used in the image reconstruction. For EPI
time series the ACS data is usually acquired once prior to the time series. In
this case the interleaved R-shot EPI trajectory, where R is the GRAPPA
reduction factor, offers advantages which we justify from a theoretical and
experimental perspective. Unfortunately, interleaved R-shot ACS can be
corrupted due to perturbations to the signal (such as direct and indirect
motion effects) occurring between the shots, and these perturbations may lead
to artifacts in GRAPPA-reconstructed images. Consequently we also present a
method of acquiring interleaved ACS data in a manner which can reduce the
effects of inter-shot signal perturbations. This method makes use of the phase
correction data, conveniently a part of many standard EPI sequences, to assess
the signal perturbations between the segments of R-shot EPI ACS scans. The
phase correction scans serve as navigator echoes, or more accurately a
perturbation-sensitive signal, to which a root-mean-square deviation
perturbation metric is applied for the determination of the best available
complete ACS data set among multiple complete sets of ACS data acquired prior
to the EPI time series. This best set (assumed to be that with the smallest
valued perturbation metric) is used in the GRAPPA autocalibration algorithm,
thereby permitting considerable improvement in both image quality and temporal
signal-to-noise ratio of the subsequent EPI time series at the expense of a
small increase in overall acquisition time.
</summary>
    <author>
      <name>D. Sheltraw</name>
    </author>
    <author>
      <name>B. Inglis</name>
    </author>
    <author>
      <name>V. Deshpande</name>
    </author>
    <author>
      <name>M. Trumpis</name>
    </author>
    <link href="http://arxiv.org/abs/1208.0972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3610v1</id>
    <updated>2011-11-15T19:01:36Z</updated>
    <published>2011-11-15T19:01:36Z</published>
    <title>Scaling of brain metabolism and blood flow in relation to capillary and
  neural scaling</title>
    <summary>  Brain is one of the most energy demanding organs in mammals, and its total
metabolic rate scales with brain volume raised to a power of around 5/6. This
value is significantly higher than the more common exponent 3/4 relating whole
body resting metabolism with body mass and several other physiological
variables in animals and plants. This article investigates the reasons for
brain allometric distinction on a level of its microvessels. Based on collected
empirical data it is found that regional cerebral blood flow CBF across gray
matter scales with cortical volume $V$ as $CBF \sim V^{-1/6}$, brain capillary
diameter increases as $V^{1/12}$, and density of capillary length decreases as
$V^{-1/6}$. It is predicted that velocity of capillary blood is almost
invariant ($\sim V^{\epsilon}$), capillary transit time scales as $V^{1/6}$,
capillary length increases as $V^{1/6+\epsilon}$, and capillary number as
$V^{2/3-\epsilon}$, where $\epsilon$ is typically a small correction for medium
and large brains, due to blood viscosity dependence on capillary radius. It is
shown that the amount of capillary length and blood flow per cortical neuron
are essentially conserved across mammals. These results indicate that geometry
and dynamics of global neuro-vascular coupling have a proportionate character.
Moreover, cerebral metabolic, hemodynamic, and microvascular variables scale
with allometric exponents that are simple multiples of 1/6, rather than 1/4,
which suggests that brain metabolism is more similar to the metabolism of
aerobic than resting body. Relation of these findings to brain functional
imaging studies involving the link between cerebral metabolism and blood flow
is also discussed.
</summary>
    <author>
      <name>Jan Karbowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0026709</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0026709" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">paper plus supporting material plus figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 6(10): e26709 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.3610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2801v2</id>
    <updated>2012-06-02T14:23:44Z</updated>
    <published>2011-05-13T18:41:15Z</published>
    <title>The geometry of spontaneous spiking in neuronal networks</title>
    <summary>  The mathematical theory of pattern formation in electrically coupled networks
of excitable neurons forced by small noise is presented in this work. Using the
Freidlin-Wentzell large deviation theory for randomly perturbed dynamical
systems and the elements of the algebraic graph theory, we identify and analyze
the main regimes in the network dynamics in terms of the key control
parameters: excitability, coupling strength, and network topology. The analysis
reveals the geometry of spontaneous dynamics in electrically coupled network.
Specifically, we show that the location of the minima of a certain continuous
function on the surface of the unit n-cube encodes the most likely activity
patterns generated by the network. By studying how the minima of this function
evolve under the variation of the coupling strength, we describe the principal
transformations in the network dynamics. The minimization problem is also used
for the quantitative description of the main dynamical regimes and transitions
between them. In particular, for the weak and strong coupling regimes, we
present asymptotic formulas for the network activity rate as a function of the
coupling strength and the degree of the network. The variational analysis is
complemented by the stability analysis of the synchronous state in the strong
coupling regime. The stability estimates reveal the contribution of the network
connectivity and the properties of the cycle subspace associated with the graph
of the network to its synchronization properties. This work is motivated by the
experimental and modeling studies of the ensemble of neurons in the Locus
Coeruleus, a nucleus in the brainstem involved in the regulation of cognitive
performance and behavior.
</summary>
    <author>
      <name>Georgi S. Medvedev</name>
    </author>
    <author>
      <name>Svitlana Zhuravytska</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00332-012-9125-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00332-012-9125-6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Nonlinear Science, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.2801v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2801v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4644v2</id>
    <updated>2011-12-31T08:45:32Z</updated>
    <published>2011-08-23T16:03:15Z</published>
    <title>Subspace-based Identification Algorithm for Characterizing Causal
  Networks in Resting Brain</title>
    <summary>  Analysis of brain activity in resting-state is of fundamental importance in
identifying functional characteristics of neuronal system. Although resting
brain has been extensively investigated for low frequency synchrony between
brain regions, namely Functional Connectivity (FC), the other main stream of
brain connectivity analysis that seeks causal interactions between brain
regions, Effective Connectivity (EC), has been little explored in spontaneous
brain oscillations. Inherent complexity of brain activities in resting-state,
as is observed in BOLD (Blood Oxygenation-Level Dependant) fluctuations, call
for exploratory methods for characterizing these causal networks. On the other
hand, the inevitable effects that hemodynamic system imposes on causal
inferences based on fMRI data, lead us toward the methods in which causal
inferences can take place in latent neuronal level, rather than observed BOLD
time-series. To simultaneously satisfy these two concerns, in this paper, we
introduce a novel state-space system identification approach for studying
causal interactions among brain regions in the absence of explicit cognitive
task. Using extensive simulations, we study the effects of network size and
signal to noise ratio (SNR) on the accuracy of our proposed method in EC
detection. Our simulations demonstrate that Subspace-based Identification
Algorithm (SIA) is sufficiently robust against above-mentioned factors, and can
reliably unravel the underlying causal interactions of resting-state BOLD fMRI
</summary>
    <author>
      <name>Shahab Kadkhodaeian Bakhtiari</name>
    </author>
    <author>
      <name>Gholam-Ali Hossein-Zadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in Neuroimage Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.4644v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4644v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2720v1</id>
    <updated>2012-08-13T22:20:05Z</updated>
    <published>2012-08-13T22:20:05Z</published>
    <title>High fidelity optogenetic control of individual prefrontal cortical
  pyramidal neurons in vivo</title>
    <summary>  Precise spatial and temporal manipulation of neural activity in specific
genetically defined cell populations is now possible with the advent of
optogenetics. The emerging field of optogenetics consists of a set of
naturally-occurring and engineered light-sensitive membrane proteins that are
able to activate (e.g., channelrhodopsin-2, ChR2) or silence (e.g.,
halorhodopsin, NpHR) neural activity. Here we demonstrate the technique and the
feasibility of using novel adeno-associated viral (AAV) tools to activate
(AAV-CaMKll{\alpha}-ChR2-eYFP) or silence (AAV-CaMKll{\alpha}-eNpHR3.0-eYFP)
neural activity of rat prefrontal cortical prelimbic (PL) pyramidal neurons in
vivo. In vivo single unit extracellular recording of ChR2-transduced pyramidal
neurons showed that delivery of brief (10 ms) blue (473 nm) light-pulse trains
up to 20 Hz via a custom fiber optic-coupled recording electrode (optrode)
induced spiking with high fidelity at 20 Hz for the duration of recording (up
to two hours in some cases). To silence spontaneously active neurons we
transduced them with the NpHR construct and administered continuous green (532
nm) light to completely inhibit action potential activity for up to 10 seconds
with 100% fidelity in most cases. These versatile photosensitive tools combined
with optrode recording methods provide experimental control over activity of
genetically defined neurons and can be used to investigate the functional
relationship between neural activity and complex cognitive behavior.
</summary>
    <author>
      <name>Shinya Nakamura</name>
    </author>
    <author>
      <name>Michael V. Baratta</name>
    </author>
    <author>
      <name>Matthew B. Pomrenze</name>
    </author>
    <author>
      <name>Samuel D. Dolzani</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3410/f1000research.1-7.v1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3410/f1000research.1-7.v1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures F1000Research article</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">F1000 Research 2012, 1:7</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.2720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.0213v1</id>
    <updated>2011-12-01T15:37:09Z</updated>
    <published>2011-12-01T15:37:09Z</published>
    <title>Supervised Learning of Logical Operations in Layered Spiking Neural
  Networks with Spike Train Encoding</title>
    <summary>  Few algorithms for supervised training of spiking neural networks exist that
can deal with patterns of multiple spikes, and their computational properties
are largely unexplored. We demonstrate in a set of simulations that the ReSuMe
learning algorithm can be successfully applied to layered neural networks.
Input and output patterns are encoded as spike trains of multiple precisely
timed spikes, and the network learns to transform the input trains into target
output trains. This is done by combining the ReSuMe learning algorithm with
multiplicative scaling of the connections of downstream neurons.
  We show in particular that layered networks with one hidden layer can learn
the basic logical operations, including Exclusive-Or, while networks without
hidden layer cannot, mirroring an analogous result for layered networks of rate
neurons.
  While supervised learning in spiking neural networks is not yet fit for
technical purposes, exploring computational properties of spiking neural
networks advances our understanding of how computations can be done with spike
trains.
</summary>
    <author>
      <name>André Grüning</name>
    </author>
    <author>
      <name>Ioana Sporea</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11063-012-9225-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11063-012-9225-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Processing Letters October 2012, Volume 36, Issue 2, pp
  117-134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.0213v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.0213v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0441v1</id>
    <updated>2012-03-02T12:22:12Z</updated>
    <published>2012-03-02T12:22:12Z</published>
    <title>Existence, uniqueness and a priori estimates for a non linear
  integro-differential equation</title>
    <summary>  The paper deals with the explicit calculus and the properties of the
fundamental solution K of a parabolic operator related to a semilinear equation
that models reaction diffusion systems with excitable kinetics. The initial
value problem in all of the space is analyzed together with continuous
dependence and a priori estimates of the solution. These estimates show that
the asymptotic behavior is determined by the reaction mechanism. Moreover it's
possible a rigorous singular perturbation analysis for discussing travelling
waves with their characteristic times.
</summary>
    <author>
      <name>M. De Angelis</name>
    </author>
    <author>
      <name>P. Renno</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/S11587(08)0028-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/S11587(08)0028-7" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ricerche mat. 57 p. 95-109 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35K47.35K25.78A70.35E05.44A10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.3496v1</id>
    <updated>2011-12-15T12:09:25Z</updated>
    <published>2011-12-15T12:09:25Z</published>
    <title>Increased Coupling in the Saliency Network is the main cause/effect of
  Attention Deficit Hyperactivity Disorder</title>
    <summary>  To uncover the underlying mechanisms of mental disorders such as attention
deficit hyperactivity disorder (ADHD) for improving both early diagnosis and
therapy, it is increasingly recognized that we need a better understanding of
how the brain's functional connections are altered. A new brain wide
association study (BWAS) has been developed and used to investigate functional
connectivity changes in the brains of patients suffering from ADHD using
resting state fMRI data. To reliably find out the most significantly altered
functional connectivity links and associate them with ADHD, a meta-analysis on
a cohort of ever reported largest population comprising 249 patients and 253
healthy controls is carried out. The greatest change in ADHD patients was the
increased coupling of the saliency network involving the anterior cingulate
gyrus and anterior insula. A voxel-based morphometry analysis was also carried
out but this revealed no evidence in the ADHD patients for altered grey matter
volumes in the regions showing altered functional connectivity. This is the
first evidence for the involvement of the saliency network in ADHD and it
suggests that this may reflect increased sensitivity over the integration of
the incoming sensory information and his/her own thoughts and the network as a
switch is bias towards to the central executive network.
</summary>
    <author>
      <name>Xiaoxi Ji</name>
    </author>
    <author>
      <name>Wei Cheng</name>
    </author>
    <author>
      <name>Jie Zhang</name>
    </author>
    <author>
      <name>Tian Ge</name>
    </author>
    <author>
      <name>Li Sun</name>
    </author>
    <author>
      <name>Yufeng Wang</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <link href="http://arxiv.org/abs/1112.3496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.3496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5322v1</id>
    <updated>2011-01-27T15:56:48Z</updated>
    <published>2011-01-27T15:56:48Z</published>
    <title>Defecting or not defecting: how to "read" human behavior during
  cooperative games by EEG measurements</title>
    <summary>  Understanding the neural mechanisms responsible for human social interactions
is difficult, since the brain activities of two or more individuals have to be
examined simultaneously and correlated with the observed social patterns. We
introduce the concept of hyper-brain network, a connectivity pattern
representing at once the information flow among the cortical regions of a
single brain as well as the relations among the areas of two distinct brains.
Graph analysis of hyper-brain networks constructed from the EEG scanning of 26
couples of individuals playing the Iterated Prisoner's Dilemma reveals the
possibility to predict non-cooperative interactions during the decision-making
phase. The hyper-brain networks of two-defector couples have significantly less
inter-brain links and overall higher modularity - i.e. the tendency to form two
separate subgraphs - than couples playing cooperative or tit-for-tat
strategies. The decision to defect can be "read" in advance by evaluating the
changes of connectivity pattern in the hyper-brain network.
</summary>
    <author>
      <name>F. De Vico Fallani</name>
    </author>
    <author>
      <name>V. Nicosia</name>
    </author>
    <author>
      <name>R. Sinatra</name>
    </author>
    <author>
      <name>L. Astolfi</name>
    </author>
    <author>
      <name>F. Cincotti</name>
    </author>
    <author>
      <name>D. Mattia</name>
    </author>
    <author>
      <name>C. Wilke</name>
    </author>
    <author>
      <name>A. Doud</name>
    </author>
    <author>
      <name>V. Latora</name>
    </author>
    <author>
      <name>B. He</name>
    </author>
    <author>
      <name>F. Babiloni</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0014187</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0014187" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 5(12): e14187 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.5322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.5720v6</id>
    <updated>2012-10-11T02:45:58Z</updated>
    <published>2012-07-24T15:05:50Z</published>
    <title>Haptic BCI Paradigm based on Somatosensory Evoked Potential</title>
    <summary>  A new concept and an online prototype of haptic BCI paradigm are presented.
Our main goal is to develop a new, alternative and low cost paradigm, with
open-source hardware and software components. We also report results obtained
with the novel dry EEG electrodes based signal acquisition system by g.tec,
which further improves experimental comfort. We address the following points: a
novel application of the BCI; a new methodological approach used compared to
earlier projects; a new benefit for potential users of a BCI; the approach
working online/in real-time; development of a novel stimuli delivery hardware
and software. The results with five healthy subjects and discussion of future
developments conclude this submission.
</summary>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <author>
      <name>Hiromu Mori</name>
    </author>
    <author>
      <name>Yoshihiro Matsumoto</name>
    </author>
    <author>
      <name>Zhenyu Cai</name>
    </author>
    <author>
      <name>Moonjeong Chang</name>
    </author>
    <author>
      <name>Nozomu Nishikawa</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Koichi Mori</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.5720v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.5720v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0031v3</id>
    <updated>2013-05-16T20:44:24Z</updated>
    <published>2012-11-30T22:43:11Z</published>
    <title>Encoding binary neural codes in networks of threshold-linear neurons</title>
    <summary>  Networks of neurons in the brain encode preferred patterns of neural activity
via their synaptic connections. Despite receiving considerable attention, the
precise relationship between network connectivity and encoded patterns is still
poorly understood. Here we consider this problem for networks of
threshold-linear neurons whose computational function is to learn and store a
set of binary patterns (e.g., a neural code) as "permitted sets" of the
network. We introduce a simple Encoding Rule that selectively turns "on"
synapses between neurons that co-appear in one or more patterns. The rule uses
synapses that are binary, in the sense of having only two states ("on" or
"off"), but also heterogeneous, with weights drawn from an underlying synaptic
strength matrix S. Our main results precisely describe the stored patterns that
result from the Encoding Rule -- including unintended "spurious" states -- and
give an explicit characterization of the dependence on S. In particular, we
find that binary patterns are successfully stored in these networks when the
excitatory connections between neurons are geometrically balanced -- i.e., they
satisfy a set of geometric constraints. Furthermore, we find that certain types
of neural codes are "natural" in the context of these networks, meaning that
the full code can be accurately learned from a highly undersampled set of
patterns. Interestingly, many commonly observed neural codes in cortical and
hippocampal areas are natural in this sense. As an application, we construct
networks that encode hippocampal place field codes nearly exactly, following
presentation of only a small fraction of patterns. To obtain our results, we
prove new theorems using classical ideas from convex and distance geometry,
such as Cayley-Menger determinants, revealing a novel connection between these
areas of mathematics and coding properties of neural networks.
</summary>
    <author>
      <name>Carina Curto</name>
    </author>
    <author>
      <name>Anda Degeratu</name>
    </author>
    <author>
      <name>Vladimir Itskov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 5 figures. Minor revisions only. Accepted to Neural
  Computation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation, Vol 25, pp. 2858-2903, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.0031v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0031v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3581v1</id>
    <updated>2011-11-15T16:59:17Z</updated>
    <published>2011-11-15T16:59:17Z</published>
    <title>Coherence stability and effect of random natural frequencies in
  populations of coupled oscillators</title>
    <summary>  We consider the (noisy) Kuramoto model, that is a population of N
oscillators, or rotators, with mean-field interaction. Each oscillator has its
own randomly chosen natural frequency (quenched disorder) and it is stirred by
Brownian motion. In the limit N goes to infty this model is accurately
described by a (deterministic) Fokker-Planck equation. We study this equation
and obtain quantitatively sharp results in the limit of weak disorder. We show
that, in general, even when the natural frequencies have zero mean the
oscillators synchronize (for sufficiently strong interaction) around a common
rotating phase, whose frequency is sharply estimated. We also establish the
stability properties of these solutions (in fact, limit cycles). These results
are obtained by identifying the stable hyperbolic manifold of stationary
solutions of an associated non disordered model and by exploiting the
robustness of hyperbolic structures under suitable perturbations. When the
disorder distribution is symmetric the speed vanishes and there is a one
parameter family of stationary solutions : in this case we provide more precise
stability estimates. The methods we use apply beyond the Kuramoto model and we
develop here the case of active rotator models, that is the case in which the
dynamics of each rotator in absence of interaction and noise is not simply a
rotation.
</summary>
    <author>
      <name>Giambattista Giacomin</name>
    </author>
    <author>
      <name>Eric Luçon</name>
    </author>
    <author>
      <name>Christophe Poquet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37N25, 82C26, 82C31, 92B25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4749v1</id>
    <updated>2011-02-23T14:32:28Z</updated>
    <published>2011-02-23T14:32:28Z</published>
    <title>Perception of categories: from coding efficiency to reaction times</title>
    <summary>  Reaction-times in perceptual tasks are the subject of many experimental and
theoretical studies. With the neural decision making process as main focus,
most of these works concern discrete (typically binary) choice tasks, implying
the identification of the stimulus as an exemplar of a category. Here we
address issues specific to the perception of categories (e.g. vowels, familiar
faces, ...), making a clear distinction between identifying a category (an
element of a discrete set) and estimating a continuous parameter (such as a
direction). We exhibit a link between optimal Bayesian decoding and coding
efficiency, the latter being measured by the mutual information between the
discrete category set and the neural activity. We characterize the properties
of the best estimator of the likelihood of the category, when this estimator
takes its inputs from a large population of stimulus-specific coding cells.
Adopting the diffusion-to-bound approach to model the decisional process, this
allows to relate analytically the bias and variance of the diffusion process
underlying decision making to macroscopic quantities that are behaviorally
measurable. A major consequence is the existence of a quantitative link between
reaction times and discrimination accuracy. The resulting analytical expression
of mean reaction times during an identification task accounts for empirical
facts, both qualitatively (e.g. more time is needed to identify a category from
a stimulus at the boundary compared to a stimulus lying within a category), and
quantitatively (working on published experimental data on phoneme
identification tasks).
</summary>
    <author>
      <name>Laurent Bonnasse-Gahot</name>
    </author>
    <author>
      <name>Jean-Pierre Nadal</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.brainres.2011.08.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.brainres.2011.08.014" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Brain Research, Volume 1434 (2012) pp. 47-61</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.4749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3744v1</id>
    <updated>2012-09-17T18:25:34Z</updated>
    <published>2012-09-17T18:25:34Z</published>
    <title>Minimum and maximum entropy distributions for binary systems with known
  means and pairwise correlations</title>
    <summary>  Maximum entropy models are increasingly being used to describe the collective
activity of neural populations with measured mean neural activities and
pairwise correlations, but the full space of probability distributions
consistent with these constraints has not been explored. We provide lower and
upper bounds on the entropy for both the minimum and maximum entropy
distributions over binary units with fixed mean and pairwise correlation, and
we construct distributions for several relevant cases. Surprisingly, the
minimum entropy solution has entropy scaling logarithmically with system size,
unlike the linear behavior of the maximum entropy solution, resolving an open
question in neuroscience. Our results show how only small amounts of randomness
are needed to mimic low-order statistical properties of highly entropic
distributions, and we discuss some applications for engineered and biological
information transmission systems.
</summary>
    <author>
      <name>Badr F. Albanna</name>
    </author>
    <author>
      <name>Christopher Hillar</name>
    </author>
    <author>
      <name>Jascha Sohl-Dickstein</name>
    </author>
    <author>
      <name>Michael R. DeWeese</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6563v1</id>
    <updated>2011-11-28T19:51:18Z</updated>
    <published>2011-11-28T19:51:18Z</published>
    <title>Perception of Motion and Architectural Form: Computational Relationships
  between Optical Flow and Perspective</title>
    <summary>  Perceptual geometry refers to the interdisciplinary research whose objectives
focuses on study of geometry from the perspective of visual perception, and in
turn, applies such geometric findings to the ecological study of vision.
Perceptual geometry attempts to answer fundamental questions in perception of
form and representation of space through synthesis of cognitive and biological
theories of visual perception with geometric theories of the physical world.
Perception of form, space and motion are among fundamental problems in vision
science. In cognitive and computational models of human perception, the
theories for modeling motion are treated separately from models for perception
of form.
</summary>
    <author>
      <name>Arash Sangari</name>
    </author>
    <author>
      <name>Hasti Mirkia</name>
    </author>
    <author>
      <name>Amir H. Assadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 13 figures, submitted and accepted in DoCEIS'2012
  Conference: http://www.uninova.pt/doceis/doceis12/home/home.php</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3450v1</id>
    <updated>2011-07-18T14:36:01Z</updated>
    <published>2011-07-18T14:36:01Z</published>
    <title>Properties of IA in a serotonergic neuron of the dorsal raphe nucleus</title>
    <summary>  Voltage clamp data were analyzed in order to characterize the properties of
the fast potassium transient current IA for a serotonergic neuron of the rat
dorsal raphe nucleus (DRN). We obtain maximal conductance, time constants of
activation and inactivation, and the steady state activation and inactivation
functions, as Boltzmann curves, defined by half-activation potentials and slope
factors. We employ a novel method to accurately obtain the activation function
and compare the results with those obtained by other methods. The form of IA is
estimated as g(V-V_{rev}) m^4h with g=20.5 nS. For activation, the
half-activation potential is V_a=-52.5 mV with slope factor k_a=16.5 mV,
whereas for inactivation the corresponding quantities are -91.5 mV and -9.3 mV.
We discuss the results in terms of the corresponding properties of \IA in other
cell types and their possible relevance to pacemaking activity in 5-HT cells of
the DRN.
</summary>
    <author>
      <name>Nicholas J Penington</name>
    </author>
    <author>
      <name>Henry C Tuckwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5353v2</id>
    <updated>2013-02-21T11:08:57Z</updated>
    <published>2012-09-24T18:18:09Z</published>
    <title>Brain organization into resting state networks emerges at criticality on
  a model of the human connectome</title>
    <summary>  The relation between large-scale brain structure and function is an
outstanding open problem in neuroscience. We approach this problem by studying
the dynamical regime under which realistic spatio-temporal patterns of brain
activity emerge from the empirically derived network of human brain
neuroanatomical connections. The results show that critical dynamics unfolding
on the structural connectivity of the human brain allow the recovery of many
key experimental findings obtained with functional Magnetic Resonance Imaging
(fMRI), such as divergence of the correlation length, anomalous scaling of
correlation fluctuations, and the emergence of large-scale resting state
networks.
</summary>
    <author>
      <name>Ariel Haimovici</name>
    </author>
    <author>
      <name>Enzo Tagliazucchi</name>
    </author>
    <author>
      <name>Pablo Balenzuela</name>
    </author>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.178101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.178101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review Letters, (2013 in press)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. Lett. (110) 17, 178101 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5353v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5353v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6041v3</id>
    <updated>2012-10-03T19:21:32Z</updated>
    <published>2012-08-29T22:31:00Z</published>
    <title>Response Selection Using Neural Phase Oscillators</title>
    <summary>  In a recent paper, Suppes et al. (2012) [arXiv:arXiv:1010.3063] used neural
oscillators to create a model, based on reasonable neurophysiological
assumptions, of the behavioral stimulus-response (SR) theory. In this paper, we
describe the model in a less mathematical and more physical and intuitive way.
</summary>
    <author>
      <name>J. Acacio de Barros</name>
    </author>
    <author>
      <name>G. Oas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure, submitted to the Festschrift in honor of Patrick
  Suppes's 90th Birthday</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.6041v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6041v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0547v2</id>
    <updated>2012-10-23T15:08:57Z</updated>
    <published>2012-08-02T17:17:44Z</published>
    <title>Cooperation in Neural Systems: Bridging Complexity and Periodicity</title>
    <summary>  Inverse power law distributions are generally interpreted as a manifestation
of complexity, and waiting time distributions with power index \mu &lt; 2 reflect
the occurrence of ergodicity breaking renewal events. In this Letter we show
how to combine these properties with the apparently foreign clocklike nature of
biological processes. We use a two-dimensional regular network of leaky
integrate-and-fire neurons, each of which is linked to its four nearest
neighbors, to show that both complexity and periodicity are generated by
locality breakdown: links of increasing strength have the effect of turning
local into long-range interaction, thereby generating first time complexity and
then time periodicity. Increasing the density of neuron firings reduces the
influence of periodicity thus creating a cooperation-induced distinctly
non-Poisson renewal condition.
</summary>
    <author>
      <name>Marzieh Zare</name>
    </author>
    <author>
      <name>Paolo Grigolini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper is under review and might be under copyright of a journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.0547v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0547v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.6054v1</id>
    <updated>2011-01-31T19:28:46Z</updated>
    <published>2011-01-31T19:28:46Z</published>
    <title>Collective oscillations of excitable elements: order parameters,
  bistability and the role of stochasticity</title>
    <summary>  We study the effects of a probabilistic refractory period in the collective
behavior of coupled discrete-time excitable cells (SIRS-like cellular
automata). Using mean-field analysis and simulations, we show that a
synchronized phase with stable collective oscillations exists even with
non-deterministic refractory periods. Moreover, further increasing the coupling
strength leads to a reentrant transition, where the synchronized phase loses
stability. In an intermediate regime, we also observe bistability (and
consequently hysteresis) between a synchronized phase and an active but
incoherent phase without oscillations. The onset of the oscillations appears in
the mean-field equations as a Neimark-Sacker bifurcation, the nature of which
(i.e. super- or subcritical) is determined by the first Lyapunov coefficient.
This allows us to determine the borders of the oscillating and of the bistable
regions. The mean-field prediction thus obtained agrees quantitatively with
simulations of complete graphs and, for random graphs, qualitatively predicts
the overall structure of the phase diagram. The latter can be obtained from
simulations by defining an order parameter q suited for detecting collective
oscillations of excitable elements. We briefly review other commonly used order
parameters and show (via data collapse) that q satisfies the expected finite
size scaling relations.
</summary>
    <author>
      <name>Fernando Rozenblit</name>
    </author>
    <author>
      <name>Mauro Copelli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2011/01/P01012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2011/01/P01012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2011) P01012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.6054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.6054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4726v1</id>
    <updated>2012-01-23T14:45:32Z</updated>
    <published>2012-01-23T14:45:32Z</published>
    <title>Coordinated optimization of visual cortical maps (II) Numerical studies</title>
    <summary>  It is an attractive hypothesis that the spatial structure of visual cortical
architecture can be explained by the coordinated optimization of multiple
visual cortical maps representing orientation preference (OP), ocular dominance
(OD), spatial frequency, or direction preference. In part (I) of this study we
defined a class of analytically tractable coordinated optimization models and
solved representative examples in which a spatially complex organization of the
orientation preference map is induced by inter-map interactions. We found that
attractor solutions near symmetry breaking threshold predict a highly ordered
map layout and require a substantial OD bias for OP pinwheel stabilization.
Here we examine in numerical simulations whether such models exhibit
biologically more realistic spatially irregular solutions at a finite distance
from threshold and when transients towards attractor states are considered. We
also examine whether model behavior qualitatively changes when the spatial
periodicities of the two maps are detuned and when considering more than 2
feature dimensions. Our numerical results support the view that neither minimal
energy states nor intermediate transient states of our coordinated optimization
models successfully explain the spatially irregular architecture of the visual
cortex. We discuss several alternative scenarios and additional factors that
may improve the agreement between model solutions and biological observations.
</summary>
    <author>
      <name>Lars Reichl</name>
    </author>
    <author>
      <name>Dominik Heide</name>
    </author>
    <author>
      <name>Siegrid Löwel</name>
    </author>
    <author>
      <name>Justin C. Crowley</name>
    </author>
    <author>
      <name>Matthias Kaschube</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 11 figures. arXiv admin note: substantial text overlap with
  arXiv:1102.3353</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.4726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4294v1</id>
    <updated>2011-10-19T14:21:43Z</updated>
    <published>2011-10-19T14:21:43Z</published>
    <title>Mean Field description of and propagation of chaos in recurrent
  multipopulation networks of Hodgkin-Huxley and Fitzhugh-Nagumo neurons</title>
    <summary>  We derive the mean-field equations arising as the limit of a network of
interacting spiking neurons, as the number of neurons goes to infinity. The
neurons belong to a fixed number of populations and are represented either by
the Hodgkin-Huxley model or by one of its simplified version, the
Fitzhugh-Nagumo model. The synapses between neurons are either electrical or
chemical. The network is assumed to be fully connected. The maximum
conductances vary randomly. Under the condition that all neurons initial
conditions are drawn independently from the same law that depends only on the
population they belong to, we prove that a propagation of chaos phenomenon
takes places, namely that in the mean-field limit, any finite number of neurons
become independent and, within each population, have the same probability
distribution. This probability distribution is solution of a set of implicit
equations, either nonlinear stochastic differential equations resembling the
McKean-Vlasov equations, or non-local partial differential equations resembling
the McKean-Vlasov-Fokker- Planck equations. We prove the well-posedness of
these equations, i.e. the existence and uniqueness of a solution. We also show
the results of some preliminary numerical experiments that indicate that the
mean-field equations are a good representation of the mean activity of a
?finite size network, even for modest sizes. These experiment also indicate
that the McKean-Vlasov-Fokker- Planck equations may be a good way to understand
the mean-field dynamics through, e.g., a bifurcation analysis.
</summary>
    <author>
      <name>Javier Baladron</name>
    </author>
    <author>
      <name>Diego Fasoli</name>
    </author>
    <author>
      <name>Olivier Faugeras</name>
    </author>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.4294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F99, 60B10, 92B20, 82C32, 82C80, 35Q80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4896v1</id>
    <updated>2012-01-23T23:35:06Z</updated>
    <published>2012-01-23T23:35:06Z</published>
    <title>On Reverse Engineering in the Cognitive and Brain Sciences</title>
    <summary>  Various research initiatives try to utilize the operational principles of
organisms and brains to develop alternative, biologically inspired computing
paradigms and artificial cognitive systems. This paper reviews key features of
the standard method applied to complexity in the cognitive and brain sciences,
i.e. decompositional analysis or reverse engineering. The indisputable
complexity of brain and mind raise the issue of whether they can be understood
by applying the standard method. Actually, recent findings in the experimental
and theoretical fields, question central assumptions and hypotheses made for
reverse engineering. Using the modeling relation as analyzed by Robert Rosen,
the scientific analysis method itself is made a subject of discussion. It is
concluded that the fundamental assumption of cognitive science, i.e. complex
cognitive systems can be analyzed, understood and duplicated by reverse
engineering, must be abandoned. Implications for investigations of organisms
and behavior as well as for engineering artificial cognitive systems are
discussed.
</summary>
    <author>
      <name>Andreas Schierwagen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.4896v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4896v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.0778v3</id>
    <updated>2012-12-03T13:28:22Z</updated>
    <published>2011-12-04T17:04:29Z</published>
    <title>A computational model of inhibitory control in frontal cortex and basal
  ganglia</title>
    <summary>  Planning and executing volitional actions in the face of conflicting habitual
responses is a critical aspect of human behavior. At the core of the interplay
between these two control systems lies an override mechanism that can suppress
the habitual action selection process and allow executive control to take over.
Here, we construct a neural circuit model informed by behavioral and
electrophysiological data collected on various response inhibition paradigms.
This model extends a well established model of action selection in the basal
ganglia by including a frontal executive control network which integrates
information about sensory input and task rules to facilitate well-informed
decision making via the oculomotor system. Our simulations of the antisaccade,
Simon and saccade-override task ensue in conflict between a prepotent and
controlled response which causes the network to pause action selection via
projections to the subthalamic nucleus. Our model reproduces key behavioral and
electrophysiological patterns and their sensitivity to lesions and
pharmacological manipulations. Finally, we show how this network can be
extended to include the inferior frontal cortex to simulate key qualitative
patterns of global response inhibition demands as required in the stop-signal
task.
</summary>
    <author>
      <name>Thomas V. Wiecki</name>
    </author>
    <author>
      <name>Michael J. Frank</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3rd submission (now accepted at Psychological Review). Removed
  switch-DDM and some other data points, restructured some graphics. Added
  systematic accuracy-RT analysis of speed-accuracy trade-off</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.0778v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.0778v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3707v2</id>
    <updated>2011-06-09T05:49:51Z</updated>
    <published>2011-04-19T10:56:44Z</published>
    <title>Brain Network Analysis: Separating Cost from Topology using
  Cost-integration</title>
    <summary>  A statistically principled way of conducting weighted network analysis is
still lacking. Comparison of different populations of weighted networks is hard
because topology is inherently dependent on wiring cost, where cost is defined
as the number of edges in an unweighted graph. In this paper, we evaluate the
benefits and limitations associated with using cost-integrated topological
metrics. Our focus is on comparing populations of weighted undirected graphs
using global efficiency. We evaluate different approaches to the comparison of
weighted networks that differ in mean association weight. Our key result shows
that integrating over cost is equivalent to controlling for any monotonic
transformation of the weight set of a weighted graph. That is, when integrating
over cost, we eliminate the differences in topology that may be due to a
monotonic transformation of the weight set. Our result holds for any unweighted
topological measure. Cost-integration is therefore helpful in disentangling
differences in cost from differences in topology. By contrast, we show that the
use of the weighted version of a topological metric does not constitute a valid
approach to this problem. Indeed, we prove that, under mild conditions, the use
of the weighted version of global efficiency is equivalent to simply comparing
weighted costs. Thus, we recommend the reporting of (i) differences in weighted
costs and (ii) differences in cost-integrated topological measures. We
demonstrate the application of these techniques in a re-analysis of an fMRI
working memory task. Finally, we discuss the limitations of integrating
topology over cost, which may pose problems when some weights are zero, when
multiplicities exist in the ranks of the weights, and when one expects subtle
cost-dependent topological differences, which could be masked by
cost-integration.
</summary>
    <author>
      <name>Cedric E. Ginestet</name>
    </author>
    <author>
      <name>Thomas E. Nichols</name>
    </author>
    <author>
      <name>Ed T. Bullmore</name>
    </author>
    <author>
      <name>Andrew Simmons</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in PLoS one, in June 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.3707v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3707v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3747v1</id>
    <updated>2012-05-16T17:48:25Z</updated>
    <published>2012-05-16T17:48:25Z</published>
    <title>The conundrum of functional brain networks: small-world efficiency or
  fractal modularity</title>
    <summary>  The human brain has been studied at multiple scales, from neurons, circuits,
areas with well defined anatomical and functional boundaries, to large-scale
functional networks which mediate coherent cognition. In a recent work, we
addressed the problem of the hierarchical organization in the brain through
network analysis. Our analysis identified functional brain modules of fractal
structure that were inter-connected in a small-world topology. Here, we provide
more details on the use of network science tools to elaborate on this behavior.
We indicate the importance of using percolation theory to highlight the modular
character of the functional brain network. These modules present a fractal,
self-similar topology, identified through fractal network methods. When we
lower the threshold of correlations to include weaker ties, the network as a
whole assumes a small-world character. These weak ties are organized precisely
as predicted by theory maximizing information transfer with minimal wiring
costs.
</summary>
    <author>
      <name>Lazaros K. Gallos</name>
    </author>
    <author>
      <name>Mariano Sigman</name>
    </author>
    <author>
      <name>Hernan A. Makse</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers in Fractal Physiology, 3, 123 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.3747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3908v3</id>
    <updated>2013-02-10T11:32:50Z</updated>
    <published>2012-12-17T07:18:56Z</published>
    <title>Synchronization of delayed coupled neurons in presence of inhomogeneity</title>
    <summary>  In principle, while coupled limit cycle oscillators can overcome mismatch in
intrinsic rates and match their frequencies, but zero phase lag synchronization
is just achievable in the limit of zero mismatch, i.e., with identical
oscillators. Delay in communication, on the other hand, can exert phase shift
in the activity of the coupled oscillators. In this study, we address the
question of how phase locked, and in particular zero phase lag synchronization,
can be achieved for a heterogeneous system of two delayed coupled neurons. We
have analytically studied the possibility of inphase synchronization and near
inphase synchronization when the neurons are not identical or the connections
are not exactly symmetric. We have shown that while any single source of
inhomogeneity can violate isochronous synchrony, multiple sources of
inhomogeneity can compensate for each other and maintain synchrony. Numeric
studies on biologically plausible models also support the analytic results.
</summary>
    <author>
      <name>Sadjad Sadeghi</name>
    </author>
    <author>
      <name>Alireza Valizadeh</name>
    </author>
    <link href="http://arxiv.org/abs/1212.3908v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3908v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4296v1</id>
    <updated>2011-08-22T12:54:54Z</updated>
    <published>2011-08-22T12:54:54Z</published>
    <title>On the evolution of phenomenal consciousness</title>
    <summary>  A number of concepts are included in the term 'consciousness'. We choose to
concentrate here on phenomenal consciousness, the process through which we are
able to experience aspects of our environment or of our physical state. We
probably share this aspect of consciousness with many animals which, like us,
feel pain or pleasure and experience colours, sounds, flavours, etc. Since
phenomenal consciousness is a feature of some living species, we should be able
to account for it in terms of natural selection. Does it have an adaptive
function, or is it an epiphenomenon ? We shall give arguments to reject the
second alternative. We propose that phenomenal properties of consciousness are
involved in a labelling process that allows us to discriminate and to evaluate
mental representations. We also discuss to what extent consciousness as such
has been selected for this labelling function.
</summary>
    <author>
      <name>Jean-Louis Dessalles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INFRES, LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Tiziana Zalla</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CREA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">jld-98072405; On the evolution of phenomenal consciousness (1998) 350</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.4296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4297v1</id>
    <updated>2011-08-22T12:55:20Z</updated>
    <published>2011-08-22T12:55:20Z</published>
    <title>Why is language well-designed for communication? (Commentary on
  Christiansen and Chater: 'Language as shaped by the brain')</title>
    <summary>  Selection through iterated learning explains no more than other
non-functional accounts, such as universal grammar, why language is so
well-designed for communicative efficiency. It does not predict several
distinctive features of language like central embedding, large lexicons or the
lack of iconicity, that seem to serve communication purposes at the expense of
learnability.
</summary>
    <author>
      <name>Jean-Louis Dessalles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INFRES, LTCI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">jld-08041101</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Behavioral and Brain Sciences 31, 5 (2008) 518-519</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.4297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0288v2</id>
    <updated>2012-03-22T13:13:44Z</updated>
    <published>2011-12-31T17:16:44Z</published>
    <title>Recurrent Interactions in Spiking Networks with Arbitrary Topology</title>
    <summary>  The population activity of random networks of excitatory and inhibitory leaky
integrate-and-fire (LIF) neurons has been studied extensively. In particular, a
state of asynchronous activity with low firing rates and low pairwise
correlations emerges in sparsely connected networks. We apply linear response
theory to evaluate the influence of detailed network structure on neuron
dynamics. It turns out that pairwise correlations induced by direct and
indirect network connections can be related to the matrix of direct linear
interactions. Furthermore, we study the influence of characteristics of the
neuron model. Interpreting the reset as self-inhibition we examine its
influence, via the spectrum of single neuron activity, on network
autocorrelation functions and the overall correlation level. The neuron model
also affects the form of interaction kernels and consequently the
time-dependent correlation functions. We finally find that a linear instability
of networks with Erd\H{o}s-R\'{e}nyi topology coincides with a global
transition to a highly correlated network state. Our work shows that recurrent
interactions have a profound impact on spike train statistics and provides
tools to study effects of specific network topologies.
</summary>
    <author>
      <name>Volker Pernice</name>
    </author>
    <author>
      <name>Benjamin Staude</name>
    </author>
    <author>
      <name>Stefano Cardanobile</name>
    </author>
    <author>
      <name>Stefan Rotter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures, to be published in Physical Review E</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0288v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0288v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1530v1</id>
    <updated>2012-10-04T18:26:03Z</updated>
    <published>2012-10-04T18:26:03Z</published>
    <title>A network of spiking neurons for computing sparse representations in an
  energy efficient way</title>
    <summary>  Computing sparse redundant representations is an important problem both in
applied mathematics and neuroscience. In many applications, this problem must
be solved in an energy efficient way. Here, we propose a hybrid distributed
algorithm (HDA), which solves this problem on a network of simple nodes
communicating via low-bandwidth channels. HDA nodes perform both
gradient-descent-like steps on analog internal variables and
coordinate-descent-like steps via quantized external variables communicated to
each other. Interestingly, such operation is equivalent to a network of
integrate-and-fire neurons, suggesting that HDA may serve as a model of neural
computation. We show that the numerical performance of HDA is on par with
existing algorithms. In the asymptotic regime the representation error of HDA
decays with time, t, as 1/t. HDA is stable against time-varying noise,
specifically, the representation error decays as 1/sqrt(t) for Gaussian white
noise.
</summary>
    <author>
      <name>Tao Hu</name>
    </author>
    <author>
      <name>Alexander Genkin</name>
    </author>
    <author>
      <name>Dmitri B. Chklovskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 figures Early Access:
  http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00353</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.1530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6496v1</id>
    <updated>2011-11-23T08:35:27Z</updated>
    <published>2011-11-23T08:35:27Z</published>
    <title>Theoretical frameworks for neuroeconomics of intertemporal choice</title>
    <summary>  Intertemporal choice has drawn attention in behavioral economics,
econophysics, and neuroeconomics. Recent studies in mainstream economics have
mainly focused on inconsistency in intertemporal choice (dynamic
inconsistency); while impulsivity/impatience in intertemporal choice has been
extensively studied in behavioral economics of addiction. However, recent
advances in neuroeconomic and econophysical studies on intertemporal choice
have made it possible to study both impulsivity and inconsistency in
intertemporal choice within a unified framework. In this paper I propose the
new frameworks for investigations into neuroeconomics of intertemporal choice.
The importance of studying neurochemical and neuroendocrinological modulations
of intertemporal choice and time-perception (e.g. serotonin, dopamine,
cortisol, testosterone, and epinephrine) is emphasized.
</summary>
    <author>
      <name>Taiki Takahashi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Neuroscience, Psychology, and Economics, Vol 2(2), Nov
  2009, 75-90</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6494v1</id>
    <updated>2011-11-22T22:41:59Z</updated>
    <published>2011-11-22T22:41:59Z</published>
    <title>Toward molecular neuroeconomics of obesity</title>
    <summary>  Because obesity is a risk factor for many serious illnesses such as diabetes,
better understandings of obesity and eating disorders have been attracting
attention in neurobiology, psychiatry, and neuroeconomics. This paper presents
future study directions by unifying (i) economic theory of addiction and
obesity (Becker and Murphy, 1988; Levy 2002; Dragone 2009), and (ii) recent
empirical findings in neuroeconomics and neurobiology of obesity and addiction.
It is suggested that neurobiological substrates such as adiponectin, dopamine
(D2 receptors), endocannabinoids, ghrelin, leptin, nesfatin-1, norepinephrine,
orexin, oxytocin, serotonin, vasopressin, CCK, GLP-1, MCH, PYY, and stress
hormones (e.g., CRF) in the brain (e.g., OFC, VTA, NAcc, and the hypothalamus)
may determine parameters in the economic theory of obesity. Also, the
importance of introducing time-inconsistent and gain/loss-asymmetrical temporal
discounting (intertemporal choice) models based on Tsallis' statistics and
incorporating time-perception parameters into the neuroeconomic theory is
emphasized. Future directions in the application of the theory to studies in
neuroeconomics and neuropsychiatry of obesity at the molecular level, which may
help medical/psychopharmacological treatments of obesity (e.g., with
sibutramine), are discussed.
</summary>
    <author>
      <name>Taiki Takahashi</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6495v1</id>
    <updated>2011-11-22T22:45:23Z</updated>
    <published>2011-11-22T22:45:23Z</published>
    <title>A neuroeconomic theory of bidirectional synaptic plasticity and
  addiction</title>
    <summary>  Neuronal mechanisms underlying addiction have been attracting attention in
neurobiology, economics, neuropsychiatry, and neuroeconomics. This paper
proposes a possible link between economic theory of addiction (Becker and
Murphy, 1988) and neurobiological theory of bidirectional synaptic plasticity
(Bienenstock, Cooper, Munro, 1982) based on recent findings in neuroeconomics
and neurobiology of addiction. Furthermore, it is suggested that several
neurobiological substrates such as cortisol (a stress hormone), NMDA and AMPA
receptors/subunits and intracellular calcium in the postsynaptic neurons are
critical factors determining parameters in Becker and Murphy's economic theory
of addiction. Future directions in the application of the theory to studies in
neuroeconomics and neuropsychiatry of addiction and its relation to stress at
the molecular level are discussed.
</summary>
    <author>
      <name>Taiki Takahashi</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6317v1</id>
    <updated>2012-10-23T18:21:16Z</updated>
    <published>2012-10-23T18:21:16Z</published>
    <title>On the geometric structure of fMRI searchlight-based information maps</title>
    <summary>  Information mapping is a popular application of Multivoxel Pattern Analysis
(MVPA) to fMRI. Information maps are constructed using the so called
searchlight method, where the spherical multivoxel neighborhood of every voxel
(i.e., a searchlight) in the brain is evaluated for the presence of
task-relevant response patterns. Despite their widespread use, information maps
present several challenges for interpretation. One such challenge has to do
with inferring the size and shape of a multivoxel pattern from its signature on
the information map. To address this issue, we formally examined the geometric
basis of this mapping relationship. Based on geometric considerations, we show
how and why small patterns (i.e., having smaller spatial extents) can produce a
larger signature on the information map as compared to large patterns,
independent of the size of the searchlight radius. Furthermore, we show that
the number of informative searchlights over the brain increase as a function of
searchlight radius, even in the complete absence of any multivariate response
patterns. These properties are unrelated to the statistical capabilities of the
pattern-analysis algorithms used but are obligatory geometric properties
arising from using the searchlight procedure.
</summary>
    <author>
      <name>Shivakumar Viswanathan</name>
    </author>
    <author>
      <name>Matthew Cieslak</name>
    </author>
    <author>
      <name>Scott T. Grafton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.6317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6493v1</id>
    <updated>2011-11-22T15:38:02Z</updated>
    <published>2011-11-22T15:38:02Z</published>
    <title>Depressive patients are more impulsive and inconsistent in intertemporal
  choice behavior for monetary gain and loss than healthy subjects- an analysis
  based on Tsallis' statistics</title>
    <summary>  Depression has been associated with impaired neural processing of reward and
punishment. However, to date, little is known regarding the relationship
between depression and intertemporal choice for gain and loss. We compared
impulsivity and inconsistency in intertemporal choice for monetary gain and
loss (quantified with parameters in the q-exponential discount function based
on Tsallis' statistics) between depressive patients and healthy control
subjects. This examination is potentially important for advances in
neuroeconomics of intertemporal choice, because depression is associated with
reduced serotonergic activities in the brain. We observed that depressive
patients were more impulsive and time-inconsistent in intertemporal choice
action for gain and loss, in comparison to healthy controls. The usefulness of
the q-exponential discount function for assessing the impaired decision-making
by depressive patients was demonstrated. Furthermore, biophysical mechanisms
underlying the altered intertemporal choice by depressive patients are
discussed in relation to impaired serotonergic neural systems.
  Keywords: Depression, Discounting, Neuroeconomics, Impulsivity,
Inconsistency, Tsallis' statistics
</summary>
    <author>
      <name>Taiki Takahashi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Direct all correspondence to Taiki Takahashi, Unit of Cognitive and Behavioral Sciences Department of Life Sciences, School of Arts and Sciences, The University of Tokyo, Komaba</arxiv:affiliation>
    </author>
    <author>
      <name>Hidemi Oono</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Behavioral Science, Hokkaido University, Sapporo, Japan</arxiv:affiliation>
    </author>
    <author>
      <name>Takeshi Inoue</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Shuken Boku</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Yuki Kako</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Yuji Kitaichi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Ichiro Kusumi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Takuya Masui</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Shin Nakagawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Katsuji Suzuki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Teruaki Tanaka</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Tsukasa Koyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Psychiatry, Graduate School of Medicine, Hokkaido University, Sapporo</arxiv:affiliation>
    </author>
    <author>
      <name>Mark H. B. Radford</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Symbiosis Group Limited, Milton, Australia, and Department of Behavioral Science, Hokkaido University, Sapporo, Japan</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neuro Endocrinol Lett. 2008, 29(3):351-358</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6493v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6493v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6467v1</id>
    <updated>2012-08-31T11:47:23Z</updated>
    <published>2012-08-31T11:47:23Z</published>
    <title>Motion clouds: model-based stimulus synthesis of natural-like random
  textures for the study of motion perception</title>
    <summary>  Choosing an appropriate set of stimuli is essential to characterize the
response of a sensory system to a particular functional dimension, such as the
eye movement following the motion of a visual scene. Here, we describe a
framework to generate random texture movies with controlled information
content, i.e., Motion Clouds. These stimuli are defined using a generative
model that is based on controlled experimental parametrization. We show that
Motion Clouds correspond to dense mixing of localized moving gratings with
random positions. Their global envelope is similar to natural-like stimulation
with an approximate full-field translation corresponding to a retinal slip. We
describe the construction of these stimuli mathematically and propose an
open-source Python-based implementation. Examples of the use of this framework
are shown. We also propose extensions to other modalities such as color vision,
touch, and audition.
</summary>
    <author>
      <name>Paula Sanz Leon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INT</arxiv:affiliation>
    </author>
    <author>
      <name>Ivo Vanzetta</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INCM</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume S Masson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INT</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent U Perrinet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INT</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1152/jn.00737.2011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1152/jn.00737.2011" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Neurophysiology 107, 11 (2012) 3217-26</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.6467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.1791v2</id>
    <updated>2011-10-03T16:59:02Z</updated>
    <published>2011-03-09T14:33:21Z</published>
    <title>Integrated information increases with fitness in the evolution of
  animats</title>
    <summary>  One of the hallmarks of biological organisms is their ability to integrate
disparate information sources to optimize their behavior in complex
environments. How this capability can be quantified and related to the
functional complexity of an organism remains a challenging problem, in
particular since organismal functional complexity is not well-defined. We
present here several candidate measures that quantify information and
integration, and study their dependence on fitness as an artificial agent
("animat") evolves over thousands of generations to solve a navigation task in
a simple, simulated environment. We compare the ability of these measures to
predict high fitness with more conventional information-theoretic processing
measures. As the animat adapts by increasing its "fit" to the world,
information integration and processing increase commensurately along the
evolutionary line of descent. We suggest that the correlation of fitness with
information integration and with processing measures implies that high fitness
requires both information processing as well as integration, but that
information integration may be a better measure when the task requires memory.
A correlation of measures of information integration (but also information
processing) and fitness strongly suggests that these measures reflect the
functional complexity of the animat, and that such measures can be used to
quantify functional complexity even in the absence of fitness data.
</summary>
    <author>
      <name>Jeffrey Edlund</name>
    </author>
    <author>
      <name>Nicolas Chaumont</name>
    </author>
    <author>
      <name>Arend Hintze</name>
    </author>
    <author>
      <name>Christof Koch</name>
    </author>
    <author>
      <name>Giulio Tononi</name>
    </author>
    <author>
      <name>Christoph Adami</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002236</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002236" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 8 figures, one supplementary figure. Three supplementary
  video files available on request. Version commensurate with published text in
  PLoS Comput. Biol</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Computational Biology 7 (2001) e1002236</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.1791v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.1791v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.6832v1</id>
    <updated>2012-03-30T14:46:47Z</updated>
    <published>2012-03-30T14:46:47Z</published>
    <title>Activity-dependent neuronal model on complex networks</title>
    <summary>  Neuronal avalanches are a novel mode of activity in neuronal networks,
experimentally found in vitro and in vivo, and exhibit a robust critical
behaviour: These avalanches are characterized by a power law distribution for
the size and duration, features found in other problems in the context of the
physics of complex systems. We present a recent model inspired in
self-organized criticality, which consists of an electrical network with
threshold firing, refractory period and activity-dependent synaptic plasticity.
The model reproduces the critical behaviour of the distribution of avalanche
sizes and durations measured experimentally. Moreover, the power spectra of the
electrical signal reproduce very robustly the power law behaviour found in
human electroencephalogram (EEG) spectra. We implement this model on a variety
of complex networks, i.e. regular, small-world and scale-free and verify the
robustness of the critical behaviour.
</summary>
    <author>
      <name>Lucilla de Arcangelis</name>
    </author>
    <author>
      <name>Hans J. Herrmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">published on Frontiers in Physiology vol3, 62 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.6832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.6832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2342v4</id>
    <updated>2013-08-28T00:27:48Z</updated>
    <published>2012-11-10T18:21:44Z</published>
    <title>On selective influences, marginal selectivity, and Bell/CHSH
  inequalities</title>
    <summary>  The Bell/CHSH inequalities of quantum physics are identical with the
inequalities derived in mathematical psychology for the problem of selective
influences in cases involving two bi- nary experimental factors and two binary
random variables recorded in response to them. The following points are made
regarding cognitive science applications: (1) compliance of data with these
inequalities is informative only if the data satisfy the requirement known as
marginal selectivity; (2) both violations of marginal selectivity and
violations of the Bell/CHSH inequalities are interpretable as indicating that
at least one of the two responses is influenced by both experimental factors.
</summary>
    <author>
      <name>Ehtibar N. Dzhafarov</name>
    </author>
    <author>
      <name>Janne V. Kujala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an invited commentary for a special issue of Topics in
  Cognitive Science, dedicated to the use of quantum physical formalisms in
  cognitive science. Currently is in press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Topics in Cognitive Psychology 6, pp. 121-128 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.2342v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2342v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60B99 (Primary) 81Q99, 91E45 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.2592v2</id>
    <updated>2011-11-16T21:17:26Z</updated>
    <published>2011-01-13T15:48:05Z</published>
    <title>An exponential random graph modeling approach to creating group-based
  representative whole-brain connectivity networks</title>
    <summary>  Group-based brain connectivity networks have great appeal for researchers
interested in gaining further insight into complex brain function and how it
changes across different mental states and disease conditions. Accurately
constructing these networks presents a daunting challenge given the
difficulties associated with accounting for inter-subject topological
variability. Viable approaches to this task must engender networks that capture
the constitutive topological properties of the group of subjects' networks that
it is aiming to represent. The conventional approach has been to use a mean or
median correlation network (Achard et al., 2006; Song et al., 2009) to embody a
group of networks. However, the degree to which their topological properties
conform with those of the groups that they are purported to represent has yet
to be explored. Here we investigate the performance of these mean and median
correlation networks. We also propose an alternative approach based on an
exponential random graph modeling framework and compare its performance to that
of the aforementioned conventional approach. Simpson et al. (2010) illustrated
the utility of exponential random graph models (ERGMs) for creating brain
networks that capture the topological characteristics of a single subject's
brain network. However, their advantageousness in the context of producing a
brain network that "represents" a group of brain networks has yet to be
examined. Here we show that our proposed ERGM approach outperforms the
conventional mean and median correlation based approaches and provides an
accurate and flexible method for constructing group-based representative brain
networks.
</summary>
    <author>
      <name>Sean L. Simpson</name>
    </author>
    <author>
      <name>Malaak N. Moussa</name>
    </author>
    <author>
      <name>Paul J. Laurienti</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NeuroImage 2012: 60, 1117-1126</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.2592v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.2592v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.2840v1</id>
    <updated>2011-08-14T03:47:14Z</updated>
    <published>2011-08-14T03:47:14Z</published>
    <title>Generalised elastic nets</title>
    <summary>  The elastic net was introduced as a heuristic algorithm for combinatorial
optimisation and has been applied, among other problems, to biological
modelling. It has an energy function which trades off a fitness term against a
tension term. In the original formulation of the algorithm the tension term was
implicitly based on a first-order derivative. In this paper we generalise the
elastic net model to an arbitrary quadratic tension term, e.g. derived from a
discretised differential operator, and give an efficient learning algorithm. We
refer to these as generalised elastic nets (GENs). We give a theoretical
analysis of the tension term for 1D nets with periodic boundary conditions, and
show that the model is sensitive to the choice of finite difference scheme that
represents the discretised derivative. We illustrate some of these issues in
the context of cortical map models, by relating the choice of tension term to a
cortical interaction function. In particular, we prove that this interaction
takes the form of a Mexican hat for the original elastic net, and of
progressively more oscillatory Mexican hats for higher-order derivatives. The
results apply not only to generalised elastic nets but also to other methods
using discrete differential penalties, and are expected to be useful in other
areas, such as data analysis, computer graphics and optimisation problems.
</summary>
    <author>
      <name>Miguel Á. Carreira-Perpiñán</name>
    </author>
    <author>
      <name>Geoffrey J. Goodhill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">52 pages, 16 figures. Original manuscript dated August 14, 2003 and
  not updated since. Current authors' email addresses:
  mcarreira-perpinan@ucmerced.edu, g.goodhill@uq.edu.au</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.2840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.2840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5629v1</id>
    <updated>2012-09-25T14:48:44Z</updated>
    <published>2012-09-25T14:48:44Z</published>
    <title>Identifying Brain Image Level Endophenotypes in Epilepsy</title>
    <summary>  A brain wide association study (BWAS) based on the logistic regression was
first developed and applied to a large population of epilepsy patients (168)
and healthy controls (136). It was found that the most significant links
associated with epilepsy are those bilateral links with regions mainly
belonging to the default mode network and subcortex, such as amygdala, fusiform
gyrus, inferior temporal gyrus, hippocampus, temporal pole, parahippocampal
gyrus, insula, middle occipital gyrus, cuneus. These links were found to have
much higher odd ratios than other links, and all of them showed reduced
functional couplings in patients compared with controls. Interestingly, with
the increasing of the seizure onset frequency or duration of illness, the
functional connection between these bilateral regions became further reduced.
On the other hand, as a functional compensation and brain plasticity,
connections of these bilateral regions to other brain regions were abnormally
enhanced and became even much stronger with the increase of the seizure onset
frequency. Furthermore, patients had higher network efficiencies than healthy
controls, and the seizure onset frequency was found to be positively correlated
with the network efficiency. A negative correlation between the bilateral
connection and the network efficiency was also observed. To further validate
our findings, we then employed our BWAS results in discriminating patients from
healthy controls and the leave-one-out accuracy was around 78%. Given the fact
that a genome-wide association study with a large cohort has failed to identify
any significant association between genes and epilepsy, our study could provide
us with a set of endophenotypes for further study.
</summary>
    <author>
      <name>Wei Cheng</name>
    </author>
    <author>
      <name>Xuejuan Zhang</name>
    </author>
    <author>
      <name>Ge Tian</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <author>
      <name>Zhengge Wang</name>
    </author>
    <author>
      <name>Zhiqiang Zhang</name>
    </author>
    <author>
      <name>GuangMing Lu</name>
    </author>
    <link href="http://arxiv.org/abs/1209.5629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2852v2</id>
    <updated>2011-03-16T01:02:17Z</updated>
    <published>2011-03-15T06:36:17Z</published>
    <title>Interaction patterns of brain activity across space, time and frequency.
  Part I: methods</title>
    <summary>  We consider exploratory methods for the discovery of cortical functional
connectivity. Typically, data for the i-th subject (i=1...NS) is represented as
an NVxNT matrix Xi, corresponding to brain activity sampled at NT moments in
time from NV cortical voxels. A widely used method of analysis first
concatenates all subjects along the temporal dimension, and then performs an
independent component analysis (ICA) for estimating the common cortical
patterns of functional connectivity. There exist many other interesting
variations of this technique, as reviewed in [Calhoun et al. 2009 Neuroimage
45: S163-172]. We present methods for the more general problem of discovering
functional connectivity occurring at all possible time lags. For this purpose,
brain activity is viewed as a function of space and time, which allows the use
of the relatively new techniques of functional data analysis [Ramsay &amp;
Silverman 2005: Functional data analysis. New York: Springer]. In essence, our
method first vectorizes the data from each subject, which constitutes the
natural discrete representation of a function of several variables, followed by
concatenation of all subjects. The singular value decomposition (SVD), as well
as the ICA of this new matrix of dimension [rows=(NT*NV); columns=NS] will
reveal spatio-temporal patterns of connectivity. As a further example, in the
case of EEG neuroimaging, Xi of size NVxNW may represent spectral density for
electric neuronal activity at NW discrete frequencies from NV cortical voxels,
from the i-th EEG epoch. In this case our functional data analysis approach
would reveal coupling of brain regions at possibly different frequencies.
</summary>
    <author>
      <name>Roberto D. Pascual-Marqui</name>
    </author>
    <author>
      <name>Rolando J. Biscay-Lirio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report 2011-March-15, The KEY Institute for Brain-Mind
  Research Zurich, KMU Osaka</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2852v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2852v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3886v1</id>
    <updated>2012-09-18T09:17:28Z</updated>
    <published>2012-09-18T09:17:28Z</published>
    <title>Spatio-temporal spike trains analysis for large scale networks using
  maximum entropy principle and Monte-Carlo method</title>
    <summary>  Understanding the dynamics of neural networks is a major challenge in
experimental neuroscience. For that purpose, a modelling of the recorded
activity that reproduces the main statistics of the data is required. In a
first part, we present a review on recent results dealing with spike train
statistics analysis using maximum entropy models (MaxEnt). Most of these
studies have been focusing on modelling synchronous spike patterns, leaving
aside the temporal dynamics of the neural activity. However, the maximum
entropy principle can be generalized to the temporal case, leading to Markovian
models where memory effects and time correlations in the dynamics are properly
taken into account. In a second part, we present a new method based on
Monte-Carlo sampling which is suited for the fitting of large-scale
spatio-temporal MaxEnt models. The formalism and the tools presented here will
be essential to fit MaxEnt spatio-temporal models to large neural ensembles.
</summary>
    <author>
      <name>Hassan Nasser</name>
    </author>
    <author>
      <name>Olivier Marre</name>
    </author>
    <author>
      <name>Bruno Cessac</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2013/03/P03006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages, 10 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2013) P03006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.3886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6238v1</id>
    <updated>2012-11-27T08:46:30Z</updated>
    <published>2012-11-27T08:46:30Z</published>
    <title>Visual illusion due to the interaction of flickering and acoustic
  vibrotactile signals</title>
    <summary>  We studied the influence of mechanical vibrotactile signals in the acoustic
range to the visual perception of flickering images. These images are shown on
a CRT screen intermittent at about 75 Hz, without external perturbations are
perceived as constant and stable. However, if presented together with a
controlled acoustical vibration an illusion is perceived. The images appears to
float out of the screen, while the rest of the room is still perceived
normally. The acoustical signal given to the subjects were of very low
frequency (below 100Hz) and low amplitude (almost inaudible). The stimuli were
transmitted through direct contact to the subject's chin with the use of a
plastic stick connected to a speaker. The nature of the illusion is described
and a basic theoretical model is given.
</summary>
    <author>
      <name>Ruggero Micheletto</name>
    </author>
    <author>
      <name>Maria Fernanda Avila-Ortega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 pictures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.6238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3798v1</id>
    <updated>2011-09-17T15:54:06Z</updated>
    <published>2011-09-17T15:54:06Z</published>
    <title>Charge-Balanced Minimum-Power Controls for Spiking Neuron Oscillators</title>
    <summary>  In this paper, we study the optimal control of phase models for spiking
neuron oscillators. We focus on the design of minimum-power current stimuli
that elicit spikes in neurons at desired times. We furthermore take the
charge-balanced constraint into account because in practice undesirable side
effects may occur due to the accumulation of electric charge resulting from
external stimuli. Charge-balanced minimum-power controls are derived for a
general phase model using the maximum principle, where the cases with unbounded
and bounded control amplitude are examined. The latter is of practical
importance since phase models are more accurate for weak forcing. The developed
optimal control strategies are then applied to both mathematically ideal and
experimentally observed phase models to demonstrate their applicability,
including the phase model for the widely studied Hodgkin-Huxley equations.
</summary>
    <author>
      <name>Isuru Dasanayake</name>
    </author>
    <author>
      <name>Jr-Shin Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4558v1</id>
    <updated>2012-04-20T08:19:08Z</updated>
    <published>2012-04-20T08:19:08Z</published>
    <title>Cortical columns for quick brains</title>
    <summary>  It is widely believed that the particular wiring observed within cortical
columns boosts neural computation. We use rewiring of neural networks
performing real-world cognitive tasks to study the validity of this argument.
In a vast survey of wirings within the column we detect, however, no traces of
the proposed effect. It is on the mesoscopic inter-columnar scale that the
existence of columns - largely irrespective of their inner organization -
enhances the speed of information transfer and minimizes the total wiring
length required to bind the distributed columnar computations towards
spatio-temporally coherent results.
</summary>
    <author>
      <name>Ralph L. Stoop</name>
    </author>
    <author>
      <name>Victor Saase</name>
    </author>
    <author>
      <name>Clemens Wagner</name>
    </author>
    <author>
      <name>Britta Stoop</name>
    </author>
    <author>
      <name>Ruedi Stoop</name>
    </author>
    <link href="http://arxiv.org/abs/1204.4558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4559v3</id>
    <updated>2013-05-24T11:49:54Z</updated>
    <published>2012-04-20T08:19:59Z</published>
    <title>Violation of the Leggett-Garg inequality in cognitive processes</title>
    <summary>  The Leggett and Garg Inequality (LGI) is a test of the classical behaviour of
an observed system, in the case of a single measurement channel monitored at
different times. Here we report LGI violation in cognitive tasks consisting in
the identification of mutually incompatible words with negligible semantic
content; the violation is maximal at an inter-measurement time {\tau}LG around
2 sec, close to, but consistently lower than, the characteristic times
associated with other, semantically rich, linguistic endeavors. The LGI
violation persists over a time window of 1 sec around {\tau}LG; outside this
window LGI is recovered.
</summary>
    <author>
      <name>F. T. Arecchi</name>
    </author>
    <author>
      <name>A. Farini</name>
    </author>
    <author>
      <name>N. Megna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to a different
  interpretation of data</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.4559v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4559v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2147v1</id>
    <updated>2012-10-08T05:20:22Z</updated>
    <published>2012-10-08T05:20:22Z</published>
    <title>Differences in the Brain Waves of 3D and 2.5D Motion Picture Viewers</title>
    <summary>  We measured brain waves of viewers watching the 2D, 2.5D, and 3D motion
pictures, comparing them with one another. The relative intensity of
{\alpha}-frequency band of 2.5D-viewer was lower than that of 2D-viewer, while
that of 3D-viewer remained with similar intensity. This result implies visual
neuro-processing of the 2.5D-viewer differs from that of the 3D-viewer.
</summary>
    <author>
      <name>Seok-Hee Kim</name>
    </author>
    <author>
      <name>Dal-Young Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, and 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2140v1</id>
    <updated>2012-10-08T03:41:45Z</updated>
    <published>2012-10-08T03:41:45Z</published>
    <title>Natural electromagnetic waveguide structures based on myelin sheath in
  the neural system</title>
    <summary>  The saltatory propagation of action potentials on myelinated axons is
conventionally explained by the mechanism employing local circuit ionic current
flows between nodes of Ranvier. Under this framework, the myelin sheath with up
to 100 layers of membrane only serves as the insulating shell. The speed of
action potentials is measured to be as fast as 100 m/s on myelinated axons, but
ions move in fluids at just 100 nm/s in a 1 V/m electric field. We show here
the action potentials, in the form of electromagnetic (EM) pulses, can
propagate in natural EM waveguide structures formed by the myelin sheath merged
in fluids. The propagation time is mainly cost on the duration for triggering
EM pulses at nodes of Ranvier. The result clearly reveals the evolution of
axons from the unmyelinated to the myelinated, which has remarkably enhanced
the propagation efficiency by increasing the thickness of myelin sheath.
</summary>
    <author>
      <name>Jiongwei Xue</name>
    </author>
    <author>
      <name>Shengyong Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6177v4</id>
    <updated>2014-07-27T21:15:43Z</updated>
    <published>2012-11-27T01:43:20Z</published>
    <title>Brain Gene Expression Analysis: a MATLAB toolbox for the analysis of
  brain-wide gene-expression data</title>
    <summary>  The Allen Brain Atlas project (ABA) generated a genome-scale collection of
gene-expression profiles using in-situ hybridization. These profiles were
co-registered to the three-dimensional Allen Reference Atlas (ARA) of the adult
mouse brain. A set of more than 4,000 such volumetric data are available for
the full brain, at a resolution of 200 microns. These data are presented in a
voxel-by-gene matrix. The ARA comes with several systems of annotation,
hierarchical (40 cortical regions, 209 sub-cortical regions in the whole
brain), or non-hierarchical (12 regions in the left hemisphere, with refinement
into 94 regions, and cortical layers). The high-dimensional nature of this
unique dataset and the possible connection between anatomy and gene expression
pose challenges to data analysis. We developed the Brain Gene Expression
Analysis Toolbox (downloadable at: www.brainarchitecture.org). The key
functionalities include: determination of marker genes for brain regions,
statistical analysis of brain-wide co-expression patterns, and the computation
of brain-wide correlation maps with cell-type specific microarray data. The
auxiliary dataset consisting of cell-type-specific transcriptomes (chapter 4)
will be made available in the second version of the toolbox.
</summary>
    <author>
      <name>Pascal Grange</name>
    </author>
    <author>
      <name>Jason W. Bohland</name>
    </author>
    <author>
      <name>Michael Hawrylycz</name>
    </author>
    <author>
      <name>Partha P. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">59 pages; v2: bug fixed on page 5, preface added; v3: more bugs
  fixed, cell-type-specific data released (chapter 5); v4: references added,
  chapter 2 expanded</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.6177v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6177v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1135v1</id>
    <updated>2012-12-05T19:33:29Z</updated>
    <published>2012-12-05T19:33:29Z</published>
    <title>Biophysical properties and computational modeling of calcium spikes in
  serotonergic neurons of the dorsal raphe nucleus</title>
    <summary>  Serotonergic neurons of the dorsal raphe nuclei, with their extensive
innervation of nearly the whole brain have important modulatory effects on many
cognitive and physiological processes. They play important roles in clinical
depression and other psychiatric disorders. In order to quantify the effects of
serotonergic transmission on target cells it is desirable to construct
computational models and to this end these it is necessary to have details of
the biophysical and spike properties of the serotonergic neurons. Here several
basic properties are reviewed with data from several studies since the 1960s to
the present. The quantities included are input resistance, resting membrane
potential, membrane time constant, firing rate, spike duration, spike and
afterhyperpolarization (AHP) amplitude, spike threshold, cell capacitance, soma
and somadendritic areas. The action potentials of these cells are normally
triggered by a combination of sodium and calcium currents which may result in
autonomous pacemaker activity. We here analyse the mechanisms of high-threshold
calcium spikes which have been demonstrated in these cells the presence of TTX.
The parameters for calcium dynamics required to give calcium spikes are quite
different from those for regular spiking which suggests the involvement of
restricted parts of the soma-dendritic surface as has been found, for example,
in hippocampal neurons.
</summary>
    <author>
      <name>Henry C. Tuckwell</name>
    </author>
    <link href="http://arxiv.org/abs/1212.1135v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1135v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0321v2</id>
    <updated>2012-05-09T12:29:23Z</updated>
    <published>2012-05-02T04:49:19Z</published>
    <title>The span of correlations in dolphin whistle sequences</title>
    <summary>  Long-range correlations are found in symbolic sequences from human language,
music and DNA. Determining the span of correlations in dolphin whistle
sequences is crucial for shedding light on their communicative complexity.
Dolphin whistles share various statistical properties with human words, i.e.
Zipf's law for word frequencies (namely that the probability of the $i$th most
frequent word of a text is about $i^{-\alpha}$) and a parallel of the tendency
of more frequent words to have more meanings. The finding of Zipf's law for
word frequencies in dolphin whistles has been the topic of an intense debate on
its implications. One of the major arguments against the relevance of Zipf's
law in dolphin whistles is that is not possible to distinguish the outcome of a
die rolling experiment from that of a linguistic or communicative source
producing Zipf's law for word frequencies. Here we show that statistically
significant whistle-whistle correlations extend back to the 2nd previous
whistle in the sequence using a global randomization test and to the 4th
previous whistle using a local randomization test. None of these correlations
are expected by a die rolling experiment and other simple explanation of Zipf's
law for word frequencies such as Simon's model that produce sequences of
unpredictable elements.
</summary>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <author>
      <name>Brenda McCowan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2012/06/P06002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2012/06/P06002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">New Tables 3 and 4</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Mechanics, P06002 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.0321v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0321v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8442v3</id>
    <updated>2013-01-27T05:30:35Z</updated>
    <published>2012-10-31T19:14:41Z</published>
    <title>Linear-Nonlinear-Poisson Neuron Networks Perform Bayesian Inference On
  Boltzmann Machines</title>
    <summary>  One conjecture in both deep learning and classical connectionist viewpoint is
that the biological brain implements certain kinds of deep networks as its
back-end. However, to our knowledge, a detailed correspondence has not yet been
set up, which is important if we want to bridge between neuroscience and
machine learning. Recent researches emphasized the biological plausibility of
Linear-Nonlinear-Poisson (LNP) neuron model. We show that with neurally
plausible settings, the whole network is capable of representing any Boltzmann
machine and performing a semi-stochastic Bayesian inference algorithm lying
between Gibbs sampling and variational inference.
</summary>
    <author>
      <name>Louis Yuanlong Shao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to International Conference of Learning Representation
  (ICLR) 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.8442v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8442v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1202v1</id>
    <updated>2011-04-06T21:58:05Z</updated>
    <published>2011-04-06T21:58:05Z</published>
    <title>Can intrinsic noise induce various resonant peaks?</title>
    <summary>  We theoretically describe how weak signals may be efficiently transmitted
throughout more than one frequency range in noisy excitable media by kind of
stochastic multiresonance. This serves us here to reinterpret recent
experiments in neuroscience, and to suggest that many other systems in nature
might be able to exhibit several resonances. In fact, the observed behavior
happens in our (network) model as a result of competition between (1) changes
in the transmitted signals as if the units were varying their activation
threshold, and (2) adaptive noise realized in the model as rapid
activity-dependent fluctuations of the connection intensities. These two
conditions are indeed known to characterize heterogeneously networked systems
of excitable units, e.g., sets of neurons and synapses in the brain. Our
results may find application also in the design of detector devices.
</summary>
    <author>
      <name>J. J. Torres</name>
    </author>
    <author>
      <name>J. Marro</name>
    </author>
    <author>
      <name>J. F. Mejias</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1255v1</id>
    <updated>2012-11-06T15:15:48Z</updated>
    <published>2012-11-06T15:15:48Z</published>
    <title>Handwritten digit recognition by bio-inspired hierarchical networks</title>
    <summary>  The human brain processes information showing learning and prediction
abilities but the underlying neuronal mechanisms still remain unknown.
Recently, many studies prove that neuronal networks are able of both
generalizations and associations of sensory inputs. In this paper, following a
set of neurophysiological evidences, we propose a learning framework with a
strong biological plausibility that mimics prominent functions of cortical
circuitries. We developed the Inductive Conceptual Network (ICN), that is a
hierarchical bio-inspired network, able to learn invariant patterns by
Variable-order Markov Models implemented in its nodes. The outputs of the
top-most node of ICN hierarchy, representing the highest input generalization,
allow for automatic classification of inputs. We found that the ICN clusterized
MNIST images with an error of 5.73% and USPS images with an error of 12.56%.
</summary>
    <author>
      <name>Antonio G. Zippo</name>
    </author>
    <author>
      <name>Giuliana Gelsomino</name>
    </author>
    <author>
      <name>Sara Nencini</name>
    </author>
    <author>
      <name>Gabriele E. M. Biella</name>
    </author>
    <link href="http://arxiv.org/abs/1211.1255v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1255v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3126v1</id>
    <updated>2011-11-14T08:03:32Z</updated>
    <published>2011-11-14T08:03:32Z</published>
    <title>Polarization Theory of Motivations, Emotions and Attention</title>
    <summary>  A new theory of motivations, emotions and attention is suggested, considering
them as functions of sensory systems. The theory connects neurophysiological
mechanisms of mental phenomena with the change of metabolic and functional
state of perceptive neurons, which is reflected in the degree of polarization
of a cell membrane.
</summary>
    <author>
      <name>Sergey E. Murik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bulletin of Eastern-Siberian Scientific Center SB RAMS, 2005, No.
  7, p.167-174 (in Russian)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.3126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92F05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.7257v2</id>
    <updated>2012-08-01T04:37:39Z</updated>
    <published>2012-07-31T14:26:05Z</published>
    <title>Hebbian Crosstalk and Input Segregation</title>
    <summary>  Purpose: We previously proposed that Hebbian adjustments that are
incompletely synapse specific ("crosstalk") might be analogous to genetic
mutations. We analyze aspects of the effect of crosstalk in Hebbian learning
using the classical Oja model.
  Methods: In previous work we showed that crosstalk leads to learning of the
principal eigenvector of EC (the input covariance matrix pre-multiplied by an
error matrix that describes the crosstalk pattern), and found that with
positive input correlations increasing crosstalk smoothly degrades performance.
However, the Oja model requires negative input correlations to account for
biological ocular segregation. Although this assumption is biologically
somewhat implausible, it captures features that are seen in more complex
models. Here, we analyze how crosstalk would affect such segregation.
  Results: We show that for statistically unbiased inputs crosstalk induces a
bifurcation from segregating to non-segregating outcomes at a critical value
which depends on correlations. We also investigate the behavior in the vicinity
of this critical state and for weakly biased inputs.
  Conclusions: Our results show that crosstalk can induce a bifurcation under
special conditions even in the simplest Hebbian models and that even the low
levels of crosstalk observed in the brain could prevent normal development.
However, during learning pairwise input statistics are more complex and
crosstalk-induced bifurcations may not occur in the Oja model. Such
bifurcations would be analogous to "error catastrophes" in genetic models, and
we argue that they are usually absent for simple linear Hebbian learning
because such learning is only driven by pairwise correlations.
</summary>
    <author>
      <name>Anca Radulescu</name>
    </author>
    <author>
      <name>Paul Adams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages manuscript text, 2 pages references, 9 figures, 4 appendices
  (included within the main file)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.7257v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.7257v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4201v2</id>
    <updated>2013-05-21T23:27:31Z</updated>
    <published>2012-12-18T00:23:54Z</published>
    <title>The neural ring: an algebraic tool for analyzing the intrinsic structure
  of neural codes</title>
    <summary>  Neurons in the brain represent external stimuli via neural codes. These codes
often arise from stereotyped stimulus-response maps, associating to each neuron
a convex receptive field. An important problem confronted by the brain is to
infer properties of a represented stimulus space without knowledge of the
receptive fields, using only the intrinsic structure of the neural code. How
does the brain do this? To address this question, it is important to determine
what stimulus space features can - in principle - be extracted from neural
codes. This motivates us to define the neural ring and a related neural ideal,
algebraic objects that encode the full combinatorial data of a neural code. Our
main finding is that these objects can be expressed in a "canonical form" that
directly translates to a minimal description of the receptive field structure
intrinsic to the code. We also find connections to Stanley-Reisner rings, and
use ideas similar to those in the theory of monomial ideals to obtain an
algorithm for computing the primary decomposition of pseudo-monomial ideals.
This allows us to algorithmically extract the canonical form associated to any
neural code, providing the groundwork for inferring stimulus space features
from neural activity alone.
</summary>
    <author>
      <name>Carina Curto</name>
    </author>
    <author>
      <name>Vladimir Itskov</name>
    </author>
    <author>
      <name>Alan Veliz-Cuba</name>
    </author>
    <author>
      <name>Nora Youngs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor revisions. 35 pages, 7 figures, and 1 table. Accepted to
  Bulletin of Mathematical Biology</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bulletin of Mathematical Biology, Volume 75, Issue 9, pp.
  1571-1611, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.4201v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4201v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5678v1</id>
    <updated>2011-06-28T14:16:30Z</updated>
    <published>2011-06-28T14:16:30Z</published>
    <title>The cell-type specific connectivity of the local cortical network
  explains prominent features of neuronal activity</title>
    <summary>  In the past decade, the cell-type specific connectivity and activity of local
cortical networks have been characterized experimentally to some detail. In
parallel, modeling has been established as a tool to relate network structure
to activity dynamics. While the available connectivity maps have been used in
various computational studies, prominent features of the simulated activity
such as the spontaneous firing rates do not match the experimental findings.
Here, we show that the inconsistency arises from the incompleteness of the
connectivity maps. Our comparison of the most comprehensive maps (Thomson et
al., 2002; Binzegger et al., 2004) reveals their main discrepancies: the
lateral sampling range and the specific selection of target cells. Taking them
into account, we compile an integrated connectivity map and analyze the unified
map by simulations of a full scale model of the local layered cortical network.
The simulated spontaneous activity is asynchronous irregular and the cell-type
specific spontaneous firing rates are in agreement with in vivo recordings in
awake animals, including the low rate of layer 2/3 excitatory cells. Similarly,
the activation patterns evoked by transient thalamic inputs reproduce recent in
vivo measurements. The correspondence of simulation results and experiments
rests on the consideration of specific target type selection and thereby on the
integration of a large body of the available connectivity data. The cell-type
specific hierarchical input structure and the combination of feed-forward and
feedback connections reveal how the interplay of excitation and inhibition
shapes the spontaneous and evoked activity of the local cortical network.
</summary>
    <author>
      <name>Tobias C. Potjans</name>
    </author>
    <author>
      <name>Markus Diesmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">57 pages (including main text and supplemental material), 12 figures,
  8 supplemental figures, 5 tables, 2 supplemental tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.5678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5188v1</id>
    <updated>2012-12-20T18:57:30Z</updated>
    <published>2012-12-20T18:57:30Z</published>
    <title>Combinatorial neural codes from a mathematical coding theory perspective</title>
    <summary>  Shannon's seminal 1948 work gave rise to two distinct areas of research:
information theory and mathematical coding theory. While information theory has
had a strong influence on theoretical neuroscience, ideas from mathematical
coding theory have received considerably less attention. Here we take a new
look at combinatorial neural codes from a mathematical coding theory
perspective, examining the error correction capabilities of familiar receptive
field codes (RF codes). We find, perhaps surprisingly, that the high levels of
redundancy present in these codes does not support accurate error correction,
although the error-correcting performance of RF codes "catches up" to that of
random comparison codes when a small tolerance to error is introduced. On the
other hand, RF codes are good at reflecting distances between represented
stimuli, while the random comparison codes are not. We suggest that a
compromise in error-correcting capability may be a necessary price to pay for a
neural code whose structure serves not only error correction, but must also
reflect relationships between stimuli.
</summary>
    <author>
      <name>Carina Curto</name>
    </author>
    <author>
      <name>Vladimir Itskov</name>
    </author>
    <author>
      <name>Katherine Morrison</name>
    </author>
    <author>
      <name>Zachary Roth</name>
    </author>
    <author>
      <name>Judy L. Walker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation, Vol 25(7), pp. 1891-1925, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5021v1</id>
    <updated>2011-02-24T15:55:27Z</updated>
    <published>2011-02-24T15:55:27Z</published>
    <title>Causality as a unifying approach between activation and connectivity
  analysis of fMRI data</title>
    <summary>  This paper indicates causality as the tool that unifies the analysis of both
activations and connectivity of brain areas, obtained with fMRI data. Causality
analysis is commonly applied to study connectivity, so this work focuses on
demonstrating that also the detection of activations can be handled with a
causality analysis. We test our method on finger tapping data, in which GLM and
Granger Causality approaches are compared in finding activations. Granger
causality not only performs the task well, but indeed we obtained a better
localization (i.e. precision) of activations. As a result we claim that
causality must be the main tool to investigate activations, since it is a
measure of "how much" the stimulus influences the BOLD signal, and since it
unifies connectivity and activations analysis under the same area.
</summary>
    <author>
      <name>Nevio Dubbini</name>
    </author>
    <link href="http://arxiv.org/abs/1102.5021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6146v4</id>
    <updated>2013-11-14T08:00:02Z</updated>
    <published>2012-12-26T09:14:39Z</published>
    <title>Sparse Hopfield network reconstruction with $\ell_{1}$ regularization</title>
    <summary>  We propose an efficient strategy to infer sparse Hopfield network based on
magnetizations and pairwise correlations measured through Glauber samplings.
This strategy incorporates the $\ell_{1}$ regularization into the Bethe
approximation by a quadratic approximation to the log-likelihood, and is able
to further reduce the inference error of the Bethe approximation without the
regularization. The optimal regularization parameter is observed to be of the
order of $M^{-\nu}$ where $M$ is the number of independent samples. The value
of the scaling exponent depends on the performance measure. $\nu\simeq0.5001$
for root mean squared error measure while $\nu\simeq0.2743$ for
misclassification rate measure. The efficiency of this strategy is demonstrated
for the sparse Hopfield model, but the method is generally applicable to other
diluted mean field models. In particular, it is simple in implementation
without heavy computational cost.
</summary>
    <author>
      <name>Haiping Huang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2013-40502-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2013-40502-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, Eur. Phys. J. B (in press)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B (2013) 86: 484</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.6146v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6146v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5686v1</id>
    <updated>2012-04-25T15:44:14Z</updated>
    <published>2012-04-25T15:44:14Z</published>
    <title>An organizing center in a planar model of neuronal excitability</title>
    <summary>  The paper studies the excitability properties of a generalized
FitzHugh-Nagumo model. The model differs from the purely competitive
FitzHugh-Nagumo model in that it accounts for the effect of cooperative gating
variables such as activation of calcium currents. Excitability is explored by
unfolding a pitchfork bifurcation that is shown to organize five different
types of excitability. In addition to the three classical types of neuronal
excitability, two novel types are described and distinctly associated to the
presence of cooperative variables.
</summary>
    <author>
      <name>Alessio Franci</name>
    </author>
    <author>
      <name>Guillaume Drion</name>
    </author>
    <author>
      <name>Rodolphe Sepulchre</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2588v1</id>
    <updated>2011-12-12T15:32:42Z</updated>
    <published>2011-12-12T15:32:42Z</published>
    <title>A Novel Phase Portrait to Understand Neuronal Excitability</title>
    <summary>  Fifty years ago, Fitzugh introduced a phase portrait that became famous for a
twofold reason: it captured in a physiological way the qualitative behavior of
Hodgkin-Huxley model and it revealed the power of simple dynamical models to
unfold complex firing patterns. To date, in spite of the enormous progresses in
qualitative and quantitative neural modeling, this phase portrait has remained
the core picture of neuronal excitability. Yet, a major difference between the
neurophysiology of 1961 and of 2011 is the recognition of the prominent role of
calcium channels in firing mechanisms. We show that including this extra
current in Hodgkin-Huxley dynamics leads to a revision of Fitzugh-Nagumo phase
portrait that affects in a fundamental way the reduced modeling of neural
excitability. The revisited model considerably enlarges the modeling power of
the original one. In particular, it captures essential electrophysiological
signatures that otherwise require non-physiological alteration or considerable
complexication of the classical model. As a basic illustration, the new model
is shown to highlight a core dynamical mechanism by which the calcium
conductance controls the two distinct firing modes of thalamocortical neurons.
</summary>
    <author>
      <name>Alessio Franci</name>
    </author>
    <author>
      <name>Guillaume Drion</name>
    </author>
    <author>
      <name>Vincent Seutin</name>
    </author>
    <author>
      <name>Rodolphe Sepulchre</name>
    </author>
    <link href="http://arxiv.org/abs/1112.2588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1117v2</id>
    <updated>2011-11-07T13:59:44Z</updated>
    <published>2011-05-05T16:32:59Z</published>
    <title>Collective Animal Behavior from Bayesian Estimation and Probability
  Matching</title>
    <summary>  Animals living in groups make movement decisions that depend, among other
factors, on social interactions with other group members. Our present
understanding of social rules in animal collectives is mainly based on
empirical fits to observations, with less emphasis in obtaining
first-principles approaches that allow their derivation. Here we show that
patterns of collective decisions can be derived from the basic ability of
animals to make probabilistic estimations in the presence of uncertainty. We
build a decision-making model with two stages: Bayesian estimation and
probabilistic matching. In the first stage, each animal makes a Bayesian
estimation of which behavior is best to perform taking into account personal
information about the environment and social information collected by observing
the behaviors of other animals. In the probability matching stage, each animal
chooses a behavior with a probability equal to the Bayesian-estimated
probability that this behavior is the most appropriate one. This model derives
very simple rules of interaction in animal collectives that depend only on two
types of reliability parameters, one that each animal assigns to the other
animals and another given by the quality of the non-social information. We test
our model by obtaining theoretically a rich set of observed collective patterns
of decisions in three-spined sticklebacks, Gasterosteus aculeatus, a shoaling
fish species. The quantitative link shown between probabilistic estimation and
collective rules of behavior allows a better contact with other fields such as
foraging, mate selection, neurobiology and psychology, and gives predictions
for experiments directly testing the relationship between estimation and
collective behavior.
</summary>
    <author>
      <name>Alfonso Pérez-Escudero</name>
    </author>
    <author>
      <name>Gonzalo G. de Polavieja</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002282</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002282" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, including Supplemental Figures and Supplemental Text. In
  press in PLoS Computational Biology</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput Biol 7(11): e1002282 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1117v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1117v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2845v2</id>
    <updated>2012-04-03T10:22:29Z</updated>
    <published>2012-01-13T14:16:51Z</published>
    <title>Competition through selective inhibitory synchrony</title>
    <summary>  Models of cortical neuronal circuits commonly depend on inhibitory feedback
to control gain, provide signal normalization, and to selectively amplify
signals using winner-take-all (WTA) dynamics. Such models generally assume that
excitatory and inhibitory neurons are able to interact easily, because their
axons and dendrites are co-localized in the same small volume. However,
quantitative neuroanatomical studies of the dimensions of axonal and dendritic
trees of neurons in the neocortex show that this co-localization assumption is
not valid. In this paper we describe a simple modification to the WTA circuit
design that permits the effects of distributed inhibitory neurons to be coupled
through synchronization, and so allows a single WTA to be distributed widely in
cortical space, well beyond the arborization of any single inhibitory neuron,
and even across different cortical areas. We prove by non-linear contraction
analysis, and demonstrate by simulation that distributed WTA sub-systems
combined by such inhibitory synchrony are inherently stable. We show
analytically that synchronization is substantially faster than winner
selection. This circuit mechanism allows networks of independent WTAs to fully
or partially compete with each other.
</summary>
    <author>
      <name>Ueli Rutishauser</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <author>
      <name>Rodney J. Douglas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in press at Neural computation; 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural computation (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.2845v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2845v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0073v1</id>
    <updated>2011-07-30T14:46:46Z</updated>
    <published>2011-07-30T14:46:46Z</published>
    <title>The Morris-Lecar neuron model embeds a leaky integrate-and-fire model</title>
    <summary>  We show that the stochastic Morris-Lecar neuron, in a neighborhood of its
stable point, can be approximated by a two-dimensional Ornstein-Uhlenbeck (OU)
modulation of a constant circular motion. The associated radial OU process is
an example of a leaky integrate-and-fire (LIF) model prior to firing. A new
model constructed from a radial OU process together with a simple firing
mechanism based on detailed Morris-Lecar firing statistics reproduces the
Morris-Lecar Interspike Interval (ISI) distribution, and has the computational
advantages of a LIF. The result justifies the large amount of attention paid to
the LIF models.
</summary>
    <author>
      <name>Susanne Ditlevsen</name>
    </author>
    <author>
      <name>Priscilla Greenwood</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00285-012-0552-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00285-012-0552-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Mathematical Biology, 67(2), 239-259, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.0073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0339v2</id>
    <updated>2012-03-26T08:28:01Z</updated>
    <published>2012-01-01T08:31:23Z</published>
    <title>Synthetic reverberating activity patterns embedded in networks of
  cortical neurons</title>
    <summary>  Synthetic reverberating activity patterns are experimentally generated by
stimulation of a subset of neurons embedded in a spontaneously active network
of cortical cells in-vitro. The neurons are artificially connected by means of
conditional stimulation matrix, forming a synthetic local circuit with a
predefined programmable connectivity and time-delays. Possible uses of this
experimental design are demonstrated, analyzing the sensitivity of these
deterministic activity patterns to transmission delays and to the nature of
ongoing network dynamics.
</summary>
    <author>
      <name>Roni Vardi</name>
    </author>
    <author>
      <name>Avner Wallach</name>
    </author>
    <author>
      <name>Evi Kopelowitz</name>
    </author>
    <author>
      <name>Moshe Abeles</name>
    </author>
    <author>
      <name>Shimon Marom</name>
    </author>
    <author>
      <name>Ido Kanter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/97/66002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/97/66002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPL (Europhysics Letters) 97, 66002 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.0339v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0339v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3666v1</id>
    <updated>2012-06-16T13:35:21Z</updated>
    <published>2012-06-16T13:35:21Z</published>
    <title>Unsupervised adaptation of brain machine interface decoders</title>
    <summary>  The performance of neural decoders can degrade over time due to
nonstationarities in the relationship between neuronal activity and behavior.
In this case, brain-machine interfaces (BMI) require adaptation of their
decoders to maintain high performance across time. One way to achieve this is
by use of periodical calibration phases, during which the BMI system (or an
external human demonstrator) instructs the user to perform certain movements or
behaviors. This approach has two disadvantages: (i) calibration phases
interrupt the autonomous operation of the BMI and (ii) between two calibration
phases the BMI performance might not be stable but continuously decrease. A
better alternative would be that the BMI decoder is able to continuously adapt
in an unsupervised manner during autonomous BMI operation, i.e. without knowing
the movement intentions of the user.
  In the present article, we present an efficient method for such unsupervised
training of BMI systems for continuous movement control. The proposed method
utilizes a cost function derived from neuronal recordings, which guides a
learning algorithm to evaluate the decoding parameters. We verify the
performance of our adaptive method by simulating a BMI user with an optimal
feedback control model and its interaction with our adaptive BMI decoder. The
simulation results show that the cost function and the algorithm yield fast and
precise trajectories towards targets at random orientations on a 2-dimensional
computer screen. For initially unknown and non-stationary tuning parameters,
our unsupervised method is still able to generate precise trajectories and to
keep its performance stable in the long term. The algorithm can optionally work
also with neuronal error signals instead or in conjunction with the proposed
unsupervised adaptation.
</summary>
    <author>
      <name>Tayfun Gürel</name>
    </author>
    <author>
      <name>Carsten Mehring</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 13 figures, submitted to Frontiers in Neuroprosthetics</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.8; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0182v1</id>
    <updated>2011-03-01T14:51:16Z</updated>
    <published>2011-03-01T14:51:16Z</published>
    <title>Neural Dynamics in Parkinsonian Brain:The Boundary Between Synchronized
  and Nonsynchronized Dynamics</title>
    <summary>  Synchronous oscillatory dynamics is frequently observed in the human brain.
We analyze the fine temporal structure of phase-locking in a realistic network
model and match it with the experimental data from parkinsonian patients. We
show that the experimentally observed intermittent synchrony can be generated
just by moderately increased coupling strength in the basal ganglia circuits
due to the lack of dopamine. Comparison of the experimental and modeling data
suggest that brain activity in Parkinson's disease resides in the large
boundary region between synchronized and nonsynchronized dynamics. Being on the
edge of synchrony may allow for easy formation of transient neuronal
assemblies.
</summary>
    <author>
      <name>Choongseok Park</name>
    </author>
    <author>
      <name>Robert M. Worth</name>
    </author>
    <author>
      <name>Leonid L. Rubchinsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.83.042901</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.83.042901" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 83, 042901 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5942v1</id>
    <updated>2011-05-30T11:02:15Z</updated>
    <published>2011-05-30T11:02:15Z</published>
    <title>Desynchronization of systems of coupled Hindmarsh-Rose oscillators</title>
    <summary>  It is widely assumed that neural activity related to synchronous rhythms of
large portions of neurons in specific locations of the brain is responsible for
the pathology manifested in patients' uncontrolled tremor and other similar
diseases. To model such systems Hindmarsh-Rose (HR) oscillators are considered
as appropriate as they mimic the qualitative behaviour of neuronal firing. Here
we consider a large number of identical HR-oscillators interacting through the
mean field created by the corresponding components of all oscillators.
Introducing additional coupling by feedback of Pyragas type, proportional to
the difference between the current value of the mean-field and its value some
time in the past, Rosenblum and Pikovsky (Phys. Rev. E 70, 041904, 2004)
demonstrated that the desirable desynchronization could be achieved with
appropriate set of parameters for the system. Following our experience with
stabilization of unstable steady states in dynamical systems, we show that by
introducing a variable delay, desynchronization is obtainable for much wider
range of parameters and that at the same time it becomes more pronounced.
</summary>
    <author>
      <name>Aleksandar Gjurchinovski</name>
    </author>
    <author>
      <name>Viktor Urumov</name>
    </author>
    <author>
      <name>Zlatko Vasilkoski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, RevTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.5942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0642v1</id>
    <updated>2011-11-02T20:12:26Z</updated>
    <published>2011-11-02T20:12:26Z</published>
    <title>Shaping bursting by electrical coupling and noise</title>
    <summary>  Gap-junctional coupling is an important way of communication between neurons
and other excitable cells. Strong electrical coupling synchronizes activity
across cell ensembles. Surprisingly, in the presence of noise synchronous
oscillations generated by an electrically coupled network may differ
qualitatively from the oscillations produced by uncoupled individual cells
forming the network. A prominent example of such behavior is the synchronized
bursting in islets of Langerhans formed by pancreatic \beta-cells, which in
isolation are known to exhibit irregular spiking. At the heart of this
intriguing phenomenon lies denoising, a remarkable ability of electrical
coupling to diminish the effects of noise acting on individual cells.
  In this paper, we derive quantitative estimates characterizing denoising in
electrically coupled networks of conductance-based models of square wave
bursting cells. Our analysis reveals the interplay of the intrinsic properties
of the individual cells and network topology and their respective contributions
to this important effect. In particular, we show that networks on graphs with
large algebraic connectivity or small total effective resistance are better
equipped for implementing denoising. As a by-product of the analysis of
denoising, we analytically estimate the rate with which trajectories converge
to the synchronization subspace and the stability of the latter to random
perturbations. These estimates reveal the role of the network topology in
synchronization. The analysis is complemented by numerical simulations of
electrically coupled conductance-based networks. Taken together, these results
explain the mechanisms underlying synchronization and denoising in an important
class of biological models.
</summary>
    <author>
      <name>Georgi S. Medvedev</name>
    </author>
    <author>
      <name>Svitlana Zhuravytska</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00422-012-0481-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00422-012-0481-y" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Biological Cybernetics Volume 106, Number 2 (2012), 67-88</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.0642v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0642v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4317v2</id>
    <updated>2011-10-29T23:18:59Z</updated>
    <published>2011-06-21T20:04:52Z</published>
    <title>A self-organizing state-space-model approach for parameter estimation in
  Hodgkin-Huxley-type models of single neurons</title>
    <summary>  Traditionally, parameter estimation in biophysical neuron and neural network
models usually adopts a global search algorithm, often combined with a local
search method in order to minimize the value of a cost function, which measures
the discrepancy between various features of the available experimental data and
model output. In this study, we approach the problem of parameter estimation in
conductance-based models of single neurons from a different perspective. By
adopting a hidden-dynamical-systems formalism, we expressed parameter
estimation as an inference problem in these systems, which can then be tackled
using well-established statistical inference methods. The particular method we
used was Kitagawa's self-organizing state-space model, which was applied on a
number of Hodgkin-Huxley models using simulated or actual electrophysiological
data. We showed that the algorithm can be used to estimate a large number of
parameters, including maximal conductances, reversal potentials, kinetics of
ionic currents and measurement noise, based on low-dimensional experimental
data and sufficiently informative priors in the form of pre-defined constraints
imposed on model parameters. The algorithm remained operational even when very
noisy experimental data were used. Importantly, by combining the
self-organizing state-space model with an adaptive sampling algorithm akin to
the Covariance Matrix Adaptation Evolution Strategy we achieved a significant
reduction in the variance of parameter estimates. The algorithm did not require
the explicit formulation of a cost function and it was straightforward to apply
on compartmental models and multiple data sets. Overall, the proposed
methodology is particularly suitable for resolving high-dimensional inference
problems based on noisy electrophysiological data and, therefore, a potentially
useful tool in the construction of biophysical neuron models.
</summary>
    <author>
      <name>Dimitrios V. Vavoulis</name>
    </author>
    <author>
      <name>Volko A. Straub</name>
    </author>
    <author>
      <name>John A. D. Aston</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002401</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002401" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vavoulis DV, Straub VA, Aston JAD, Feng J (2012) A Self-Organizing
  State-Space-Model Approach for Parameter Estimation in Hodgkin-Huxley-Type
  Models of Single Neurons. PLoS Comput Biol 8(3): e1002401</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.4317v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4317v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5082v3</id>
    <updated>2013-03-15T12:20:24Z</updated>
    <published>2012-10-18T10:25:50Z</published>
    <title>Topological and Dynamical Complexity of Random Neural Networks</title>
    <summary>  Random neural networks are dynamical descriptions of randomly interconnected
neural units. These show a phase transition to chaos as a disorder parameter is
increased. The microscopic mechanisms underlying this phase transition are
unknown, and similarly to spin-glasses, shall be fundamentally related to the
behavior of the system. In this Letter we investigate the explosion of
complexity arising near that phase transition. We show that the mean number of
equilibria undergoes a sharp transition from one equilibrium to a very large
number scaling exponentially with the dimension on the system. Near
criticality, we compute the exponential rate of divergence, called topological
complexity. Strikingly, we show that it behaves exactly as the maximal Lyapunov
exponent, a classical measure of dynamical complexity. This relationship
unravels a microscopic mechanism leading to chaos which we further demonstrate
on a simpler class of disordered systems, suggesting a deep and underexplored
link between topological and dynamical complexity.
</summary>
    <author>
      <name>Gilles Wainrib</name>
    </author>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.118101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.118101" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physical Review Letters 110, 118101 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.5082v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5082v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6251v4</id>
    <updated>2014-04-29T22:29:03Z</updated>
    <published>2012-07-26T12:21:55Z</published>
    <title>Spiking input-output relation for general biophysical neuron models</title>
    <summary>  Cortical neurons include many sub-cellular processes, operating at multiple
timescales, which may affect their response to stimulation through non-linear
and stochastic interaction with ion channels and ionic concentrations. Since
new processes are constantly being discovered, biophysical neuron models
increasingly become "too complex to be useful" yet "too simple to be
realistic". A fundamental open question in theoretical neuroscience pertains to
how this deadlock may be resolved. In order to tackle this problem, we first
define the notion of a "excitable neuron model". Then we analytically derive
the input-output relation of such neuronal models, relating input spike trains
to output spikes based on known biophysical properties. Thus we obtain
closed-form expressions for the mean firing rates, all second order statistics
(input-state-output correlation and spectra) and construct optimal linear
estimators for the neuronal response and internal state. These results are
guaranteed to hold, given a few generic assumptions, for any stochastic
biophysical neuron model (with an arbitrary number of slow kinetic processes)
under general sparse stimulation. This solution suggests that the common
simplifying approach that ignores much of the complexity of the neuron might
actually be unnecessary and even deleterious in some cases. Specifically, the
stochasticity of ion channels and the temporal sparseness of inputs is exactly
what rendered our analysis tractable, allowing us to incorporate slow kinetics.
</summary>
    <author>
      <name>Daniel Soudry</name>
    </author>
    <author>
      <name>Ron Meir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Soudry D and Meir R (2014) The neuronal response at extended
  timescales: a linearized spiking input--output relation. Front. Comput.
  Neurosci. 8:29. doi: 10.3389/fncom.2014.00029. This version of the paper is
  now obsolete. For the the updated and published version - see comments</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.6251v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6251v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3410v2</id>
    <updated>2013-09-09T11:53:34Z</updated>
    <published>2011-07-18T12:05:31Z</published>
    <title>Firing statistics of inhibitory neuron with delayed feedback. I. Output
  ISI probability density</title>
    <summary>  Activity of inhibitory neuron with delayed feedback is considered in the
framework of point stochastic processes. The neuron receives excitatory input
impulses from a Poisson stream, and inhibitory impulses from the feedback line
with a delay. We investigate here, how does the presence of inhibitory feedback
affect the output firing statistics. Using binding neuron (BN) as a model, we
derive analytically the exact expressions for the output interspike intervals
(ISI) probability density, mean output ISI and coefficient of variation as
functions of model's parameters for the case of threshold 2. Using the leaky
integrate-and-fire (LIF) model, as well as the BN model with higher thresholds,
these statistical quantities are found numerically. In contrast to the
previously studied situation of no feedback, the ISI probability densities
found here both for BN and LIF neuron become bimodal and have discontinuity of
jump type. Nevertheless, the presence of inhibitory delayed feedback was not
found to affect substantially the output ISI coefficient of variation. The ISI
coefficient of variation found ranges between 0.5 and 1. It is concluded that
introduction of delayed inhibitory feedback can radically change neuronal
output firing statistics. This statistics is as well distinct from what was
found previously (Vidybida &amp; Kravchuk, 2009) by a similar method for excitatory
neuron with delayed feedback.
</summary>
    <author>
      <name>Alexander K. Vidybida</name>
    </author>
    <author>
      <name>Kseniya G. Kravchuk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.biosystems.2012.12.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.biosystems.2012.12.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">BioSystems 112 (2013) 224-232</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.3410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G55, 92B20, 82C32, 60G30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3928v1</id>
    <updated>2012-04-17T21:51:34Z</updated>
    <published>2012-04-17T21:51:34Z</published>
    <title>Approximate invariance of metabolic energy per synapse during
  development in mammalian brains</title>
    <summary>  During mammalian development the cerebral metabolic rate correlates
qualitatively with synaptogenesis, and both often exhibit bimodal temporal
profiles. Despite these non-monotonic dependencies, it is found based on
empirical data for different mammals that regional metabolic rate per synapse
is approximately conserved from birth to adulthood for a given species (with a
slight deviation from this constancy for human visual and temporal cortices
during adolescence). A typical synapse uses about $(7\pm 2)\cdot 10^{3}$
glucose molecules per second in primate cerebral cortex, and about 5 times of
that amount in cat and rat visual cortices. A theoretical model for brain
metabolic expenditure is used to estimate synaptic signaling and neural spiking
activity during development. It is found that synaptic efficacy is generally
inversely correlated with average firing rate, and additionally, synapses
consume a bulk of metabolic energy, roughly $50-90 %$ during most of the
developmental process (except human temporal cortex $ &lt; 50%$). Overall, these
results suggest a tight regulation of brain electrical and chemical activities
during the formation and consolidation of neural connections. This presumably
reflects strong energetic constraints on brain development.
</summary>
    <author>
      <name>Jan Karbowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0033425</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0033425" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">brain development, synaptogenesis, brain metabolism</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 7(3): e33425 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2070v1</id>
    <updated>2011-03-10T16:23:58Z</updated>
    <published>2011-03-10T16:23:58Z</published>
    <title>The collective brain is critical</title>
    <summary>  The unique dynamical features of the critical state endow the brain with
properties which are fundamental for adaptive behavior. This proposal, put
forward with Per Bak several years ago, is now supported by a wide body of
empirical evidence at different scales demonstrating that the spatiotemporal
brain dynamics exhibits key signatures of critical dynamics previously
recognized in other complex systems. The rationale behind this program is
discussed in these notes, followed by an account of the most recent results,
together with a discussion of the physiological significance of these ideas.
</summary>
    <author>
      <name>Enzo Tagliazucchi</name>
    </author>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <link href="http://arxiv.org/abs/1103.2070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3765v1</id>
    <updated>2012-12-16T09:05:02Z</updated>
    <published>2012-12-16T09:05:02Z</published>
    <title>Biologically Inspired Spiking Neurons : Piecewise Linear Models and
  Digital Implementation</title>
    <summary>  There has been a strong push recently to examine biological scale simulations
of neuromorphic algorithms to achieve stronger inference capabilities. This
paper presents a set of piecewise linear spiking neuron models, which can
reproduce different behaviors, similar to the biological neuron, both for a
single neuron as well as a network of neurons. The proposed models are
investigated, in terms of digital implementation feasibility and costs,
targeting large scale hardware implementation. Hardware synthesis and physical
implementations on FPGA show that the proposed models can produce precise
neural behaviors with higher performance and considerably lower implementation
costs compared with the original model. Accordingly, a compact structure of the
models which can be trained with supervised and unsupervised learning
algorithms has been developed. Using this structure and based on a spike rate
coding, a character recognition case study has been implemented and tested.
</summary>
    <author>
      <name>Hamid Soleimani</name>
    </author>
    <author>
      <name>Arash Ahmadi</name>
    </author>
    <author>
      <name>Mohammad Bavandpour</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCSI.2012.2206463</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCSI.2012.2206463" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions On Circuits And Systems I: Regular Papers, Vol.
  59, NO. 12, December 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.7085v1</id>
    <updated>2012-05-31T19:38:08Z</updated>
    <published>2012-05-31T19:38:08Z</published>
    <title>Long-term memory stabilized by noise-induced rehearsal</title>
    <summary>  Cortical networks can maintain memories for decades despite the short
lifetime of synaptic strength. Can a neural network store long-lasting memories
in unstable synapses? Here, we study the effects of random noise on the
stability of memory stored in synapses of an attractor neural network. The
model includes ongoing spike timing dependent plasticity (STDP). We show that
certain classes of STDP rules can lead to the stabilization of memory patterns
stored in the network. The stabilization results from rehearsals induced by
noise. We show that unstructured neural noise, after passing through the
recurrent network weights, carries the imprint of all memory patterns in
temporal correlations. Under certain conditions, STDP combined with these
correlations, can lead to reinforcement of all existing patterns, even those
that are never explicitly visited. Thus, unstructured neural noise can
stabilize the existing structure of synaptic connectivity. Our findings may
provide the functional reason for highly irregular spiking displayed by
cortical neurons and provide justification for models of system memory
consolidation. Therefore, we propose that irregular neural activity is the
feature that helps cortical networks maintain stable connections.
</summary>
    <author>
      <name>Yi Wei</name>
    </author>
    <author>
      <name>Alexei A. Koulakov</name>
    </author>
    <link href="http://arxiv.org/abs/1205.7085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.7085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.3138v1</id>
    <updated>2011-12-14T08:13:59Z</updated>
    <published>2011-12-14T08:13:59Z</published>
    <title>A memristive nanoparticle/organic hybrid synapstor for neuro-inspired
  computing</title>
    <summary>  A large effort is devoted to the research of new computing paradigms
associated to innovative nanotechnologies that should complement and/or propose
alternative solutions to the classical Von Neumann/CMOS association. Among
various propositions, Spiking Neural Network (SNN) seems a valid candidate. (i)
In terms of functions, SNN using relative spike timing for information coding
are deemed to be the most effective at taking inspiration from the brain to
allow fast and efficient processing of information for complex tasks in
recognition or classification. (ii) In terms of technology, SNN may be able to
benefit the most from nanodevices, because SNN architectures are intrinsically
tolerant to defective devices and performance variability. Here we demonstrate
Spike-Timing-Dependent Plasticity (STDP), a basic and primordial learning
function in the brain, with a new class of synapstor (synapse-transistor),
called Nanoparticle Organic Memory Field Effect Transistor (NOMFET). We show
that this learning function is obtained with a simple hybrid material made of
the self-assembly of gold nanoparticles and organic semiconductor thin films.
Beyond mimicking biological synapses, we also demonstrate how the shape of the
applied spikes can tailor the STDP learning function. Moreover, the experiments
and modeling show that this synapstor is a memristive device. Finally, these
synapstors are successfully coupled with a CMOS platform emulating the pre- and
post-synaptic neurons, and a behavioral macro-model is developed on usual
device simulator.
</summary>
    <author>
      <name>F. Alibart</name>
    </author>
    <author>
      <name>S. Pleutin</name>
    </author>
    <author>
      <name>O. Bichler</name>
    </author>
    <author>
      <name>C. Gamrat</name>
    </author>
    <author>
      <name>T. Serrano-Gotarredona</name>
    </author>
    <author>
      <name>B. Linares-Barranco</name>
    </author>
    <author>
      <name>D. Vuillaume</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/adfm.201101935</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/adfm.201101935" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A single pdf file, with the full paper and the supplementary
  information; Adv. Func. Mater., on line Dec. 13 (2011)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Adv. Func. Mater., 22, 609-616 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.3138v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.3138v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.0639v1</id>
    <updated>2011-12-03T09:36:12Z</updated>
    <published>2011-12-03T09:36:12Z</published>
    <title>A tale of two stories: astrocyte regulation of synaptic depression and
  facilitation</title>
    <summary>  Short-term presynaptic plasticity designates variations of the amplitude of
synaptic information transfer whereby the amount of neurotransmitter released
upon presynaptic stimulation changes over seconds as a function of the neuronal
firing activity. While a consensus has emerged that changes of the synapse
strength are crucial to neuronal computations, their modes of expression in
vivo remain unclear. Recent experimental studies have reported that glial
cells, particularly astrocytes in the hippocampus, are able to modulate
short-term plasticity but the underlying mechanism is poorly understood. Here,
we investigate the characteristics of short-term plasticity modulation by
astrocytes using a biophysically realistic computational model. Mean-field
analysis of the model unravels that astrocytes may mediate counterintuitive
effects. Depending on the expressed presynaptic signaling pathways, astrocytes
may globally inhibit or potentiate the synapse: the amount of released
neurotransmitter in the presence of the astrocyte is transiently smaller or
larger than in its absence. But this global effect usually coexists with the
opposite local effect on paired pulses: with release-decreasing astrocytes most
paired pulses become facilitated, while paired-pulse depression becomes
prominent under release-increasing astrocytes. Moreover, we show that the
frequency of astrocytic intracellular Ca2+ oscillations controls the effects of
the astrocyte on short-term synaptic plasticity. Our model explains several
experimental observations yet unsolved, and uncovers astrocytic
gliotransmission as a possible transient switch between short-term paired-pulse
depression and facilitation. This possibility has deep implications on the
processing of neuronal spikes and resulting information transfer at synapses.
</summary>
    <author>
      <name>Maurizio De Pittà</name>
    </author>
    <author>
      <name>Vladislav Volman</name>
    </author>
    <author>
      <name>Hugues Berry</name>
    </author>
    <author>
      <name>Eshel Ben-Jacob</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002293</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002293" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">93 pages, manuscript+supplementary text, 10 main figures, 11
  supplementary figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput. Biol. (2011) 7(12): e1002293</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.0639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.0639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3241v1</id>
    <updated>2011-11-14T15:18:07Z</updated>
    <published>2011-11-14T15:18:07Z</published>
    <title>Magnetoencephalography based on high-Tc superconductivity: a closer look
  into the brain?</title>
    <summary>  Magnetoencephalography (MEG) enables the study of brain activity by recording
the magnetic fields generated by neural currents and has become an important
technique for neuroscientists in research and clinical settings. Unlike the
liquid-helium cooled low-Tc superconducting quantum interference devices
(SQUIDs) that have been at the heart of modern MEG systems since their
invention, high-Tc SQUIDs can operate with liquid nitrogen cooling. The
relaxation of thermal insulation requirements allows for a reduction in the
stand-off distance between the sensor and the room-temperature environment from
a few centimeters to less than a millimeter, where MEG signal strength is
significantly higher. Despite this advantage, high-Tc SQUIDs have only been
used for proof-of-principle MEG recordings of well-understood evoked activity.
Here we show high-Tc SQUID-based MEG may be capable of providing novel
information about brain activity due to the close proximity of the sensor to
the head. We have performed single- and two-channel high-Tc SQUID MEG
recordings of spontaneous brain activity in two healthy human subjects. We
demonstrate modulation of the occipital alpha rhythm and the mu rhythm found in
the motor cortex. Furthermore, we have discovered uncharacteristically
high-amplitude activity in the theta-band from the occipital region of the
brain. Our results suggest high-Tc SQUIDs can provide a closer look into the
brain.
</summary>
    <author>
      <name>F. Öisjöen</name>
    </author>
    <author>
      <name>J. F. Schneiderman</name>
    </author>
    <author>
      <name>G. A. Figueras</name>
    </author>
    <author>
      <name>M. L. Chukharkin</name>
    </author>
    <author>
      <name>A. Kalabukhov</name>
    </author>
    <author>
      <name>A. Hedström</name>
    </author>
    <author>
      <name>M. Elam</name>
    </author>
    <author>
      <name>D. Winkler</name>
    </author>
    <link href="http://arxiv.org/abs/1111.3241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3911v1</id>
    <updated>2011-07-20T07:31:28Z</updated>
    <published>2011-07-20T07:31:28Z</published>
    <title>Integrating temporal and spatial scales: Human structural network motifs
  across age and region-of-interest size</title>
    <summary>  Human brain networks can be characterized at different temporal or spatial
scales given by the age of the subject or the spatial resolution of the
neuroimaging method. Integration of data across scales can only be successful
if the combined networks show a similar architecture. One way to compare
networks is to look at spatial features, based on fibre length, and topological
features of individual nodes where outlier nodes form single node motifs whose
frequency yields a fingerprint of the network. Here, we observe how
characteristic single node motifs change over age (12-23 years) and network
size (414, 813, and 1615 nodes) for diffusion tensor imaging (DTI) structural
connectivity in healthy human subjects. First, we find the number and diversity
of motifs in a network to be strongly correlated. Second, comparing different
scales, the number and diversity of motifs varied across the temporal (subject
age) and spatial (network resolution) scale: certain motifs might only occur at
one spatial scale or for a certain age range. Third, regions of interest which
show one motif at a lower resolution may show a range of motifs at a higher
resolution which may or may not include the original motif at the lower
resolution. Therefore, both the type and localisation of motifs differ for
different spatial resolutions. Our results also indicate that spatial
resolution has a higher effect on topological measures whereas spatial
measures, based on fibre lengths, remain more comparable between resolutions.
Therefore, spatial resolution is crucial when comparing characteristic node
fingerprints given by topological and spatial network features. As node motifs
are based on topological and spatial properties of brain connectivity networks,
these conclusions are also relevant to other studies using connectome analysis.
</summary>
    <author>
      <name>Christoph Echtermeyer</name>
    </author>
    <author>
      <name>Cheol E. Han</name>
    </author>
    <author>
      <name>Anna Rotarska-Jagiela</name>
    </author>
    <author>
      <name>Harald Mohr</name>
    </author>
    <author>
      <name>Peter J. Uhlhaas</name>
    </author>
    <author>
      <name>Marcus Kaiser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fninf.2011.00010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fninf.2011.00010" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 8 figures; Front. Neuroinform. 5:10 (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0142v2</id>
    <updated>2012-04-03T19:58:13Z</updated>
    <published>2012-03-31T22:13:06Z</published>
    <title>TRPC4 ion channel protein is selectively expressed in a subpopulation of
  dopamine neurons in the ventral tegmental area</title>
    <summary>  The nonselective cation channel TRPC4 has been shown to be present in high
abundance in the corticolimbic regions of the brain and play a pivotal role in
modulating cellular excitability due to their involvement in intracellular Ca2+
regulation. Recently we reported their involvement in socialization and
regulating anxiety-like behaviors in rats. Given the important role for
dopamine in modulating emotions involved in social anxiety we investigated
whether TRPC4 protein and mRNA was found on dopaminergic neurons of the ventral
tegmental area (VTA). Using emulsion autoradiography we found that TRPC4 mRNA
is indeed present in the VTA and the substantia nigra. Additionally,
immunohistochemistry verified it's presence on a subpopulation of dopamine
neurons in the VTA. We confirmed these findings by testing Trpc4 knock-out rats
in addition to wild-type animals. This novel finding suggests that TRPC4 plays
a pivotal role in regulating dopamine release in a sub-population of neurons
that may modulate emotional and cognitive responses in social situations.
</summary>
    <author>
      <name>Kurt R. Illig</name>
    </author>
    <author>
      <name>Kristin C. Rasmus</name>
    </author>
    <author>
      <name>Andrew L. Varnell</name>
    </author>
    <author>
      <name>Eric M. Ostertag</name>
    </author>
    <author>
      <name>William D. Klipec</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/npre.2011.6577.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/npre.2011.6577.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages 2 figures; Nature Precedings
  http://dx.doi.org/10.1038/npre.2011.6577.1 (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0142v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0142v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7414v5</id>
    <updated>2013-08-07T10:35:08Z</updated>
    <published>2012-10-28T07:30:49Z</published>
    <title>Self-organized criticality in single neuron excitability</title>
    <summary>  We present experimental and theoretical arguments, at the single neuron
level, suggesting that neuronal response fluctuations reflect a process that
positions the neuron near a transition point that separates excitable and
unexcitable phases. This view is supported by the dynamical properties of the
system as observed in experiments on isolated cultured cortical neurons, as
well as by a theoretical mapping between the constructs of self organized
criticality and membrane excitability biophysics.
</summary>
    <author>
      <name>Asaf Gal</name>
    </author>
    <author>
      <name>Shimon Marom</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.88.062717</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.88.062717" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 88, 062717 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.7414v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7414v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6353v2</id>
    <updated>2012-01-18T04:02:23Z</updated>
    <published>2011-11-28T06:28:53Z</published>
    <title>Limitations of perturbative techniques in the analysis of rhythms and
  oscillations</title>
    <summary>  Perturbation theory is an important tool in the analysis of oscillators and
their response to external stimuli. It is predicated on the assumption that the
perturbations in question are "sufficiently weak", an assumption that is not
always valid when perturbative methods are applied. In this paper, we identify
a number of concrete dynamical scenarios in which a standard perturbative
technique, based on the infinitesimal phase response curve (PRC), is shown to
give different predictions than the full model. Shear-induced chaos, i.e.,
chaotic behavior that results from the amplification of small perturbations by
underlying shear, is missed entirely by the PRC. We show also that the presence
of "sticky" phase-space structures tend to cause perturbative techniques to
overestimate the frequencies and regularity of the oscillations. The phenomena
we describe can all be observed in a simple 2D neuron model, which we choose
for illustration as the PRC is widely used in mathematical neuroscience.
</summary>
    <author>
      <name>Kevin K. Lin</name>
    </author>
    <author>
      <name>Kyle C. A. Wedgwood</name>
    </author>
    <author>
      <name>Stephen Coombes</name>
    </author>
    <author>
      <name>Lai-Sang Young</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6353v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6353v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B25, 37N25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2382v1</id>
    <updated>2011-03-11T21:35:45Z</updated>
    <published>2011-03-11T21:35:45Z</published>
    <title>Adaptive Drift-Diffusion Process to Learn Time Intervals</title>
    <summary>  Animals learn the timing between consecutive events very easily. Their
precision is usually proportional to the interval to time (Weber's law for
timing). Most current timing models either require a central clock and
unbounded accumulator or whole pre-defined populations of delay lines, decaying
traces or oscillators to represent elapsing time. Current adaptive recurrent
neural networks fail at learning to predict the timing of future events (the
'when') in a realistic manner. In this paper, we present a new model of
interval timing, based on simple temporal integrators, derived from
drift-diffusion models. We develop a simple geometric rule to learn 'when'
instead of 'what'. We provide an analytical proof that the model can learn
inter-event intervals in a number of trials independent of the interval size
and that the temporal precision of the system is proportional to the timed
interval. This new model uses no clock, no gradient, no unbounded accumulators,
no delay lines, and has internal noise allowing generations of individual
trials. Three interesting predictions are made.
</summary>
    <author>
      <name>Francois Rivest</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5495v1</id>
    <updated>2011-01-28T10:03:39Z</updated>
    <published>2011-01-28T10:03:39Z</published>
    <title>Impact of EEG biofeedback on event-related potentials (ERPs) in
  attention-deficit hyperactivity (ADHD) children</title>
    <summary>  Impact of EEG biofeedback on event-related potentials (ERPs) in
attention-deficit hyperactivity (ADHD) children. Introduction: ADHD is one of
the most widely spread condition of school aged children affecting 5% of
children of this age.The core clinical signs of ADHD are inattention,
restlessness and impulsivity. According to various authors direct measures of
attention are of two types: 1. Recording the alpha rhythm on the EEG and
event-related potentials (ERP); 2. Tests of reaction time, continuous
performance tests, paired associated learning, and tests of memorization; The
second one is evidence-based. As for the first one it is known that ERPs
especially of those with later response reflect the process of mental
effortfullness to select the appropriate behavior and accomplish decision
making during the action of target stimulus. Thus selection of action as well
as decision making is the most important points affected in ADHD children.
Besides in recent years EEG biofeedback (Neurofeedback) have become the
evidence-based in the treatment of ADHD. Unfortunately the effectiveness of
this approach on ERPs parameters is still unknown. Thus we aimed to study the
changes of ERPs after neurofeedback therapy. Methods: We have examined 16
children with ADHD before- and after 3- sessions of neurofeedback therapy and
23 without treatment. Results: We have observed statistically significant
improvement of parameters of later response like P300 in treated children
compared with untreated ones whereas the treatment was non effective for
earlier components of ERPs. Conclusions: Neurofeedback can affect on the
process of selection of action and decision making by means of changing of P300
parameters in ADHDchildren.
</summary>
    <author>
      <name>Sophio Bakhtadze</name>
    </author>
    <author>
      <name>Marine Janelidze</name>
    </author>
    <author>
      <name>Nana Khachapuridze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 4 tables, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4862v1</id>
    <updated>2012-06-21T13:08:32Z</updated>
    <published>2012-06-21T13:08:32Z</published>
    <title>Complex synchronous behavior in interneuronal networks with delayed
  inhibitory and fast electrical synapses</title>
    <summary>  Networks of fast-spiking interneurons are crucial for the generation of
neural oscillations in the brain. Here we study the synchronous behavior of
interneuronal networks that are coupled by delayed inhibitory and fast
electrical synapses. We find that both coupling modes play a crucial role by
the synchronization of the network. In addition, delayed inhibitory synapses
affect the emerging oscillatory patterns. By increasing the inhibitory synaptic
delay, we observe a transition from regular to mixed oscillatory patterns at a
critical value. We also examine how the unreliability of inhibitory synapses
influences the emergence of synchronization and the oscillatory patterns. We
find that low levels of reliability tend to destroy synchronization, and
moreover, that interneuronal networks with long inhibitory synaptic delays
require a minimal level of reliability for the mixed oscillatory pattern to be
maintained.
</summary>
    <author>
      <name>Daqing Guo</name>
    </author>
    <author>
      <name>Qingyun Wang</name>
    </author>
    <author>
      <name>Matjaz Perc</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.85.061905</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.85.061905" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 two-column pages, 7 figures; accepted for publication in Physical
  Review E</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 85 (2012) 061905</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.6271v2</id>
    <updated>2011-10-12T00:09:53Z</updated>
    <published>2011-08-31T15:35:36Z</published>
    <title>Optimizing the quantity/quality trade-off in connectome inference</title>
    <summary>  We demonstrate a meaningful prospective power analysis for an (admittedly
idealized) illustrative connectome inference task. Modeling neurons as vertices
and synapses as edges in a simple random graph model, we optimize the trade-off
between the number of (putative) edges identified and the accuracy of the edge
identification procedure. We conclude that explicit analysis of the
quantity/quality trade-off is imperative for optimal neuroscientific
experimental design. In particular, more though more errorful edge
identification can yield superior inferential performance.
</summary>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <author>
      <name>Joshua T. Vogelstein</name>
    </author>
    <author>
      <name>Davi Bock</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.6271v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.6271v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.5933v1</id>
    <updated>2012-07-25T09:34:25Z</updated>
    <published>2012-07-25T09:34:25Z</published>
    <title>Open-source software for studying neural codes</title>
    <summary>  In this chapter we first outline some of the popular computing environments
used for analysing neural data, followed by a brief discussion of 'software
carpentry', basic tools and skills from software engineering that can be of
great use to computational scientists. We then introduce the concept of
open-source software and explain some of its potential benefits for the
academic community before giving a brief directory of some freely available
open source software packages that address various aspects of the study of
neural codes. While there are many commercial offerings that provide similar
functionality, we concentrate here on open source packages, which in addition
to being available free of charge, also have the source code available for
study and modification.
</summary>
    <author>
      <name>Robin A. A. Ince</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Quian Quiroga and Panzeri (Eds) Principles of Neural
  Coding, CRC Press, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.5933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.5933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5245v1</id>
    <updated>2012-09-24T12:28:16Z</updated>
    <published>2012-09-24T12:28:16Z</published>
    <title>Spike Timing Dependent Competitive Learning in Recurrent Self Organizing
  Pulsed Neural Networks Case Study: Phoneme and Word Recognition</title>
    <summary>  Synaptic plasticity seems to be a capital aspect of the dynamics of neural
networks. It is about the physiological modifications of the synapse, which
have like consequence a variation of the value of the synaptic weight. The
information encoding is based on the precise timing of single spike events that
is based on the relative timing of the pre- and post-synaptic spikes, local
synapse competitions within a single neuron and global competition via lateral
connections. In order to classify temporal sequences, we present in this paper
how to use a local hebbian learning, spike-timing dependent plasticity for
unsupervised competitive learning, preserving self-organizing maps of spiking
neurons. In fact we present three variants of self-organizing maps (SOM) with
spike-timing dependent Hebbian learning rule, the Leaky Integrators Neurons
(LIN), the Spiking_SOM and the recurrent Spiking_SOM (RSSOM) models. The case
study of the proposed SOM variants is phoneme classification and word
recognition in continuous speech and speaker independent.
</summary>
    <author>
      <name>Tarek Behi</name>
    </author>
    <author>
      <name>Najet Arous</name>
    </author>
    <author>
      <name>Noureddine Ellouze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 15 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, Vol. 9, Issue 4,
  No 2, (2012)328-337</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4617v1</id>
    <updated>2012-01-23T00:23:05Z</updated>
    <published>2012-01-23T00:23:05Z</published>
    <title>Photo-Thermal Neural Excitation by Extrinsic and Intrinsic Absorbers: A
  Temperature-Rate Model</title>
    <summary>  Infrared neural stimulation (INS) pulses at water-absorbed mid-IR wavelengths
could provide a non-invasive and safe modality for stimulating peripheral and
cranial nerves and central nervous system neurons. The excitation mechanism
underlying INS activation is thought to be mediated by photo-thermal tissue
transients, which can also potentially be induced using extrinsic absorbers
(Photo-Absorber Induced Neural-Thermal Stimulation or PAINTS). The specific
biophysical effect of photo-thermal transients on target neurons has yet to be
determined and quantitatively characterized. Here, we propose and study a model
for thermally-induced neural stimulation where temperature changes induce a
depolarizing transmembrane current proportional to the temperature rate of
change. Our model includes physical calculations of the temperature transients
induced by laser absorption and a biophysical model of the target cells. Our
results indicate that stimulation thresholds predicted by the model are in good
agreement with empirical data obtained in cortical cell cultures using
extrinsic micro-particle absorbers (PAINTS) as well as with earlier results on
auditory neuron stimulation using INS. These results suggest a general
empirical-law for photo-thermal interactions with neural systems, and could
help direct future basic and applied studies of these phenomena.
</summary>
    <author>
      <name>Nairouz Farah</name>
    </author>
    <author>
      <name>Inbar Brosh</name>
    </author>
    <author>
      <name>Christopher R. Butson</name>
    </author>
    <author>
      <name>Shy Shoham</name>
    </author>
    <link href="http://arxiv.org/abs/1201.4617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4469v1</id>
    <updated>2012-06-20T12:10:24Z</updated>
    <published>2012-06-20T12:10:24Z</published>
    <title>Stochastic Amplification of Fluctuations in Cortical Up-states</title>
    <summary>  Cortical neurons are bistable; as a consequence their local field potentials
can fluctuate between quiescent and active states, generating slow 0.5-2 Hz
oscillations which are widely known as transitions between Up and Down States.
Despite a large number of studies on Up-Down transitions, deciphering its
nature, mechanisms and function are still today challenging tasks. In this
paper we focus on recent experimental evidence, showing that a class of
spontaneous oscillations can emerge within the Up states. In particular, a
non-trivial peak around 20 Hz appears in their associated power-spectra, what
produces an enhancement of the activity power for higher frequencies (in the
30-90 Hz band). Moreover, this rhythm within Ups seems to be an emergent or
collective phenomenon given that individual neurons do not lock to it as they
remain mostly unsynchronized. Remarkably, similar oscillations (and the
concomitant peak in the spectrum) do not appear in the Down states. Here we
shed light on these findings by using different computational models for the
dynamics of cortical networks in presence of different levels of physiological
complexity. Our conclusion, supported by both theory and simulations, is that
the collective phenomenon of "stochastic amplification of fluctuations"
-previously described in other contexts such as Ecology and Epidemiology--
explains in an elegant and parsimonious manner, beyond model-dependent details,
this extra-rhythm emerging only in the Up states but not in the Downs.
</summary>
    <author>
      <name>Jorge Hidalgo</name>
    </author>
    <author>
      <name>Luis F. Seoane</name>
    </author>
    <author>
      <name>Jesus M. Cortes</name>
    </author>
    <author>
      <name>Miguel A. Munoz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">main text: 24 pages, 3 figures; supporting information: 16 pages, 7
  figures. Accepted for publication in PLoS ONE</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4469v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4469v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0311v1</id>
    <updated>2012-06-01T21:26:53Z</updated>
    <published>2012-06-01T21:26:53Z</published>
    <title>Speed and accuracy in a visual motion discrimination task as performed
  by rats</title>
    <summary>  We find that rats, like primates and humans, perform better on the random dot
motion task when they take more time to respond. We provide evidence that this
improvement is due to stimulus integration. Rats increase their response
latency modestly as a function of trial difficulty. Rats can modulate response
latency more strongly on a trial by trial basis, apparently on the basis of
reward-related parameters.
</summary>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <author>
      <name>Emily Mankin</name>
    </author>
    <author>
      <name>Adam Calhoun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Content is identical to a poster presented at the 2009 Society for
  Neuroscience meeting: Reinagel P, Mankin E, and Calhoun A (2009) Speed and
  accuracy in a visual motion discrimination task as performed by rats. Program
  No. 281.12. 2009 Neuroscience Meeting Planner. Chicago, IL: Society for
  Neuroscience, 2009. Online</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1076v1</id>
    <updated>2012-03-06T00:25:23Z</updated>
    <published>2012-03-06T00:25:23Z</published>
    <title>On the Relation between Encoding and Decoding of Neuronal Spikes</title>
    <summary>  Neural coding is a field of study that concerns how sensory information is
represented in the brain by networks of neurons. The link between external
stimulus and neural response can be studied from two parallel points of view.
The first, neural encoding refers to the mapping from stimulus to response, and
primarily focuses on understanding how neurons respond to a wide variety of
stimuli, and on constructing models that accurately describe the
stimulus-response relationship. Neural decoding, on the other hand, refers to
the reverse mapping, from response to stimulus, where the challenge is to
reconstruct a stimulus from the spikes it evokes. Since neuronal response is
stochastic, a one-to-one mapping of stimuli into neural responses does not
exist, causing a mismatch between the two viewpoints of neural coding. Here, we
use these two perspectives to investigate the question of what rate coding is,
in the simple setting of a single stationary stimulus parameter and a single
stationary spike train represented by a renewal process. We show that when rate
codes are defined in terms of encoding, i.e., the stimulus parameter is mapped
onto the mean firing rate, the rate decoder given by spike counts or the sample
mean, does not always efficiently decode the rate codes, but can improve
efficiency in reading certain rate codes, when correlations within a spike
train are taken into account.
</summary>
    <author>
      <name>Shinsuke Koyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.1076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2916v2</id>
    <updated>2015-05-19T21:46:42Z</updated>
    <published>2012-04-13T08:28:53Z</published>
    <title>Efficient and optimal binary Hopfield associative memory storage using
  minimum probability flow</title>
    <summary>  We present an algorithm to store binary memories in a Hopfield neural network
using minimum probability flow, a recent technique to fit parameters in
energy-based probabilistic models. In the case of memories without noise, our
algorithm provably achieves optimal pattern storage (which we show is at least
one pattern per neuron) and outperforms classical methods both in speed and
memory recovery. Moreover, when trained on noisy or corrupted versions of a
fixed set of binary patterns, our algorithm finds networks which correctly
store the originals. We also demonstrate this finding visually with the
unsupervised storage and clean-up of large binary fingerprint images from
significantly corrupted samples.
</summary>
    <author>
      <name>Christopher Hillar</name>
    </author>
    <author>
      <name>Jascha Sohl-Dickstein</name>
    </author>
    <author>
      <name>Kilian Koepsell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, 2012 Neural Information Processing Systems (NIPS)
  workshop on Discrete Optimization in Machine Learning (DISCML)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2916v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2916v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6539v1</id>
    <updated>2012-04-30T03:01:25Z</updated>
    <published>2012-04-30T03:01:25Z</published>
    <title>Neuronal avalanches of a self-organized neural network with
  active-neuron-dominant structure</title>
    <summary>  Neuronal avalanche is a spontaneous neuronal activity which obeys a power-law
distribution of population event sizes with an exponent of -3/2. It has been
observed in the superficial layers of cortex both \emph{in vivo} and \emph{in
vitro}. In this paper we analyze the information transmission of a novel
self-organized neural network with active-neuron-dominant structure. Neuronal
avalanches can be observed in this network with appropriate input intensity. We
find that the process of network learning via spike-timing dependent plasticity
dramatically increases the complexity of network structure, which is finally
self-organized to be active-neuron-dominant connectivity. Both the entropy of
activity patterns and the complexity of their resulting post-synaptic inputs
are maximized when the network dynamics are propagated as neuronal avalanches.
This emergent topology is beneficial for information transmission with high
efficiency and also could be responsible for the large information capacity of
this network compared with alternative archetypal networks with different
neural connectivity.
</summary>
    <author>
      <name>Xiumin Li</name>
    </author>
    <author>
      <name>Michael Small</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Non-final version submitted to Chaos</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 22, 023104 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.6539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2577v2</id>
    <updated>2011-09-14T19:21:18Z</updated>
    <published>2011-09-12T19:39:02Z</published>
    <title>The Organization of Strong Links in Complex Networks</title>
    <summary>  A small-world topology characterizes many complex systems including the
structural and functional organization of brain networks. The topology allows
simultaneously for local and global efficiency in the interaction of the system
constituents. However, it ignores the gradations of interactions commonly
quantified by the link weight, w. Here, we identify an integrative weight
organization for brain, gene, social, and language networks, in which strong
links preferentially occur between nodes with overlapping neighbourhoods and
the small-world properties are robust to removal of a large fraction of the
weakest links. We also determine local learning rules that dynamically
establish such weight organization in response to past activity and capacity
demands, while preserving efficient local and global communication.
</summary>
    <author>
      <name>Sinisa Pajevic</name>
    </author>
    <author>
      <name>Dietmar Plenz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 9 figures, 1 table in the main text + Supplementary
  Material</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.2577v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2577v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0309v2</id>
    <updated>2012-01-23T05:54:41Z</updated>
    <published>2011-11-01T20:26:51Z</published>
    <title>Optimal Region of Latching Activity in an Adaptive Potts Model for
  Networks of Neurons</title>
    <summary>  In statistical mechanics, the Potts model is a model for interacting spins
with more than two discrete states. Neural networks which exhibit features of
learning and associative memory can also be modeled by a system of Potts spins.
A spontaneous behavior of hopping from one discrete attractor state to another
(referred to as latching) has been proposed to be associated with higher
cognitive functions. Here we propose a model in which both the stochastic
dynamics of Potts models and an adaptive potential function are present. A
latching dynamics is observed in a limited region of the
noise(temperature)-adaptation parameter space. We hence suggest noise as a
fundamental factor in such alternations alongside adaptation. From a dynamical
systems point of view, the noise-adaptation alternations may be the underlying
mechanism for multi-stability in attractor based models. An optimality
criterion for realistic models is finally inferred.
</summary>
    <author>
      <name>Mohammad-Farshad Abdollah-nia</name>
    </author>
    <author>
      <name>Mohammadkarim Saeedghalati</name>
    </author>
    <author>
      <name>Abdolhossein Abbassian</name>
    </author>
    <link href="http://arxiv.org/abs/1111.0309v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0309v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2417v4</id>
    <updated>2013-01-25T00:02:29Z</updated>
    <published>2012-11-11T13:03:03Z</published>
    <title>Multicommand Tactile Brain Computer Interface based on Fingertips or
  Head Stimulation</title>
    <summary>  The paper presents results from a computational neuroscience study conducted
to test vibrotactile stimuli delivered to subject fingertips and head areas in
order to evoke the somatosensory brain responses utilized in a haptic brain
computer interface (hBCI) paradigm. We present the preliminary and very
encouraging results, with subjects conducting online hBCI interfacing
experiments, ranging from 40% to 90% with a very fast inter-stimulus-interval
(ISI) of 250ms. The presented results confirm our hypothesis that the hBCI
paradigm concept is valid and it allows for rapid stimuli presentation in order
to achieve a satisfactory information-transfer-rate of the novel BCI.
</summary>
    <author>
      <name>Hiromu Mori</name>
    </author>
    <author>
      <name>Yoshihiro Matsumoto</name>
    </author>
    <author>
      <name>Koichi Mori</name>
    </author>
    <author>
      <name>Victor Kryssanov</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Zbigniew R. Struzik</name>
    </author>
    <author>
      <name>Gen Hori</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to extension of the
  research and submission to the other conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.2417v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2417v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3954v2</id>
    <updated>2012-03-24T13:57:49Z</updated>
    <published>2012-03-18T14:29:30Z</published>
    <title>Gender differences in time perception and its relation with academic
  performance: non-linear dynamics in the formation of cognitive systems</title>
    <summary>  Non-linear dynamics is probably much more common in the epigenetic dynamics
of living beings than hitherto recognized. Here we report a case of global
bifurcation triggered by gender that affects higher cognitive functions in
humans. We report a cross-cultural study showing deviations in time perception,
as assessed by estimating the duration of brief sounds, according to their
durations and to the gender of the perciver. Results show that the duration of
sounds lasting less than 10 s were on average overestimated, whereas those
lasting longer were underestimated; estimates of sounds shorter than 1 s were
extremely inaccurate. Females consistently gave longer estimates than males.
Accuracy in time estimation was correlated to academic performance in
disciplines requiring mathematical or scientific skills in male, but not in
female students. This difference in correlation however had nothing to do with
overall skills in mathematics. Both sexes scored similarly in scientific and
technical disciplines, but females had higher grades than males in languages
and lower ones in physical education. Our results confirm existing evidence for
gender differences in cognitive processing, hinting to the existence of
different "mathematical intelligences" with different non-linear relationships
between natural or biological mathematical intuition and time perception.
</summary>
    <author>
      <name>Klaus Jaffe</name>
    </author>
    <author>
      <name>Guillermo Mascitti</name>
    </author>
    <author>
      <name>Daniella Seguias</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Politically incorrect paper practically impossible to publish in a
  psychology journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3954v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3954v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1544v1</id>
    <updated>2012-10-04T19:03:19Z</updated>
    <published>2012-10-04T19:03:19Z</published>
    <title>Reconstruction of Sparse Circuits Using Multi-neuronal Excitation
  (RESCUME)</title>
    <summary>  One of the central problems in neuroscience is reconstructing synaptic
connectivity in neural circuits. Synapses onto a neuron can be probed by
sequentially stimulating potentially pre-synaptic neurons while monitoring the
membrane voltage of the post-synaptic neuron. Reconstructing a large neural
circuit using such a "brute force" approach is rather time-consuming and
inefficient because the connectivity in neural circuits is sparse. Instead, we
propose to measure a post-synaptic neuron's voltage while stimulating
sequentially random subsets of multiple potentially pre-synaptic neurons. To
reconstruct these synaptic connections from the recorded voltage we apply a
decoding algorithm recently developed for compressive sensing. Compared to the
brute force approach, our method promises significant time savings that grow
with the size of the circuit. We use computer simulations to find optimal
stimulation parameters and explore the feasibility of our reconstruction method
under realistic experimental conditions including noise and non-linear synaptic
integration. Multineuronal stimulation allows reconstructing synaptic
connectivity just from the spiking activity of post-synaptic neurons, even when
sub-threshold voltage is unavailable. By using calcium indicators,
voltage-sensitive dyes, or multi-electrode arrays one could monitor activity of
multiple postsynaptic neurons simultaneously, thus mapping their synaptic
inputs in parallel, potentially reconstructing a complete neural circuit.
</summary>
    <author>
      <name>Tao Hu</name>
    </author>
    <author>
      <name>Dmitri B. Chklovskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures. Advances in Neural Information Processing Systems
  (NIPS) 22, 790 (2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.1544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2616v1</id>
    <updated>2011-04-13T20:46:43Z</updated>
    <published>2011-04-13T20:46:43Z</published>
    <title>Algorithmic choice of coordinates for injections into the brain:
  encoding a neuroanatomical atlas on a grid</title>
    <summary>  Given an atlas of the brain and a number of injections to be performed in
order to map out the connections between parts of the brain, we propose an
algorithm to compute the coordinates of the injections. The algorithm is
designed to sample the brain in the most homogeneous way compatible with the
separation of brain regions. It can be applied to other species for which a
neuroanatomical atlas is available. The computation is tested on the annotation
at a resolution of 25 microns corresponding to the Allen Reference Atlas, which
is hierarchical and consists of 209 regions. The resulting injection
coordinates are being used for the injection protocol of the Mouse Brain
Architecture project. Due to its large size and layered structure, the cerebral
cortex is treated in a separate algorithm, which is more adapted to its
geometry.
</summary>
    <author>
      <name>Pascal Grange</name>
    </author>
    <author>
      <name>Partha P. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, LaTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0451v1</id>
    <updated>2011-03-02T15:11:59Z</updated>
    <published>2011-03-02T15:11:59Z</published>
    <title>How to take turns: the fly's way to encode and decode rotational
  information</title>
    <summary>  Sensory systems take continuously varying stimuli as their input and encode
features relevant for the organism's survival into a sequence of action
potentials - spike trains. The full dynamic range of complex dynamical inputs
has to be compressed into a set of discrete spike times and the question,
facing any sensory system, arises: which features of the stimulus are thereby
encoded and how does the animal decode them to recover its external sensory
world?
  Here we study this issue for the two motion-sensitive H1 neurons of the fly's
optical system, which are sensitive to horizontal velocity stimuli, each neuron
responding to oppositely pointing preferred directions. They constitute an
efficient detector for rotations of the fly's body about a vertical axis.
Surprisingly the spike trains $\rho_B(t)$ generated by an empoverished stimulus
$S_B(t)$, containing just the instants when the of velocity $S(t)$ reverses its
direction, convey the same amount of global (Shannon) information as spike
trains $\rho(t)$ generated by the complete stimulus $S(t)$. This amount of
information is just enough to encode the instants of velocity reversal. Yet
this suffices to give the motor system just one, yet vital order: go left or
right, turning the H1 neurons into efficient analog-to-digital converters.
Furthermore also probability distributions computed from $\rho(t)$ and
$\rho_B(t)$ are identical. Still there are regions in the spike trains
following velocity reversals, 80 msec long and containing about 3-6 msec long
spike intervals, where detailed stimulus properties are encoded. We suggest a
decoding scheme - how to reconstruct the stimulus from the spike train, which
is fast and works in real time.
</summary>
    <author>
      <name>Ingrid M. Esteves</name>
    </author>
    <author>
      <name>Nelson M. Fernandes</name>
    </author>
    <author>
      <name>Roland Köberle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages including 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.0451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.2819v3</id>
    <updated>2012-05-25T00:36:55Z</updated>
    <published>2011-08-13T20:47:25Z</published>
    <title>Qubit-wannabe Neural Networks</title>
    <summary>  Recurrent neurons, or "simulated" qubits, can store simultaneous true and
false with probabilistic behaviors usually reserved for the qubits of quantum
physics. Although possible to construct artificially, simulated qubits are
intended to explain biological mysteries. It is shown below that they can
simulate certain quantum computations and, although less potent than the qubits
of quantum physics, they nevertheless are shown to significantly exceed the
capabilities of classical deterministic circuits.
</summary>
    <author>
      <name>John Robert Burger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Re-worked algorithms concerning function classification and
  satisfiability</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.2819v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.2819v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4228v1</id>
    <updated>2011-07-21T10:33:59Z</updated>
    <published>2011-07-21T10:33:59Z</published>
    <title>A Bayesian approach for inferring neuronal connectivity from calcium
  fluorescent imaging data</title>
    <summary>  Deducing the structure of neural circuits is one of the central problems of
modern neuroscience. Recently-introduced calcium fluorescent imaging methods
permit experimentalists to observe network activity in large populations of
neurons, but these techniques provide only indirect observations of neural
spike trains, with limited time resolution and signal quality. In this work we
present a Bayesian approach for inferring neural circuitry given this type of
imaging data. We model the network activity in terms of a collection of coupled
hidden Markov chains, with each chain corresponding to a single neuron in the
network and the coupling between the chains reflecting the network's
connectivity matrix. We derive a Monte Carlo Expectation--Maximization
algorithm for fitting the model parameters; to obtain the sufficient statistics
in a computationally-efficient manner, we introduce a specialized
blockwise-Gibbs algorithm for sampling from the joint activity of all observed
neurons given the observed fluorescence data. We perform large-scale
simulations of randomly connected neuronal networks with biophysically
realistic parameters and find that the proposed methods can accurately infer
the connectivity in these networks given reasonable experimental and
computational constraints. In addition, the estimation accuracy may be improved
significantly by incorporating prior knowledge about the sparseness of
connectivity in the network, via standard L$_1$ penalization methods.
</summary>
    <author>
      <name>Yuriy Mishchencko</name>
    </author>
    <author>
      <name>Joshua T. Vogelstein</name>
    </author>
    <author>
      <name>Liam Paninski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/09-AOAS303</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/09-AOAS303" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/09-AOAS303 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1229-1261</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.4228v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4228v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5550v1</id>
    <updated>2012-12-21T18:44:28Z</updated>
    <published>2012-12-21T18:44:28Z</published>
    <title>Statistical patterns of visual search for hidden objects</title>
    <summary>  The movement of the eyes has been the subject of intensive research as a way
to elucidate inner mechanisms of cognitive processes. A cognitive task that is
rather frequent in our daily life is the visual search for hidden objects. Here
we investigate through eye-tracking experiments the statistical properties
associated with the search of target images embedded in a landscape of
distractors. Specifically, our results show that the twofold process of eye
movement, composed of sequences of fixations (small steps) intercalated by
saccades (longer jumps), displays characteristic statistical signatures. While
the saccadic jumps follow a log normal distribution of distances, which is
typical of multiplicative processes, the lengths of the smaller steps in the
fixation trajectories are consistent with a power-law distribution. Moreover,
the present analysis reveals a clear transition between a directional serial
search to an isotropic random movement as the difficulty level of the searching
task is increased.
</summary>
    <author>
      <name>H. F. Credidio</name>
    </author>
    <author>
      <name>E. N. Teixeira</name>
    </author>
    <author>
      <name>S. D. S. Reis</name>
    </author>
    <author>
      <name>A. A. Moreira</name>
    </author>
    <author>
      <name>J. S. Andrade Jr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep00920</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep00920" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sci. Rep. 2, 920 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.6594v1</id>
    <updated>2012-01-31T16:21:27Z</updated>
    <published>2012-01-31T16:21:27Z</published>
    <title>Stability of the splay state in networks of pulse-coupled neurons</title>
    <summary>  We analytically investigate the stability of {\it splay states} in networks
of $N$ pulse-coupled phase-like models of neurons. By developing a perturbative
technique, we find that, in the limit of large $N$, the Floquet spectrum scales
as $1/N^2$ for generic discontinuous velocity fields. Moreover, the stability
of the so-called short-wavelength component is determined by the sign of the
jump at the discontinuity. Altogether, the form of the spectrum depends on the
pulse shape but is independent of the velocity field.
</summary>
    <author>
      <name>Simona Olmi</name>
    </author>
    <author>
      <name>Antonio Politi</name>
    </author>
    <author>
      <name>Alessandro Torcini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/2190-8567-2-12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/2190-8567-2-12" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, no figures and 120 equations</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Mathematical Neuroscience 2012, 2:12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.6594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.6594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4586v1</id>
    <updated>2011-04-23T20:07:49Z</updated>
    <published>2011-04-23T20:07:49Z</published>
    <title>Relativistic virtual worlds: an emerging framework</title>
    <summary>  In this paper, I will attempt to establish a framework for representation in
virtual worlds that may allow for input data from many different scales and
virtual physics to be merged. For example, a typical virtual environment must
effectively handle user input, sensor data, and virtual world physics all in
real- time. Merging all of these data into a single interactive system requires
that we adapt approaches from topological methods such as n-dimensional
relativistic representation. A number of hypothetical examples will be provided
throughout the paper to clarify technical challenges that need to be overcome
to realize this vision.
  The long-term goal of this work is that truly invariant representations will
ultimately result from establishing formal, inclusive relationships between
these different domains. Using this framework, incomplete information in one or
more domains can be compensated for by parallelism and mappings within the
virtual world representation. To introduce this approach, I will review recent
developments in embodiment, virtual world technology, and neuroscience relevant
to the control of virtual worlds. The next step will be to borrow ideas from
fields such as brain science, applied mathematics, and cosmology to give proper
perspective to this approach. A simple demonstration will then be given using
an intuitive example of physical relativism. Finally, future directions for the
application of this method will be considered.
</summary>
    <author>
      <name>Bradly Alicea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; H.1.2; H.5.1; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0758v1</id>
    <updated>2012-12-01T11:25:43Z</updated>
    <published>2012-12-01T11:25:43Z</published>
    <title>Observables Generalizing Positive Operator Valued Measures</title>
    <summary>  We discuss a generalization of POVM which is used in quantum-like modeling of
mental processing.
</summary>
    <author>
      <name>Irina Basieva</name>
    </author>
    <author>
      <name>Andrei Khrennikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:0711.1366</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4987v1</id>
    <updated>2011-12-21T11:07:16Z</updated>
    <published>2011-12-21T11:07:16Z</published>
    <title>Biologically-Inspired Electronics with Memory Circuit Elements</title>
    <summary>  Several abilities of biological systems, such as adaptation to natural
environment, or of animals to learn patterns when appropriately trained, are
features that are extremely useful, if emulated by electronic circuits, in
applications ranging from robotics to solution of complex optimization
problems, traffic control, etc. In this chapter, we discuss several examples of
biologically-inspired circuits that take advantage of memory circuit elements,
namely, electronic elements whose resistive, capacitive or inductive
characteristics depend on their past dynamics. We provide several illustrations
of what can be accomplished with these elements including learning circuits and
related adaptive filters, neuromorphic and cellular computing circuits, analog
massively-parallel computation architectures, etc. We also give examples of
experimental realizations of memory circuit elements and discuss opportunities
and challenges in this new field.
</summary>
    <author>
      <name>M. Di Ventra</name>
    </author>
    <author>
      <name>Y. V. Pershin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in "Advances in Neuromorphic Memristor Science and
  Applications" (Springer), edited by R. Kozma, R. Pino, G. Pazienza</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.4987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3582v1</id>
    <updated>2011-09-16T11:07:10Z</updated>
    <published>2011-09-16T11:07:10Z</published>
    <title>Some inverse problems in biophysics</title>
    <summary>  During the past few years the development of experimental techniques has
allowed the quantitative analysis of biological systems ranging from
neurobiology and molecular biology. This work focuses on the quantitative
description of these systems by means of theoretical and numerical tools
ranging from statistical physics to probability theory.
  This dissertation is divided in three parts, each of which has a different
biological system as its focus.
  The first such system is Infotaxis, an olfactory search algorithm proposed by
Vergassola et al. in 2007: we give a continuous formulation and we characterize
its performances.
  Secondly we will focus on single-molecule experiments, especially unzipping
of DNA molecules, whose experimental traces depend strongly on the DNA
sequence: we develop a detailed model of the dynamics for this kind of
experiments and then we propose several inference algorithm aiming at the
characterization of the genetic sequence.
  The last section is devoted to the description of an algorithm that allows
the inference of interactions between neurons given the recording of neural
activity from multi-electrode experiments; we propose an integrated software
that will allow the analysis of these data.
</summary>
    <author>
      <name>Carlo Barbieri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD dissertation</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6082v1</id>
    <updated>2012-10-22T22:59:58Z</updated>
    <published>2012-10-22T22:59:58Z</published>
    <title>Interplay: Dispersed Activation in Neural Networks</title>
    <summary>  This paper presents a multi-point stimulation of a Hebbian neural network
with investigation of the interplay between the stimulus waves through the
neurons of the network. Equilibrium of the resulting memory is achieved for
recall of specific memory data at a rate faster than single point stimulus. The
interplay of the intersecting stimuli appears to parallel the clarification
process of recall in biological systems.
</summary>
    <author>
      <name>Richard L. Churchill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.6082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2532v2</id>
    <updated>2011-05-11T18:19:53Z</updated>
    <published>2011-04-13T15:51:15Z</published>
    <title>Abnormal effective connectivity in migraine with aura under photic
  stimulation</title>
    <summary>  Migraine patients with aura show a peculiar pattern of visual reactivity
compared with those of migraine patients without aura: an increased effective
connectivity, connected to a reduced synchronization among EEG channels, for
frequencies in the beta band. The effective connectivity is evaluated in terms
of the Granger causality. This anomalous response to visual stimuli may play a
crucial role in the progression of spreading depression and clinical evidences
of aura symptoms.
</summary>
    <author>
      <name>Sebastiano Stramaglia</name>
    </author>
    <author>
      <name>Daniele Marinazzo</name>
    </author>
    <author>
      <name>Mario Pellicoro</name>
    </author>
    <author>
      <name>Marina de Tommaso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2532v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2532v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0758v2</id>
    <updated>2011-07-13T16:47:22Z</updated>
    <published>2011-06-03T20:16:52Z</published>
    <title>Transitions in active rotator systems: invariant hyperbolic manifold
  approach</title>
    <summary>  Our main focus is on a general class of active rotators with mean field
interactions, that is globally coupled large families of dynamical systems on
the unit circle with non-trivial stochastic dynamics. Each isolated system is a
diffusion process on a circle, with drift -delta V', where V' is a periodic
function and delta is an intensity parameter. It is well known that the
interacting dynamics is accurately described, in the limit of infinitely many
interacting components, by a Fokker-Planck PDE and the model reduces for
delta=0 to a particular case of the Kuramoto synchronization model, for which
one can show the existence of a stable normally hyperbolic manifold of
stationary solutions for the corresponding Fokker-Planck equation (we are
interested in the case in which this manifold is non-trivial, that happens when
the interaction is sufficiently strong, that is in the synchronized regime of
the Kuramoto model). We use the robustness of normally hyperbolic structures to
infer qualitative and quantitative results on the |delta|&lt; delta0 cases, with
delta0 a suitable threshold: as a matter of fact, we obtain an accurate
description of the dynamics on the invariant manifold for delta=0 and we link
it explicitly to the potential V . This approach allows to have a complete
description of the phase diagram of the active rotators model, at least for
|delta|&lt; delta0, thus identifying for which values of the parameters (notably,
noise intensity and/or coupling strength) the system exhibits periodic pulse
waves or stabilizes at a quiescent resting state. Moreover, some of our results
are very explicit and this brings a new insight into the combined effect of
active rotator dynamics, noise and interaction. The links with the literature
on specific systems, notably neuronal models, are discussed in detail.
</summary>
    <author>
      <name>Giambattista Giacomin</name>
    </author>
    <author>
      <name>Khashayar Pakdaman</name>
    </author>
    <author>
      <name>Xavier Pellegrin</name>
    </author>
    <author>
      <name>Christophe Poquet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 4 figures. Version 2: some changes in introduction, added
  references</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.0758v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0758v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37N25, 82C26, 82C31, 92B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8415v1</id>
    <updated>2012-10-31T17:47:21Z</updated>
    <published>2012-10-31T17:47:21Z</published>
    <title>Predicted selective increase of cortical magnification due to cortical
  folding</title>
    <summary>  The cortical magnification matrix M is introduced founded on a notion similar
to that of the scalar cortical magnification factor M. Unlike M, this matrix is
suitable to describe anisotropy in cortical magnification, which is of
particular interest in the highly gyrified human cerebral cortex. The advantage
of our tensor method over other surface-based 3D methods to explore cortical
morphometry is that M expresses cortical quantities in the corresponding
sensory space. It allows us to investigate the spatial relation between sensory
function and anatomical structure. To this end, we consider the calcarine
sulcus (CS) as an anatomical landmark for the primary visual cortex (V1). We
found that a stereotypically formed 3D model of V1 compared to a flat model
explains an excess of cortical tissue for the representation of visual
information coming from the horizon of the visual field. This suggests that the
intrinsic geometry of this sulcus is adapted to encephalize a particular
function along the horizon. Since visual functions are assumed to be M-scaled,
cortical folding can serve as an anatomical basis for increased functionality
on the horizon similar to a retinal specialization known as visual streak,
which is found in animals with lower encephalization. Thus, the gain of surface
area by cortical folding links anatomical structure to cortical function in a
previously unrecognized way, which may guide sulci development.
</summary>
    <author>
      <name>Markus A. Dahlem</name>
    </author>
    <author>
      <name>Jan Tusch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.8415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92C20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.5159v1</id>
    <updated>2012-07-21T16:36:39Z</updated>
    <published>2012-07-21T16:36:39Z</published>
    <title>Impact of correlated neural activity on decision making performance</title>
    <summary>  Stimulus from the environment that guides behavior and informs decisions is
encoded in the firing rates of neural populations. Each neuron in the
populations, however, does not spike independently: spike events are correlated
from cell to cell. To what degree does this apparent redundancy impact the
accuracy with which decisions can be made, and the computations that are
required to optimally decide? We explore these questions for two illustrative
models of correlation among cells. Each model is statistically identical at the
level of pairs cells, but differs in higher-order statistics that describe the
simultaneous activity of larger cell groups. We find that the presence of
correlations can diminish the performance attained by an ideal decision maker
to either a small or large extent, depending on the nature of the higher-order
interactions. Moreover, while this optimal performance can in some cases be
obtained via the standard integration-to-bound operation, in others it requires
a nonlinear computation on incoming spikes. Overall, we conclude that a given
level of pairwise correlations--even when restricted to identical neural
populations--may not always indicate redundancies that diminish decision making
performance.
</summary>
    <author>
      <name>Nicholas Cain</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <link href="http://arxiv.org/abs/1207.5159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.5159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3330v3</id>
    <updated>2013-04-03T19:56:18Z</updated>
    <published>2012-09-14T21:31:18Z</published>
    <title>Predator confusion is sufficient to evolve swarming behavior</title>
    <summary>  Swarming behaviors in animals have been extensively studied due to their
implications for the evolution of cooperation, social cognition, and
predator-prey dynamics. An important goal of these studies is discerning which
evolutionary pressures favor the formation of swarms. One hypothesis is that
swarms arise because the presence of multiple moving prey in swarms causes
confusion for attacking predators, but it remains unclear how important this
selective force is. Using an evolutionary model of a predator-prey system, we
show that predator confusion provides a sufficient selection pressure to evolve
swarming behavior in prey. Furthermore, we demonstrate that the evolutionary
effect of predator confusion on prey could in turn exert pressure on the
structure of the predator's visual field, favoring the frontally oriented,
high-resolution visual systems commonly observed in predators that feed on
swarming animals. Finally, we provide evidence that when prey evolve swarming
in response to predator confusion, there is a change in the shape of the
functional response curve describing the predator's consumption rate as prey
density increases. Thus, we show that a relatively simple perceptual
constraint--predator confusion--could have pervasive evolutionary effects on
prey behavior, predator sensory mechanisms, and the ecological interactions
between predators and prey.
</summary>
    <author>
      <name>Randal S. Olson</name>
    </author>
    <author>
      <name>Arend Hintze</name>
    </author>
    <author>
      <name>Fred C. Dyer</name>
    </author>
    <author>
      <name>David B. Knoester</name>
    </author>
    <author>
      <name>Christoph Adami</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rsif.2013.0305</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rsif.2013.0305" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 6 figures. Supplementary information (including video files
  S1 and S5) in ancillary material. Videos S2-S4 are available from the authors
  upon request</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Royal Society Interface 10 (2013) 2010305</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.3330v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3330v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4611v2</id>
    <updated>2013-01-03T16:14:03Z</updated>
    <published>2012-08-22T20:12:32Z</published>
    <title>Human Time-Frequency Acuity Beats the Fourier Uncertainty Principle</title>
    <summary>  The time-frequency uncertainty principle states that the product of the
temporal and frequency extents of a signal cannot be smaller than $1/(4\pi)$.
We study human ability to simultaneously judge the frequency and the timing of
a sound. Our subjects often exceeded the uncertainty limit, sometimes by more
than tenfold, mostly through remarkable timing acuity. Our results establish a
lower bound for the nonlinearity and complexity of the algorithms employed by
our brains in parsing transient sounds, rule out simple "linear filter" models
of early auditory processing, and highlight timing acuity as a central feature
in auditory object processing.
</summary>
    <author>
      <name>Jacob N. Oppenheim</name>
    </author>
    <author>
      <name>Marcelo O. Magnasco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.110.044301</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.110.044301" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures; Accepted at PRL</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.4611v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4611v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2032v1</id>
    <updated>2011-06-10T12:24:07Z</updated>
    <published>2011-06-10T12:24:07Z</published>
    <title>Storage capacity of phase-coded patterns in sparse neural networks</title>
    <summary>  We study the storage of multiple phase-coded patterns as stable dynamical
attractors in recurrent neural networks with sparse connectivity. To determine
the synaptic strength of existent connections and store the phase-coded
patterns, we introduce a learning rule inspired to the spike-timing dependent
plasticity (STDP). We find that, after learning, the spontaneous dynamics of
the network replay one of the stored dynamical patterns, depending on the
network initialization. We study the network capacity as a function of
topology, and find that a small- world-like topology may be optimal, as a
compromise between the high wiring cost of long range connections and the
capacity increase.
</summary>
    <author>
      <name>Siliva Scarpetta</name>
    </author>
    <author>
      <name>Ferdinando Giacco</name>
    </author>
    <author>
      <name>Antonio de Candia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Europhysics Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3963v1</id>
    <updated>2012-06-18T15:23:37Z</updated>
    <published>2012-06-18T15:23:37Z</published>
    <title>Small-world topology of functional connectivity in randomly connected
  dynamical systems</title>
    <summary>  Characterization of real-world complex systems increasingly involves the
study of their topological structure using graph theory. Among global network
properties, small-world property, consisting in existence of relatively short
paths together with high clustering of the network, is one of the most
discussed and studied. When dealing with coupled dynamical systems, links among
units of the system are commonly quantified by a measure of pairwise
statistical dependence of observed time series (functional connectivity). We
argue that the functional connectivity approach leads to upwardly biased
estimates of small-world characteristics (with respect to commonly used random
graph models) due to partial transitivity of the accepted functional
connectivity measures such as the correlation coefficient. In particular, this
may lead to observation of small-world characteristics in connectivity graphs
estimated from generic randomly connected dynamical systems. The ubiquity and
robustness of the phenomenon is documented by an extensive parameter study of
its manifestation in a multivariate linear autoregressive process, with
discussion of the potential relevance for nonlinear processes and measures.
</summary>
    <author>
      <name>Jaroslav Hlinka</name>
    </author>
    <author>
      <name>David Hartman</name>
    </author>
    <author>
      <name>Milan Paluš</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The following article has been submitted to Chaos: An
  interdisciplinary journal of nonlinear science. After it is published, it
  will be found at http://chaos.aip.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3963v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3963v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0433v1</id>
    <updated>2011-10-03T18:00:00Z</updated>
    <published>2011-10-03T18:00:00Z</published>
    <title>Computation of Object Approach by a Biophysical Model of a Wide-Field
  Visual Neuron: Dynamics, Peaks, and Fits</title>
    <summary>  Many species show avoidance reactions in response to looming object
approaches. In locusts, the corresponding escape behavior correlates with the
activity of the lobula giant movement detector (LGMD) neuron. During an object
approach, its firing rate was reported to gradually increase until a peak is
reached, and then it declines quickly. The ETA-function predicts that the LGMD
activity is a product between an exponential function of angular size and
angular velocity, and that peak activity is reached before time-to-contact
(ttc). The ETA-function has become the prevailing LGMD model because it
reproduces many experimental observations, and even experimental evidence for
the multiplicative operation was reported. Several inconsistencies remain
unresolved, though. Here we address these issues with a new model (PSI-model),
which explicitly connects angular size and angular velocity to biophysical
quantities. The PSI-model avoids biophysical problems associated with
implementing exp(), implements the multiplicative operation of ETA via divisive
inhibition, and explains why activity peaks could occur after ttc. It
consistently predicts response features of the LGMD, and provides excellent
fits to published experimental data, with goodness of fit measures comparable
to corresponding fits with the ETA-function.
</summary>
    <author>
      <name>Matthias S. Keil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A revised version of this paper with the title "Emergence of
  Multiplication in a Biophysical Model of a Wide-Field Visual Neuron for
  Computing Object Approaches: Dynamics, Peaks, &amp; Fits" has been accepted in
  Advances in Neural Information Processing Systems, NIPS 2011, Granda, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.0433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3260v1</id>
    <updated>2011-02-16T08:15:42Z</updated>
    <published>2011-02-16T08:15:42Z</published>
    <title>Adaptive Cluster Expansion for Inferring Boltzmann Machines with Noisy
  Data</title>
    <summary>  We introduce a procedure to infer the interactions among a set of binary
variables, based on their sampled frequencies and pairwise correlations. The
algorithm builds the clusters of variables contributing most to the entropy of
the inferred Ising model, and rejects the small contributions due to the
sampling noise. Our procedure successfully recovers benchmark Ising models even
at criticality and in the low temperature phase, and is applied to
neurobiological data.
</summary>
    <author>
      <name>Simona Cocco</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPS</arxiv:affiliation>
    </author>
    <author>
      <name>Rémi Monasson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPTENS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Physical Review Letters (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.1652v1</id>
    <updated>2012-08-08T12:40:19Z</updated>
    <published>2012-08-08T12:40:19Z</published>
    <title>Retinal and post-retinal contributions to the quantum efficiency of the
  human eye</title>
    <summary>  The retina is one of the best known quantum detectors with rods able to
respond to a single photon. However, estimates on the number of photons
eliciting conscious perception, based on signal detection theory, are
systematically above these values. One possibility is that post-retinal
processing significantly contributes to the decrease in the quantum efficiency
determined by signal detection. We carried out experiments in humans using
controlled sources of light while recording EEG and reaction times. Half of the
participants behaved as noisy detectors reporting perception in trials where no
light was sent. DN subjects were significantly faster to take decisions.
Reaction times significantly increased with the decrease in the number of
photons. This trend was reflected in the latency and onset of the EEG responses
over frontal and parietal contacts where the first significant differences in
latency comparable to differences in reaction time appeared. Delays in latency
of neural responses across intensities were observed later over visual areas
suggesting that they are due to the time required to reach the decision
threshold in decision areas rather than to longer integration times at sensory
areas. Our results suggest that post-retinal processing significantly
contribute to increase detection noise and thresholds, decreasing the
efficiency of the retina brain detector system.
</summary>
    <author>
      <name>Gibran Manasseh</name>
    </author>
    <author>
      <name>Chloe de Balthasar</name>
    </author>
    <author>
      <name>Bruno Sanguinetti</name>
    </author>
    <author>
      <name>Enrico Pomarico</name>
    </author>
    <author>
      <name>Nicolas Gisin</name>
    </author>
    <author>
      <name>Rolando Grave de Peralta</name>
    </author>
    <author>
      <name>Sara L. Gonzalez</name>
    </author>
    <link href="http://arxiv.org/abs/1208.1652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.1652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3888v1</id>
    <updated>2011-09-18T17:03:11Z</updated>
    <published>2011-09-18T17:03:11Z</published>
    <title>Analysing properties of the C. Elegans neural network: mathematically
  modeling a biological system</title>
    <summary>  The brain is one of the most studied and highly complex systems in the
biological world. It is the information center behind all vertebrate and most
invertebrate life, and thus has become a major focus in current research. While
many of these studies have concentrated on studying the brain directly, our
focus is the structure of the brain itself: at its core an interconnected
network of nodes (neurons). A better understanding of the structural aspects of
the brain should elucidate some of its functional properties. In this paper we
analyze the brain of the nematode Caenorhabditis elegans. Consisting of only
302 neurons, it is one of the better-understood neural networks. Using a
Laplacian matrix of the 279-neuron "giant component" of the network, we use an
eigenvalue counting function to look for fractal-like self similarity. This
matrix representation is also used to plot (in eigenfunction coordinates) both
2 and 3 dimensional visualizations of the neural network. Further analysis
examines the small-world properties of the system, including average path
length and clustering coefficient. We then test for localization of
eigenfunctions, using graph energy and spacial variance. To better understand
these results, all of these calculations are also performed on random networks,
branching trees, and known fractals, as well as fractals which have been
"rewired" to have small-world properties. This analysis is one of many
stepping-stones in the research of neural networks. While many of the
structures and functions within the brain are known, understanding how the two
interact is also important. A firmer grasp on the structural properties of the
neural network is a key step in this process
</summary>
    <author>
      <name>Daniel J. Kelleher</name>
    </author>
    <author>
      <name>Tyler M. Reese</name>
    </author>
    <author>
      <name>Dylan T. Yott</name>
    </author>
    <author>
      <name>Antoni Brzoska</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 Pages, 6 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.3867v1</id>
    <updated>2011-12-16T15:59:35Z</updated>
    <published>2011-12-16T15:59:35Z</published>
    <title>The use of information theory in evolutionary biology</title>
    <summary>  Information is a key concept in evolutionary biology. Information is stored
in biological organism's genomes, and used to generate the organism as well as
to maintain and control it. Information is also "that which evolves". When a
population adapts to a local environment, information about this environment is
fixed in a representative genome. However, when an environment changes,
information can be lost. At the same time, information is processed by animal
brains to survive in complex environments, and the capacity for information
processing also evolves. Here I review applications of information theory to
the evolution of proteins as well as to the evolution of information processing
in simulated agents that adapt to perform a complex task.
</summary>
    <author>
      <name>Christoph Adami</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1749-6632.2011.06422.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1749-6632.2011.06422.x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 7 figures. To appear in "The Year in Evolutionary Biology",
  of the Annals of the NY Academy of Sciences</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals NY Acad. Sciences 1256 (2012) 49-65</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.3867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.3867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0947v1</id>
    <updated>2012-11-05T17:50:56Z</updated>
    <published>2012-11-05T17:50:56Z</published>
    <title>Online Discrimination of Nonlinear Dynamics with Switching Differential
  Equations</title>
    <summary>  How to recognise whether an observed person walks or runs? We consider a
dynamic environment where observations (e.g. the posture of a person) are
caused by different dynamic processes (walking or running) which are active one
at a time and which may transition from one to another at any time. For this
setup, switching dynamic models have been suggested previously, mostly, for
linear and nonlinear dynamics in discrete time. Motivated by basic principles
of computations in the brain (dynamic, internal models) we suggest a model for
switching nonlinear differential equations. The switching process in the model
is implemented by a Hopfield network and we use parametric dynamic movement
primitives to represent arbitrary rhythmic motions. The model generates
observed dynamics by linearly interpolating the primitives weighted by the
switching variables and it is constructed such that standard filtering
algorithms can be applied. In two experiments with synthetic planar motion and
a human motion capture data set we show that inference with the unscented
Kalman filter can successfully discriminate several dynamic processes online.
</summary>
    <author>
      <name>Sebastian Bitzer</name>
    </author>
    <author>
      <name>Izzet B. Yildiz</name>
    </author>
    <author>
      <name>Stefan J. Kiebel</name>
    </author>
    <link href="http://arxiv.org/abs/1211.0947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5376v2</id>
    <updated>2013-05-17T14:25:03Z</updated>
    <published>2011-05-26T19:06:10Z</published>
    <title>Response of the Hodgkin-Huxley neuron to a periodic sequence of biphasic
  pulses</title>
    <summary>  We study the response of the Hodgkin-Huxley neuron stimulated periodically by
biphasic rectangular current pulses. The optimal response for charge-balanced
input is obtained for cathodic-first pulses with an inter-phase gap (IPG)
approximately equal 5 ms. For short pulses the topology of the global
bifurcation diagram in the period-amplitude plane is approximately invariant
with respect to the pulse polarity and shape details. If stimuli are delivered
at neuron's resonant frequencies the firing rate is a continuous function of
pulse amplitude. At nonresonant frequencies the quiescent state and the firing
state coexist over a range of amplitude values and the transition to
excitability is a discontinuous one. There is a multimodal odd-all transition
between the 2:1 and 3:1 locked-in states. A strong antiresonant effect is found
between the states 3:1 and 4:1, where the modes (2+3n):1, $n=0,1,2,...$, are
entirely absent. At high frequencies the excitation threshold is a nonmonotonic
function of the stimulus and the perithreshold region is bistable, with the
quiescent state coexisting with either a regular or chaotic firing.
</summary>
    <author>
      <name>L. S. Borkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.5376v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5376v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0621v3</id>
    <updated>2013-07-16T23:31:16Z</updated>
    <published>2012-12-04T06:17:36Z</published>
    <title>Development of spatial coarse-to-fine processing in the visual pathway</title>
    <summary>  The sequential analysis of information in a coarse-to-fine manner is a
fundamental mode of processing in the visual pathway. Spatial frequency (SF)
tuning, arguably the most fundamental feature of spatial vision, provides
particular intuition within the coarse-to-fine framework: low spatial
frequencies convey global information about an image (e.g., general
orientation), while high spatial frequencies carry more detailed information
(e.g., edges). In this paper, we study the development of cortical spatial
frequency tuning. As feedforward input from the lateral geniculate nucleus
(LGN) has been shown to have significant influence on cortical coarse-to-fine
processing, we present a firing-rate based thalamocortical model which includes
both feedforward and feedback components. We analyze the relationship between
various model parameters (including cortical feedback strength) and responses.
We confirm the importance of the antagonistic relationship between the center
and surround responses in thalamic relay cell receptive fields (RFs), and
further characterize how specific structural LGN RF parameters affect cortical
coarse-to-fine processing. Our results also indicate that the effect of
cortical feedback on spatial frequency tuning is age-dependent: in particular,
cortical feedback more strongly affects coarse-to-fine processing in kittens
than in adults. We use our results to propose an experimentally testable
hypothesis for the function of the extensive feedback in the corticothalamic
circuit.
</summary>
    <author>
      <name>Jasmine A. Nirody</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 7 figures; substantial restructuring from previous version</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0621v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0621v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3647v4</id>
    <updated>2013-12-13T14:53:44Z</updated>
    <published>2012-12-15T01:29:33Z</published>
    <title>Parametric inference in the large data limit using maximally informative
  models</title>
    <summary>  Motivated by data-rich experiments in transcriptional regulation and sensory
neuroscience, we consider the following general problem in statistical
inference. When exposed to a high-dimensional signal S, a system of interest
computes a representation R of that signal which is then observed through a
noisy measurement M. From a large number of signals and measurements, we wish
to infer the "filter" that maps S to R. However, the standard method for
solving such problems, likelihood-based inference, requires perfect a priori
knowledge of the "noise function" mapping R to M. In practice such noise
functions are usually known only approximately, if at all, and using an
incorrect noise function will typically bias the inferred filter. Here we show
that, in the large data limit, this need for a pre-characterized noise function
can be circumvented by searching for filters that instead maximize the mutual
information I[M;R] between observed measurements and predicted representations.
Moreover, if the correct filter lies within the space of filters being
explored, maximizing mutual information becomes equivalent to simultaneously
maximizing every dependence measure that satisfies the Data Processing
Inequality. It is important to note that maximizing mutual information will
typically leave a small number of directions in parameter space unconstrained.
We term these directions "diffeomorphic modes" and present an equation that
allows these modes to be derived systematically. The presence of diffeomorphic
modes reflects a fundamental and nontrivial substructure within parameter
space, one that is obscured by standard likelihood-based inference.
</summary>
    <author>
      <name>Justin B. Kinney</name>
    </author>
    <author>
      <name>Gurinder S. Atwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Neural Computation</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3647v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3647v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3108v3</id>
    <updated>2012-12-12T07:00:59Z</updated>
    <published>2012-06-14T13:57:28Z</published>
    <title>A common rule for decision-making in animal collectives across species</title>
    <summary>  A diversity of decision-making systems has been observed in animal
collectives. In some species, choices depend on the differences of the numbers
of animals that have chosen each of the available options, while in other
species on the relative differences (a behavior known as Weber's law) or follow
more complex rules. We here show that this diversity of decision systems
corresponds to a single rule of decision-making in collectives. We first
obtained a decision rule based on Bayesian estimation that uses the information
provided by the behaviors of the other individuals to improve the estimation of
the structure of the world. We then tested this rule in decision experiments
using zebrafish (Danio rerio), and in existing rich datasets of argentine ants
(Linepithema humile) and sticklebacks (Gasterosteus aculeatus), showing that a
unified model across species can quantitatively explain the diversity of
decision systems. Further, these results show that the different counting
systems used by animals, including humans, can emerge from the common principle
of using social information to make good decisions.
</summary>
    <author>
      <name>Sara Arganda</name>
    </author>
    <author>
      <name>Alfonso Pérez-Escudero</name>
    </author>
    <author>
      <name>Gonzalo G. de Polavieja</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1073/pnas.1210664109</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1073/pnas.1210664109" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc Natl Acad Sci USA vol. 109 no. 50 20508-20513 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.3108v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3108v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3915v1</id>
    <updated>2011-01-20T14:36:11Z</updated>
    <published>2011-01-20T14:36:11Z</published>
    <title>A Lower Bound for the First Passage Time Density of the Suprathreshold
  Ornstein-Uhlenbeck Process</title>
    <summary>  We prove that the first passage time density $\rho(t)$ for an
Ornstein-Uhlenbeck process $X(t)$ obeying $dX=-\beta X dt + \sigma dW$ to reach
a fixed threshold $\theta$ from a suprathreshold initial condition
$x_0&gt;\theta&gt;0$ has a lower bound of the form $\rho(t)&gt;k \exp\left[-p e^{6\beta
t}\right]$ for positive constants $k$ and $p$ for times $t$ exceeding some
positive value $u$. We obtain explicit expressions for $k, p$ and $u$ in terms
of $\beta$, $\sigma$, $x_0$ and $\theta$, and discuss application of the
results to the synchronization of periodically forced stochastic leaky
integrate-and-fire model neurons.
</summary>
    <author>
      <name>Peter J. Thomas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1239/jap/1308662636</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1239/jap/1308662636" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Appl. Probab. Volume 48, Number 2 (2011), 420-434</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.3915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60J70, 92C20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7083v4</id>
    <updated>2013-02-21T16:55:08Z</updated>
    <published>2012-10-26T09:51:03Z</published>
    <title>Six networks on a universal neuromorphic computing substrate</title>
    <summary>  In this study, we present a highly configurable neuromorphic computing
substrate and use it for emulating several types of neural networks. At the
heart of this system lies a mixed-signal chip, with analog implementations of
neurons and synapses and digital transmission of action potentials. Major
advantages of this emulation device, which has been explicitly designed as a
universal neural network emulator, are its inherent parallelism and high
acceleration factor compared to conventional computers. Its configurability
allows the realization of almost arbitrary network topologies and the use of
widely varied neuronal and synaptic parameters. Fixed-pattern noise inherent to
analog circuitry is reduced by calibration routines. An integrated development
environment allows neuroscientists to operate the device without any prior
knowledge of neuromorphic circuit design. As a showcase for the capabilities of
the system, we describe the successful emulation of six different neural
networks which cover a broad spectrum of both structure and functionality.
</summary>
    <author>
      <name>Thomas Pfeil</name>
    </author>
    <author>
      <name>Andreas Grübl</name>
    </author>
    <author>
      <name>Sebastian Jeltsch</name>
    </author>
    <author>
      <name>Eric Müller</name>
    </author>
    <author>
      <name>Paul Müller</name>
    </author>
    <author>
      <name>Mihai A. Petrovici</name>
    </author>
    <author>
      <name>Michael Schmuker</name>
    </author>
    <author>
      <name>Daniel Brüderle</name>
    </author>
    <author>
      <name>Johannes Schemmel</name>
    </author>
    <author>
      <name>Karlheinz Meier</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fnins.2013.00011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fnins.2013.00011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Neurosci. 7:11 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.7083v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7083v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4482v2</id>
    <updated>2013-02-09T21:34:51Z</updated>
    <published>2012-02-20T22:02:16Z</published>
    <title>Metabolic cost as an organizing principle for cooperative learning</title>
    <summary>  This paper investigates how neurons can use metabolic cost to facilitate
learning at a population level. Although decision-making by individual neurons
has been extensively studied, questions regarding how neurons should behave to
cooperate effectively remain largely unaddressed. Under assumptions that
capture a few basic features of cortical neurons, we show that constraining
reward maximization by metabolic cost aligns the information content of actions
with their expected reward. Thus, metabolic cost provides a mechanism whereby
neurons encode expected reward into their outputs. Further, aside from reducing
energy expenditures, imposing a tight metabolic constraint also increases the
accuracy of empirical estimates of rewards, increasing the robustness of
distributed learning. Finally, we present two implementations of metabolically
constrained learning that confirm our theoretical finding. These results
suggest that metabolic cost may be an organizing principle underlying the
neural code, and may also provide a useful guide to the design and analysis of
other cooperating populations.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <author>
      <name>Pedro A Ortega</name>
    </author>
    <author>
      <name>Michel Besserve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 2 figures, to appear in Advances in Complex Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4482v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4482v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6319v1</id>
    <updated>2012-07-26T16:28:11Z</updated>
    <published>2012-07-26T16:28:11Z</published>
    <title>The simplest maximum entropy model for collective behavior in a neural
  network</title>
    <summary>  Recent work emphasizes that the maximum entropy principle provides a bridge
between statistical mechanics models for collective behavior in neural networks
and experiments on networks of real neurons. Most of this work has focused on
capturing the measured correlations among pairs of neurons. Here we suggest an
alternative, constructing models that are consistent with the distribution of
global network activity, i.e. the probability that K out of N cells in the
network generate action potentials in the same small time bin. The inverse
problem that we need to solve in constructing the model is analytically
tractable, and provides a natural "thermodynamics" for the network in the limit
of large N. We analyze the responses of neurons in a small patch of the retina
to naturalistic stimuli, and find that the implied thermodynamics is very close
to an unusual critical point, in which the entropy (in proper units) is exactly
equal to the energy.
</summary>
    <author>
      <name>Gasper Tkacik</name>
    </author>
    <author>
      <name>Olivier Marre</name>
    </author>
    <author>
      <name>Thierry Mora</name>
    </author>
    <author>
      <name>Dario Amodei</name>
    </author>
    <author>
      <name>Michael J. Berry II</name>
    </author>
    <author>
      <name>William Bialek</name>
    </author>
    <link href="http://arxiv.org/abs/1207.6319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4485v1</id>
    <updated>2012-10-16T16:41:57Z</updated>
    <published>2012-10-16T16:41:57Z</published>
    <title>Leg-tracking and automated behavioral classification in Drosophila</title>
    <summary>  Here we present the first method for tracking each leg of a fruit fly
behaving spontaneously upon a trackball, in real time. Legs were tracked with
infrared-fluorescent dye invisible to the fly, and compatible with two-photon
microscopy and controlled visual stimuli. We developed machine learning
classifiers to identify instances of numerous behavioral features (e.g.
walking, turning, grooming) thus producing the highest resolution ethological
profiles for individual flies.
</summary>
    <author>
      <name>Jamey Kain</name>
    </author>
    <author>
      <name>Chris Stokes</name>
    </author>
    <author>
      <name>Quentin Gaudry</name>
    </author>
    <author>
      <name>Xiangzhi Song</name>
    </author>
    <author>
      <name>James Foley</name>
    </author>
    <author>
      <name>Rachel Wilson</name>
    </author>
    <author>
      <name>Benjamin de Bivort</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, incl 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.4485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2048v1</id>
    <updated>2011-06-09T18:30:52Z</updated>
    <published>2011-06-09T18:30:52Z</published>
    <title>Old equations for a new system: A possible use of Navier-Stokes
  equations to model the circulation of spikes in the nervous system</title>
    <summary>  In the present work we discuss a possible application of Navier-Stokes-based
models to the quantitative description of the circulation of nervous impulses
throughout the nervous system. In previous works we have shown that the
discharge from Basal Ganglia neurons from patients with Parkinson's disease
share mathematical features with the velocity fields of fluids under turbulence
regimes. In the present work we try to build the fundaments for a physical
analogy between both kinds of systems.
</summary>
    <author>
      <name>Daniela Sabrina Andres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 color figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3051v3</id>
    <updated>2013-04-10T18:56:06Z</updated>
    <published>2012-09-13T22:11:13Z</published>
    <title>Chaos and reliability in balanced spiking networks with temporal drive</title>
    <summary>  Biological information processing is often carried out by complex networks of
interconnected dynamical units. A basic question about such networks is that of
reliability: if the same signal is presented many times with the network in
different initial states, will the system entrain to the signal in a repeatable
way? Reliability is of particular interest in neuroscience, where large,
complex networks of excitatory and inhibitory cells are ubiquitous. These
networks are known to autonomously produce strongly chaotic dynamics - an
obvious threat to reliability. Here, we show that such chaos persists in the
presence of weak and strong stimuli, but that even in the presence of chaos,
intermittent periods of highly reliable spiking often coexist with unreliable
activity. We elucidate the local dynamical mechanisms involved in this
intermittent reliability, and investigate the relationship between this
phenomenon and certain time-dependent attractors arising from the dynamics. A
conclusion is that chaotic dynamics do not have to be an obstacle to precise
spike responses, a fact with implications for signal coding in large networks.
</summary>
    <author>
      <name>Guillaume Lajoie</name>
    </author>
    <author>
      <name>Kevin K. Lin</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3051v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3051v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20, 37H99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2239v1</id>
    <updated>2011-09-10T17:36:38Z</updated>
    <published>2011-09-10T17:36:38Z</published>
    <title>A sparse coding model with synaptically local plasticity and spiking
  neurons can account for the diverse shapes of V1 simple cell receptive fields</title>
    <summary>  Sparse coding algorithms trained on natural images can accurately predict the
features that excite visual cortical neurons, but it is not known whether such
codes can be learned using biologically realistic plasticity rules. We have
developed a biophysically motivated spiking network, relying solely on
synaptically local information, that can predict the full diversity of V1
simple cell receptive field shapes when trained on natural images. This
represents the first demonstration that sparse coding principles, operating
within the constraints imposed by cortical architecture, can successfully
reproduce these receptive fields. We further prove, mathematically, that
sparseness and decorrelation are the key ingredients that allow for
synaptically local plasticity rules to optimize a cooperative, linear
generative image model formed by the neural representation. Finally, we discuss
several interesting emergent properties of our network, with the intent of
bridging the gap between theoretical and experimental studies of visual cortex.
</summary>
    <author>
      <name>Joel Zylberberg</name>
    </author>
    <author>
      <name>Jason Timothy Murphy</name>
    </author>
    <author>
      <name>Michael Robert DeWeese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002250</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002250" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 6 figures. To appear in PLoS Computational Biology. Some of
  these data were presented by author JZ at the 2011 CoSyNe meeting in Salt
  Lake City</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Computational Biology (2011) 7(10): e1002250</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.2239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0528v2</id>
    <updated>2012-05-03T15:46:44Z</updated>
    <published>2012-05-01T12:15:03Z</published>
    <title>Are insight problems really different from noninsight problems?</title>
    <summary>  In this text, I will suggest an electroencephalogram (EEG) experiment with
which it will be possible to see whether there is biological evidence for the
frequently made distinction between insight and noninsight problems. What is
meant with insight here is the 'aha'-experience, the sudden discovery of how a
problem works. First, I will give a summary of the research done by Auke Pols
in his thesis 'Insight in problem solving' (Pols, 2002), an introductory text
on insight. This part of this text consists of an overview of the questions
Pols asks himself, the answers to these questions, and the methods he uses to
find them. Secondly, I will formulate my own research question, and propose the
methods with which I want to answer this question.
</summary>
    <author>
      <name>Matthijs Melissen</name>
    </author>
    <link href="http://arxiv.org/abs/1205.0528v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0528v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5041v2</id>
    <updated>2012-04-18T10:01:42Z</updated>
    <published>2012-02-22T21:02:10Z</published>
    <title>Information flow in a network model and the law of diminishing marginal
  returns</title>
    <summary>  We analyze a simple dynamical network model which describes the limited
capacity of nodes to process the input information. For a suitable choice of
the parameters, the information flow pattern is characterized by exponential
distribution of the incoming information and a fat-tailed distribution of the
outgoing information, as a signature of the law of diminishing marginal
returns. The analysis of a real EEG data-set shows that similar phenomena may
be relevant for brain signals.
</summary>
    <author>
      <name>Daniele Marinazzo</name>
    </author>
    <author>
      <name>Mario Pellicoro</name>
    </author>
    <author>
      <name>Guorong Wu</name>
    </author>
    <author>
      <name>Leonardo Angelini</name>
    </author>
    <author>
      <name>Sebastiano Stramaglia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6979v1</id>
    <updated>2012-10-25T11:09:56Z</updated>
    <published>2012-10-25T11:09:56Z</published>
    <title>Attractor networks and memory replay of phase coded spike patterns</title>
    <summary>  We analyse the storage and retrieval capacity in a recurrent neural network
of spiking integrate and fire neurons. In the model we distinguish between a
learning mode, during which the synaptic connections change according to a
Spike-Timing Dependent Plasticity (STDP) rule, and a recall mode, in which
connections strengths are no more plastic. Our findings show the ability of the
network to store and recall periodic phase coded patterns a small number of
neurons has been stimulated. The self sustained dynamics selectively gives an
oscillating spiking activity that matches one of the stored patterns, depending
on the initialization of the network.
</summary>
    <author>
      <name>Ferdinando Giacco</name>
    </author>
    <author>
      <name>Silvia Scarpetta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1210.6789</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers in Artificial Intelligence and Applications, Volume 234,
  2011, pag 265-274</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0754v1</id>
    <updated>2012-10-02T12:43:18Z</updated>
    <published>2012-10-02T12:43:18Z</published>
    <title>Invariance of visual operations at the level of receptive fields</title>
    <summary>  Receptive field profiles registered by cell recordings have shown that
mammalian vision has developed receptive fields tuned to different sizes and
orientations in the image domain as well as to different image velocities in
space-time. This article presents a theoretical model by which families of
idealized receptive field profiles can be derived mathematically from a small
set of basic assumptions that correspond to structural properties of the
environment. The article also presents a theory for how basic invariance
properties to variations in scale, viewing direction and relative motion can be
obtained from the output of such receptive fields, using complementary
selection mechanisms that operate over the output of families of receptive
fields tuned to different parameters. Thereby, the theory shows how basic
invariance properties of a visual system can be obtained already at the level
of receptive fields, and we can explain the different shapes of receptive field
profiles found in biological vision from a requirement that the visual system
should be invariant to the natural types of image transformations that occur in
its environment.
</summary>
    <author>
      <name>Tony Lindeberg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0066990</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0066990" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 17 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 8(7):e66990, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.0754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6129v1</id>
    <updated>2012-06-26T21:48:53Z</updated>
    <published>2012-06-26T21:48:53Z</published>
    <title>A phase transition in the first passage of a Brownian process through a
  fluctuating boundary: implications for neural coding</title>
    <summary>  Finding the first time a fluctuating quantity reaches a given boundary is a
deceptively simple-looking problem of vast practical importance in physics,
biology, chemistry, neuroscience, economics and industry. Problems in which the
bound to be traversed is itself a fluctuating function of time include widely
studied settings in neural coding, such as neuronal integrators with irregular
inputs and internal noise. We show that the probability p(t) that a
Gauss-Markov process will first exceed the boundary at time t suffers a phase
transition as a function of the roughness of the boundary, as measured by its
H\"older exponent H, with critical value Hc = 1/2. For smoother boundaries, H &gt;
1/2, the probability density is a continuous func- tion of time. For rougher
boundaries, H &lt; 1/2, the probability is concentrated on a Cantor-like set of
zero measure: the probability density becomes divergent, almost everywhere
either zero or infin- ity. The critical point Hc = 1/2 corresponds to a
widely-studied case in the theory of neural coding, where the external input
integrated by a model neuron is a white-noise process, such as uncorrelated but
precisely balanced excitatory and inhibitory inputs. We argue this transition
corresponds to a sharp boundary between rate codes, in which the neural firing
probability varies smoothly, and temporal codes, in which the neuron fires at
sharply-defined times regardless of the intensity of internal noise.
</summary>
    <author>
      <name>Thibaud Taillefumier</name>
    </author>
    <author>
      <name>Marcelo O. Magnasco</name>
    </author>
    <link href="http://arxiv.org/abs/1206.6129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2596v1</id>
    <updated>2012-09-12T12:53:02Z</updated>
    <published>2012-09-12T12:53:02Z</published>
    <title>Limits and dynamics of stochastic neuronal networks with random
  heterogeneous delays</title>
    <summary>  Realistic networks display heterogeneous transmission delays. We analyze here
the limits of large stochastic multi-populations networks with stochastic
coupling and random interconnection delays. We show that depending on the
nature of the delays distributions, a quenched or averaged propagation of chaos
takes place in these networks, and that the network equations converge towards
a delayed McKean-Vlasov equation with distributed delays. Our approach is
mostly fitted to neuroscience applications. We instantiate in particular a
classical neuronal model, the Wilson and Cowan system, and show that the
obtained limit equations have Gaussian solutions whose mean and standard
deviation satisfy a closed set of coupled delay differential equations in which
the distribution of delays and the noise levels appear as parameters. This
allows to uncover precisely the effects of noise, delays and coupling on the
dynamics of such heterogeneous networks, in particular their role in the
emergence of synchronized oscillations. We show in several examples that not
only the averaged delay, but also the dispersion, govern the dynamics of such
networks.
</summary>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <link href="http://arxiv.org/abs/1209.2596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1564v4</id>
    <updated>2012-12-17T16:58:04Z</updated>
    <published>2012-04-06T20:57:07Z</published>
    <title>Minimal model of associative learning for cross-situational lexicon
  acquisition</title>
    <summary>  An explanation for the acquisition of word-object mappings is the associative
learning in a cross-situational scenario. Here we present analytical results of
the performance of a simple associative learning algorithm for acquiring a
one-to-one mapping between $N$ objects and $N$ words based solely on the
co-occurrence between objects and words. In particular, a learning trial in our
learning scenario consists of the presentation of $C + 1 &lt; N$ objects together
with a target word, which refers to one of the objects in the context. We find
that the learning times are distributed exponentially and the learning rates
are given by $\ln{[\frac{N(N-1)}{C + (N-1)^{2}}]}$ in the case the $N$ target
words are sampled randomly and by $\frac{1}{N} \ln [\frac{N-1}{C}] $ in the
case they follow a deterministic presentation sequence. This learning
performance is much superior to those exhibited by humans and more realistic
learning algorithms in cross-situational experiments. We show that introduction
of discrimination limitations using Weber's law and forgetting reduce the
performance of the associative algorithm to the human level.
</summary>
    <author>
      <name>Paulo F. C. Tilles</name>
    </author>
    <author>
      <name>Jose F. Fontanari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jmp.2012.11.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jmp.2012.11.002" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Math. Psych. 56, 396-403 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.1564v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1564v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3025v2</id>
    <updated>2013-11-20T08:02:32Z</updated>
    <published>2012-05-14T13:48:51Z</published>
    <title>Current practice in software development for computational neuroscience
  and how to improve it</title>
    <summary>  Almost all research work in computational neuroscience involves software. As
researchers try to understand ever more complex systems, there is a continual
need for software with new capabilities. Because of the wide range of questions
being investigated, new software is often developed rapidly by individuals or
small groups. In these cases, it can be hard to demonstrate that the software
gives the right results. Software developers are often open about the code they
produce and willing to share it, but there is little appreciation among
potential users of the great diversity of software development practices and
end results, and how this affects the suitability of software tools for use in
research projects. To help clarify these issues, we have reviewed a range of
software tools and asked how the culture and practice of software development
affects their validity and trustworthiness. We identified four key questions
that can be used to categorize software projects and correlate them with the
type of product that results. The first question addresses what is being
produced. The other three concern why, how, and by whom the work is done. The
answers to these questions show strong correlations with the nature of the
software being produced, and its suitability for particular purposes. Based on
our findings, we suggest ways in which current software development practice in
computational neuroscience can be improved and propose checklists to help
developers, reviewers and scientists to assess the quality whether particular
pieces of software are ready for use in research.
</summary>
    <author>
      <name>Marc-Oliver Gewaltig</name>
    </author>
    <author>
      <name>Robert Cannon</name>
    </author>
    <link href="http://arxiv.org/abs/1205.3025v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3025v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2599v1</id>
    <updated>2012-09-12T13:01:52Z</updated>
    <published>2012-09-12T13:01:52Z</published>
    <title>Heterogeneous connections induce oscillations in large scale networks</title>
    <summary>  Realistic large-scale networks display an heterogeneous distribution of
connectivity weights, that might also randomly vary in time. We show that
depending on the level of heterogeneity in the connectivity coefficients,
different qualitative macroscopic and microscopic regimes emerge. We evidence
in particular generic transitions from stationary to perfectly periodic
phase-locked regimes as the disorder parameter is increased, both in a simple
model treated analytically and in a biologically relevant network made of
excitable cells.
</summary>
    <author>
      <name>Geoffroy Hermann</name>
    </author>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.109.018702</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.109.018702" rel="related"/>
    <link href="http://arxiv.org/abs/1209.2599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5853v1</id>
    <updated>2011-01-31T05:53:42Z</updated>
    <published>2011-01-31T05:53:42Z</published>
    <title>Modular organization enhances the robustness of attractor network
  dynamics</title>
    <summary>  Modular organization characterizes many complex networks occurring in nature,
including the brain. In this paper we show that modular structure may be
responsible for increasing the robustness of certain dynamical states of such
systems. In a neural network model with threshold-activated binary elements, we
observe that the basins of attractors, corresponding to patterns that have been
embedded using a learning rule, occupy maximum volume in phase space at an
optimal modularity. Simultaneously, the convergence time to these attractors
decreases as a result of cooperative dynamics between the modules. The role of
modularity in increasing global stability of certain desirable attractors of a
system may provide a clue to its evolution and ubiquity in natural systems.
</summary>
    <author>
      <name>Neeraj Pradhan</name>
    </author>
    <author>
      <name>Subinay Dasgupta</name>
    </author>
    <author>
      <name>Sitabhra Sinha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5853v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5853v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5913v1</id>
    <updated>2011-12-27T03:25:33Z</updated>
    <published>2011-12-27T03:25:33Z</published>
    <title>Dynamical aspects of Kinouchi-Copelli model: emergence of avalanches at
  criticality</title>
    <summary>  We analyze the behavior of bursts of neural activity in the Kinouchi-Copelli
model, originally conceived to explain information processing issues in sensory
systems. We show that, at a critical condition, power-law behavior emerges for
the size and duration of the bursts (avalanches), with exponents experimentally
observed in real biological systems.
</summary>
    <author>
      <name>T. S. Mosqueiro</name>
    </author>
    <author>
      <name>C. Akimushkin</name>
    </author>
    <author>
      <name>L. P. Maia</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5540/DINCON.2011.001.1.0064</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5540/DINCON.2011.001.1.0064" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted for Brazilian Conference on Dynamics, Control and
  Applications (oral presentation and poster). 4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.5913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5922v3</id>
    <updated>2013-03-07T01:56:51Z</updated>
    <published>2012-09-26T13:12:49Z</published>
    <title>Towards structured sharing of raw and derived neuroimaging data across
  existing resources</title>
    <summary>  Data sharing efforts increasingly contribute to the acceleration of
scientific discovery. Neuroimaging data is accumulating in distributed
domain-specific databases and there is currently no integrated access mechanism
nor an accepted format for the critically important meta-data that is necessary
for making use of the combined, available neuroimaging data. In this
manuscript, we present work from the Derived Data Working Group, an open-access
group sponsored by the Biomedical Informatics Research Network (BIRN) and the
International Neuroimaging Coordinating Facility (INCF) focused on practical
tools for distributed access to neuroimaging data. The working group develops
models and tools facilitating the structured interchange of neuroimaging
meta-data and is making progress towards a unified set of tools for such data
and meta-data exchange. We report on the key components required for integrated
access to raw and derived neuroimaging data as well as associated meta-data and
provenance across neuroimaging resources. The components include (1) a
structured terminology that provides semantic context to data, (2) a formal
data model for neuroimaging with robust tracking of data provenance, (3) a web
service-based application programming interface (API) that provides a
consistent mechanism to access and query the data model, and (4) a provenance
library that can be used for the extraction of provenance data by image
analysts and imaging software developers. We believe that the framework and set
of tools outlined in this manuscript have great potential for solving many of
the issues the neuroimaging community faces when sharing raw and derived
neuroimaging data across the various existing database systems for the purpose
of accelerating scientific discovery.
</summary>
    <author>
      <name>D. B. Keator</name>
    </author>
    <author>
      <name>K. Helmer</name>
    </author>
    <author>
      <name>J. Steffener</name>
    </author>
    <author>
      <name>J. A. Turner</name>
    </author>
    <author>
      <name>T. G. M. Van Erp</name>
    </author>
    <author>
      <name>S. Gadde</name>
    </author>
    <author>
      <name>N. Ashish</name>
    </author>
    <author>
      <name>G. A. Burns</name>
    </author>
    <author>
      <name>B. N. Nichols</name>
    </author>
    <author>
      <name>S. S. Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/1209.5922v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5922v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0863v1</id>
    <updated>2011-06-04T22:29:34Z</updated>
    <published>2011-06-04T22:29:34Z</published>
    <title>The A-current and Type I / Type II transition determine collective
  spiking from common input</title>
    <summary>  The mechanisms and impact of correlated, or synchronous, firing among pairs
and groups of neurons is under intense investigation throughout the nervous
system. A ubiquitous circuit feature that can give rise to such correlations
consists of overlapping, or common, inputs to pairs and populations of cells,
leading to common spike train responses. Here, we use computational tools to
study how the transfer of common input currents into common spike outputs is
modulated by the physiology of the recipient cells. We focus on a key
conductance - gA, for the A-type potassium current - which drives neurons
between "Type II" excitability (low gA), and "Type I" excitability (high gA).
Regardless of gA, cells transform common input fluctuations into a ten- dency
to spike nearly simultaneously. However, this process is more pronounced at low
gA values, as previously predicted by reduced "phase" models. Thus, for a given
level of common input, Type II neurons produce spikes that are relatively more
correlated over short time scales. Over long time scales, the trend reverses,
with Type II neurons producing relatively less correlated spike trains. This is
because these cells' increased tendency for simultaneous spiking is balanced by
opposing tendencies at larger time lags. We demonstrate a novel implication for
neural signal processing: downstream cells with long time constants are
selectively driven by Type I cell populations upstream, and those with short
time constants by Type II cell populations. Our results are established via
high-throughput numerical simulations, and explained via the cells' filtering
properties and nonlinear dynamics.
</summary>
    <author>
      <name>Andrea K. Barreiro</name>
    </author>
    <author>
      <name>Evan L. Thilo</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 10 figures v1: Submitted June 4, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.0863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0249v3</id>
    <updated>2013-01-21T15:27:58Z</updated>
    <published>2012-11-01T18:37:08Z</published>
    <title>Finite element analysis of neuronal electric fields: the effect of
  heterogeneous resistivity</title>
    <summary>  Simulation of extracellular fields is one of the substantial methods used in
the area of computational neuroscience. Its most common usage is validation of
experimental methods as EEG and extracellular spike recordings or modeling of
physiological phenomena which can not be easily determined empirically.
Continuous experimental work has been re-raising the importance of polarization
effects between neuronal structures to neuronal communication. As this effects
relies on very small potential changes, better modeling methods are necessary
to quantify the weak electrical fields in the microscopic scale in a more
realistic way. An important factor of influence on local field effects in the
hippocampal formation is the heterogeneous resistivity of extracellular tissue.
The vast majority of modeling studies consider the extracellular space to be
homogeneous while experimentally, it has been shown that the stratum pyramidale
has two times higher resistivity then other hippocampal layers. Common
simulation methods for extracellular electrical fields based on the point
source approximation are bound to describe the resistance of the space with a
single, linear factor. We propose that models should be based on the space- and
time-dependent Maxwell equations in order to account for heterogeneous
properties of the extracellular space and specific arrangements of neurons in
dense hippocampal layers. To demonstrate the influence of heterogeneous
extracellular resistivity and neuronal spatial orientation on modeling results,
we combine solutions of classical compartment models with spatiotemporal PDEs
solved by the FEM. With the help of these methods, we show that the inclusion
of heterogeneous resistivity has a substantial impact on voltages in close
proximity to emitting neurons, increasing the extracellular potentials
substantially compared to the homogeneous variant.
</summary>
    <author>
      <name>Pavol Bauer</name>
    </author>
    <author>
      <name>Sanja Mikulovic</name>
    </author>
    <author>
      <name>Stefan Engblom</name>
    </author>
    <author>
      <name>Katarina E. Leão</name>
    </author>
    <author>
      <name>Frank Rattay</name>
    </author>
    <author>
      <name>Richardson N. Leão</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0249v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0249v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.0033v2</id>
    <updated>2012-10-08T16:32:07Z</updated>
    <published>2012-06-29T23:28:21Z</published>
    <title>Quantum-like model of behavioral response computation using neural
  oscillators</title>
    <summary>  In this paper we propose the use of neural interference as the origin of
quantum-like effects in the brain. We do so by using a neural oscillator model
consistent with neurophysiological data. The model used was shown to reproduce
well the predictions of behavioral stimulus-response theory. The quantum-like
effects are obtained by the spreading activation of incompatible oscillators,
leading to an interference-like effect mediated by inhibitory and excitatory
synapses.
</summary>
    <author>
      <name>José Acacio de Barros</name>
    </author>
    <link href="http://arxiv.org/abs/1207.0033v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.0033v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2081v3</id>
    <updated>2015-04-29T19:20:42Z</updated>
    <published>2012-06-11T02:15:22Z</published>
    <title>Robust exponential binary pattern storage in Little-Hopfield networks</title>
    <summary>  The Little-Hopfield network is an auto-associative computational model of
neural memory storage and retrieval. This model is known to robustly store
collections of randomly generated binary patterns as stable-states of the
network dynamics. However, the number of binary memories so storable scales
linearly in the number of neurons, and it has been a long-standing open problem
whether robust exponential storage of binary patterns was possible in such a
network memory model. In this note, we design simple families of
Little-Hopfield networks that provably solve this problem affirmatively. As a
byproduct, we produce a set of novel (nonlinear) binary codes with an
efficient, highly parallelizable denoising mechanism.
</summary>
    <author>
      <name>Christopher Hillar</name>
    </author>
    <author>
      <name>Ngoc Tran</name>
    </author>
    <author>
      <name>Kilian Koepsell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authors. preliminary early draft
  unsuitable for viewing and attribution, instead, see: arXiv:1411.4625</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.2081v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2081v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3683v1</id>
    <updated>2012-04-17T01:46:27Z</updated>
    <published>2012-04-17T01:46:27Z</published>
    <title>Strong surround antagonism in the dLGN of the awake rat</title>
    <summary>  Classical center-surround antagonism in the early visual system is thought to
serve important functions such as enhancing edge detection and increasing
sparseness. The relative strength of the center and surround determine the
specific computation achieved. For example, weak surrounds achieve low-pass
spatial frequency filtering and are optimal for denoising when signal-to-noise
ratio (SNR) is low. Balanced surrounds achieve band-pass spatial frequency
filtering and are optimal for decorrelation of responses when SNR is high.
Surround strength has been measured in the retina and dorsal Lateral Geniculate
Nucleus (dLGN), primarily in anesthetized or ex vivo preparations. Here we
revisit the center-surround architecture of dLGN neurons in the un-anesthetized
rat. We report the spatial frequency tuning responses of N=47 neurons. We fit
these tuning curves to a difference-of-Gaussians (DOG) model of the spatial
receptive field. We find that some dLGN neurons in the awake rat (N=8/47) have
weak surrounds. The majority of cells in our sample (N=29/47), however, have
well-balanced center and surround strengths and band-pass tuning curves. We
also observed several neurons (N=10/47) with notched or dual-band-pass tuning
curves, a response class that has not been described previously. Within the
space of circularly concentric DOG models, strong surrounds were necessary and
sufficient to explain the dual-band-pass spatial frequency tuning of these
cells. It remains to be determined what advantage if any is conferred by this
novel response class, or by the heterogeneity of surround strength as such. We
conclude that surround antagonism can be strong in the dLGN of the awake rat.
</summary>
    <author>
      <name>Balaji Sriram</name>
    </author>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.3683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5029v1</id>
    <updated>2012-09-23T01:17:02Z</updated>
    <published>2012-09-23T01:17:02Z</published>
    <title>Sparse Codes for Speech Predict Spectrotemporal Receptive Fields in the
  Inferior Colliculus</title>
    <summary>  We have developed a sparse mathematical representation of speech that
minimizes the number of active model neurons needed to represent typical speech
sounds. The model learns several well-known acoustic features of speech such as
harmonic stacks, formants, onsets and terminations, but we also find more
exotic structures in the spectrogram representation of sound such as localized
checkerboard patterns and frequency-modulated excitatory subregions flanked by
suppressive sidebands. Moreover, several of these novel features resemble
neuronal receptive fields reported in the Inferior Colliculus (IC), as well as
auditory thalamus and cortex, and our model neurons exhibit the same tradeoff
in spectrotemporal resolution as has been observed in IC. To our knowledge,
this is the first demonstration that receptive fields of neurons in the
ascending mammalian auditory pathway beyond the auditory nerve can be predicted
based on coding principles and the statistical properties of recorded sounds.
</summary>
    <author>
      <name>Nicole L. Carlson</name>
    </author>
    <author>
      <name>Vivienne L. Ming</name>
    </author>
    <author>
      <name>Michael R. DeWeese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002594</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002594" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For Supporting Information, see PLoS website:
  http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1002594</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput Biol 8(7): e1002594 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6451v1</id>
    <updated>2012-08-31T10:36:23Z</updated>
    <published>2012-08-31T10:36:23Z</published>
    <title>Can brains generate random numbers?</title>
    <summary>  Motivated by EEG recordings of normal brain activity, we construct
arbitrarily large McCulloch-Pitts neural networks that, without any external
input, make every subset of their neurons fire in some iteration (and therefore
in infinitely many iterations).
</summary>
    <author>
      <name>Vašek Chvátal</name>
    </author>
    <author>
      <name>Mark Goldsmith</name>
    </author>
    <link href="http://arxiv.org/abs/1208.6451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20, 65C10, 37B15, 62P10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0119v2</id>
    <updated>2012-04-27T17:34:37Z</updated>
    <published>2012-03-31T17:46:07Z</published>
    <title>Signal integration enhances the dynamic range in neuronal systems</title>
    <summary>  The dynamic range measures the capacity of a system to discriminate the
intensity of an external stimulus. Such an ability is fundamental for living
beings to survive: to leverage resources and to avoid danger. Consequently, the
larger is the dynamic range, the greater is the probability of survival. We
investigate how the integration of different input signals affects the dynamic
range, and in general the collective behavior of a network of excitable units.
By means of numerical simulations and a mean-field approach, we explore the
nonequilibrium phase transition in the presence of integration. We show that
the firing rate in random and scale-free networks undergoes a discontinuous
phase transition depending on both the integration time and the density of
integrator units. Moreover, in the presence of external stimuli, we find that a
system of excitable integrator units operating in a bistable regime largely
enhances its dynamic range.
</summary>
    <author>
      <name>Leonardo L. Gollo</name>
    </author>
    <author>
      <name>Claudio Mirasso</name>
    </author>
    <author>
      <name>Víctor M. Eguíluz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.85.040902</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.85.040902" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E, 85, 040902 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.0119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3616v3</id>
    <updated>2013-08-08T08:35:56Z</updated>
    <published>2012-11-15T14:31:07Z</published>
    <title>Nonlinear dynamics of human locomotion: effects of rhythmic auditory
  cueing on local dynamic stability</title>
    <summary>  Synchronizing steps with an external auditory stimulus (rhythmic auditory
cueing (RAC) enhances gait recovery in neurological disorders. The activation
of specific sensory-motor processes, which may partially replace impaired
neural pathways, is likely the cause of the observed benefits. Nonlinear
indexes, such as scaling exponents and Lyapunov exponents, have been proposed
to characterize RAC effects. The maximal Lyapunov exponent estimates the degree
of resilience of gait control to small perturbations, i.e. the local dynamic
stability (LDS). The objective of the present study was to assess to what
extent RAC influences gait LDS, and to compare this effect with that on scaling
exponents. Twenty healthy subjects performed 6x5min walking trials on an
instrumented treadmill at three different speeds. Freely chosen walking
cadences were measured during the first three trials and then imposed
accordingly in the last three trials with a metronome. The 2D trajectory of the
center of pressure on the treadmill was recorded. From the antero-posterior and
the medio-lateral signals, both long-term and short-term LDS were computed.
Long-term LDS was strongly enhanced (relative change +47%), with significant
change in every direction and speed. The average change in short-term LDS was
smaller (+3%), with a more marked effect at low speed (+5%). RAC substantially
modified the fluctuation dynamics of the center of the pressure trajectory. We
also observed that both LDS and fractal dynamics (scaling exponents) responded
similarly to RAC. Thus, both scaling exponents and LDS are responsive to
sensory-motor synchronizing processes that RAC activates, and may constitute
relevant indexes for evaluating gait variability in cued walking. Finally, the
more locally stable gait pattern could be an indication of a lower fall risk,
which may be an advantage to patients of RAC therapies.
</summary>
    <author>
      <name>Philippe Terrier</name>
    </author>
    <author>
      <name>Olivier Deriaz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fphys.2013.00230</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fphys.2013.00230" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an outdated version of an article subsequently published in
  Frontiers in Physiology. Please refer to the final version (open access)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Physiol. 2013 4:230</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.3616v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3616v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6176v1</id>
    <updated>2012-04-27T11:51:56Z</updated>
    <published>2012-04-27T11:51:56Z</published>
    <title>The balance between excitation and inhibition controls the temporal
  organization of neuronal avalanches</title>
    <summary>  Neuronal avalanches, measured in vitro and in vivo, exhibit a robust critical
behaviour. Their temporal organization hides the presence of correlations. Here
we present experimental measurements of the waiting time distribution between
successive avalanches in the rat cortex in vitro. This exhibits a non-monotonic
behaviour, not usually found in other natural processes. Numerical simulations
provide evidence that this behaviour is a consequence of the alternation
between states of high and low activity, named up and down states, leading to a
balance between excitation and inhibition controlled by a single parameter.
During these periods both the single neuron state and the network excitability
level, keeping memory of past activity, are tuned by homeostatic mechanisms.
</summary>
    <author>
      <name>F. Lombardi</name>
    </author>
    <author>
      <name>H. J. Herrmann</name>
    </author>
    <author>
      <name>C. Perrone-Capano</name>
    </author>
    <author>
      <name>D. Plenz</name>
    </author>
    <author>
      <name>L. de Arcangelis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, to appear on Physical Review Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.6176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.1513v4</id>
    <updated>2015-03-12T05:04:30Z</updated>
    <published>2012-08-07T20:22:31Z</published>
    <title>Dynamics on Networks of Manifolds</title>
    <summary>  We propose a precise definition of a continuous time dynamical system made up
of interacting open subsystems. The interconnections of subsystems are coded by
directed graphs. We prove that the appropriate maps of graphs called graph
fibrations give rise to maps of dynamical systems. Consequently surjective
graph fibrations give rise to invariant subsystems and injective graph
fibrations give rise to projections of dynamical systems.
</summary>
    <author>
      <name>Lee DeVille</name>
    </author>
    <author>
      <name>Eugene Lerman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3842/SIGMA.2015.022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3842/SIGMA.2015.022" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIGMA 11 (2015), 022, 21 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.1513v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.1513v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3211v1</id>
    <updated>2012-07-13T11:59:57Z</updated>
    <published>2012-07-13T11:59:57Z</published>
    <title>Exploring Neuronal Bistability at the Depolarization Block</title>
    <summary>  Many neurons display bistability - coexistence of two firing modes such as
bursting and tonic spiking or tonic spiking and silence. Bistability has been
proposed to endow neurons with richer forms of information processing in
general and to be involved in short-term memory in particular by allowing a
brief signal to elicit long-lasting changes in firing. In this paper, we focus
on bistability that allows for a choice between tonic spiking and
depolarization block in a wide range of the depolarization levels. We consider
the spike-producing currents in two neurons, models of which differ by the
parameter values. Our dopaminergic neuron model displays bistability in a wide
range of applied currents at the depolarization block. The Hodgkin-Huxley model
of the squid giant axon shows no bistability. We varied parameter values for
the model to analyze transitions between the two parameter sets. We show that
bistability primarily characterizes the inactivation of the Na+ current. Our
study suggests a connection between the amount of the Na+ window current and
the length of the bistability range. For the dopaminergic neuron we hypothesize
that bistability can be linked to a prolonged action of antipsychotic drugs.
</summary>
    <author>
      <name>A. Dovzhenok</name>
    </author>
    <author>
      <name>A. S. Kuznetsov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0042811</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0042811" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 8 figures, accepted to PLoS ONE</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(2012) PLoS ONE 7(8): e42811</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.3211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.7098v1</id>
    <updated>2011-11-30T09:44:48Z</updated>
    <published>2011-11-30T09:44:48Z</published>
    <title>Efficient methods for sampling spike trains in networks of coupled
  neurons</title>
    <summary>  Monte Carlo approaches have recently been proposed to quantify connectivity
in neuronal networks. The key problem is to sample from the conditional
distribution of a single neuronal spike train, given the activity of the other
neurons in the network. Dependencies between neurons are usually relatively
weak; however, temporal dependencies within the spike train of a single neuron
are typically strong. In this paper we develop several specialized
Metropolis--Hastings samplers which take advantage of this dependency
structure. These samplers are based on two ideas: (1) an adaptation of fast
forward--backward algorithms from the theory of hidden Markov models to take
advantage of the local dependencies inherent in spike trains, and (2) a
first-order expansion of the conditional likelihood which allows for efficient
exact sampling in the limit of weak coupling between neurons. We also
demonstrate that these samplers can effectively incorporate side information,
in particular, noisy fluorescence observations in the context of
calcium-sensitive imaging experiments. We quantify the efficiency of these
samplers in a variety of simulated experiments in which the network parameters
are closely matched to data measured in real cortical networks, and also
demonstrate the sampler applied to real calcium imaging data.
</summary>
    <author>
      <name>Yuriy Mishchenko</name>
    </author>
    <author>
      <name>Liam Paninski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/11-AOAS467</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/11-AOAS467" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/11-AOAS467 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Statistics 2011, Vol. 5, No. 3, 1893-1919</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.7098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.7098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2717v1</id>
    <updated>2011-04-14T10:41:28Z</updated>
    <published>2011-04-14T10:41:28Z</published>
    <title>Estimating the number of neurons in multi-neuronal spike trains</title>
    <summary>  A common way of studying the relationship between neural activity and
behavior is through the analysis of neuronal spike trains that are recorded
using one or more electrodes implanted in the brain. Each spike train typically
contains spikes generated by multiple neurons. A natural question that arises
is "what is the number of neurons $\nu$ generating the spike train?"; This
article proposes a method-of-moments technique for estimating $\nu$. This
technique estimates the noise nonparametrically using data from the silent
region of the spike train and it applies to isolated spikes with a possibly
small, but nonnegligible, presence of overlapping spikes. Conditions are
established in which the resulting estimator for $\nu$ is shown to be strongly
consistent. To gauge its finite sample performance, the technique is applied to
simulated spike trains as well as to actual neuronal spike train data.
</summary>
    <author>
      <name>Mengxin Li</name>
    </author>
    <author>
      <name>Wei-Liem Loh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/10-AOAS371</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/10-AOAS371" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/10-AOAS371 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Statistics 2011, Vol. 5, No. 1, 176-200</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.2717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0121v1</id>
    <updated>2012-09-01T18:43:44Z</updated>
    <published>2012-09-01T18:43:44Z</published>
    <title>Learning quadratic receptive fields from neural responses to natural
  stimuli</title>
    <summary>  Models of neural responses to stimuli with complex spatiotemporal correlation
structure often assume that neurons are only selective for a small number of
linear projections of a potentially high-dimensional input. Here we explore
recent modeling approaches where the neural response depends on the quadratic
form of the input rather than on its linear projection, that is, the neuron is
sensitive to the local covariance structure of the signal preceding the spike.
To infer this quadratic dependence in the presence of arbitrary (e.g.
naturalistic) stimulus distribution, we review several inference methods,
focussing in particular on two information-theory-based approaches
(maximization of stimulus energy or of noise entropy) and a likelihood-based
approach (Bayesian spike-triggered covariance, extensions of generalized linear
models). We analyze the formal connection between the likelihood-based and
information-based approaches to show how they lead to consistent inference. We
demonstrate the practical feasibility of these procedures by using model
neurons responding to a flickering variance stimulus.
</summary>
    <author>
      <name>Kanaka Rajan</name>
    </author>
    <author>
      <name>Olivier Marre</name>
    </author>
    <author>
      <name>Gašper Tkačik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jphysparis.2012.12.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jphysparis.2012.12.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Review, 17 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Comput 25 (2013): 1661-1692</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.0121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2352v12</id>
    <updated>2013-11-23T21:52:27Z</updated>
    <published>2011-05-12T01:32:56Z</published>
    <title>Electroencephalographic field influence on calcium momentum waves</title>
    <summary>  Macroscopic EEG fields can be an explicit top-down neocortical mechanism that
directly drives bottom-up processes that describe memory, attention, and other
neuronal processes. The top-down mechanism considered are macrocolumnar EEG
firings in neocortex, as described by a statistical mechanics of neocortical
interactions (SMNI), developed as a magnetic vector potential $\mathbf{A}$. The
bottom-up process considered are $\mathrm{Ca}^{2+}$ waves prominent in synaptic
and extracellular processes that are considered to greatly influence neuronal
firings. Here, the complimentary effects are considered, i.e., the influence of
$\mathbf{A}$ on $\mathrm{Ca}^{2+}$ momentum, $\mathbf{p}$. The canonical
momentum of a charged particle in an electromagnetic field, $\mathbf{\Pi} =
\mathbf{p} + q \mathbf{A}$ (SI units), is calculated, where the charge of
$\mathrm{Ca}^{2+}$ is $q = - 2 e$, $e$ is the magnitude of the charge of an
electron. Calculations demonstrate that macroscopic EEG $\mathbf{A}$ can be
quite influential on the momentum $\mathbf{p}$ of $\mathrm{Ca}^{2+}$ ions, in
both classical and quantum mechanics. Molecular scales of $\mathrm{Ca}^{2+}$
wave dynamics are coupled with $\mathbf{A}$ fields developed at macroscopic
regional scales measured by coherent neuronal firing activity measured by scalp
EEG. The project has three main aspects: fitting $\mathbf{A}$ models to EEG
data as reported here, building tripartite models to develop $\mathbf{A}$
models, and studying long coherence times of $\mathrm{Ca}^{2+}$ waves in the
presence of $\mathbf{A}$ due to coherent neuronal firings measured by scalp
EEG. The SMNI model supports a mechanism wherein the $\mathbf{p} + q
\mathbf{A}$ interaction at tripartite synapses, via a dynamic centering
mechanism (DCM) to control background synaptic activity, acts to maintain
short-term memory (STM) during states of selective attention.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <author>
      <name>Marco Pappalepore</name>
    </author>
    <author>
      <name>Ronald R. Stesiak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jtbi.2013.11.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jtbi.2013.11.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final draft. http://ingber.com/smni14_eeg_ca.pdf may be updated more
  frequently</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.2352v12" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2352v12" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5673v1</id>
    <updated>2012-07-17T22:01:58Z</updated>
    <published>2012-07-17T22:01:58Z</published>
    <title>The dynamics of H-bonds of the hydration shells of ions, ATPase and
  NE-activated adenylyl cyclase on the coupling of energy and signal
  transduction</title>
    <summary>  Glycerol titration distinguished from free water the local hydration shell
involved in ATPase transition from active to inactive, with cooperativity for
water n=16. Rat brain cortex: NE-stimulated and its basal AC in the absence of
free Mg2+, allows a refractive state of AC with negative cooperativity for
MgATP and ATP4-. The erythrocyte-Hb system operates as a metabolic sensor to
match glucose availability with the release of Hb-carried, O2 and Mg2+ at CSF.
[Mg(H2O)6](H2O)122+ by chelating either a protein or ATP4- losses most of its
hydration shell. The ion pump ATPase by forming ADP3- releases an incompletely
hydrated Mg2+, which could capture H2O from either [Na.(H2O)6]+ or [K.(H2O)6]+.
Thus, sieve-sizing their hydration shells for fitting into Na+-pump channels.
An AC refractory period may participate in STM. Mg2+ with cooperativity n=3.7
activates NE-AC. CREB-generated receptors coupled by Mg2+ may modulate
hydration shells-dependent oscillations for retrieval of LTM
</summary>
    <author>
      <name>Alfred Bennun</name>
    </author>
    <link href="http://arxiv.org/abs/1208.5673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0158v2</id>
    <updated>2011-09-22T07:09:58Z</updated>
    <published>2011-05-01T10:10:44Z</published>
    <title>Detecting emergent processes in cellular automata with excess
  information</title>
    <summary>  Many natural processes occur over characteristic spatial and temporal scales.
This paper presents tools for (i) flexibly and scalably coarse-graining
cellular automata and (ii) identifying which coarse-grainings express an
automaton's dynamics well, and which express its dynamics badly. We apply the
tools to investigate a range of examples in Conway's Game of Life and Hopfield
networks and demonstrate that they capture some basic intuitions about emergent
processes. Finally, we formalize the notion that a process is emergent if it is
better expressed at a coarser granularity.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5306v1</id>
    <updated>2012-09-24T15:41:48Z</updated>
    <published>2012-09-24T15:41:48Z</published>
    <title>A Model of Decision-Making in Groups of Humans</title>
    <summary>  Decisions by humans depend on their estimations given some uncertain sensory
data. These decisions can also be influenced by the behavior of others. Here we
present a mathematical model to quantify this influence, inviting a further
study on the cognitive consequences of social information. We also expect that
the present model can be used for a better understanding of the neural circuits
implicated in social processing.
</summary>
    <author>
      <name>Gabriel Madirolas</name>
    </author>
    <author>
      <name>Alfonso Perez-Escudero</name>
    </author>
    <author>
      <name>Gonzalo G. de Polavieja</name>
    </author>
    <link href="http://arxiv.org/abs/1209.5306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1096v1</id>
    <updated>2012-12-05T17:00:52Z</updated>
    <published>2012-12-05T17:00:52Z</published>
    <title>Computational modeling of spike generation in serotonergic neurons of
  the dorsal raphe nucleu</title>
    <summary>  We consider here a single-compartment model of these neurons which is capable
of describing many of the known features of spike generation, particularly the
slow rhythmic pacemaking activity often observed in these cells in a variety of
species. Included in the model are ten kinds of voltage dependent ion channels
as well as calcium-dependent potassium current. Calcium dynamics includes
buffering and pumping. In sections 3-9, each component is considered in detail
and parameters estimated from voltage clamp data where possible. In the next
two sections simplified versions of some components are employed to explore the
effects of various parameters on spiking, using a systematic approach, ending
up with the following eleven components: a fast sodium current $I_{Na}$, a
delayed rectifier potassium current $I_{KDR}$, a transient potassium current
$I_A$, a low-threshold calcium current $I_T$, two high threshold calcium
currents $I_L$ and $I_N$, small and large conductance potassium currents
$I_{SK}$ and $I_{BK}$, a hyperpolarization-activated cation current $I_H$, a
leak current $I_{Leak}$ and intracellular calcium ion concentration $Ca_i$.
Attention is focused on the properties usually associated with these neurons,
particularly long duration of action potential, pacemaker-like spiking and the
ramp-like return to threshold after a spike. In some cases the membrane
potential trajectories display doublets or have kinks or notches as have been
reported in some experimental studies. The computed time courses of $I_A$ and
$I_T$ during the interspike interval support the generally held view of a
competition between them in influencing the frequency of spiking. Spontaneous
spiking could be obtained with small changes in a few parameters from their
values with driven spiking.
</summary>
    <author>
      <name>Henry C. Tuckwell</name>
    </author>
    <author>
      <name>Nicholas J. Penington</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The abstract has been truncated</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.1096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4358v2</id>
    <updated>2013-04-12T22:39:50Z</updated>
    <published>2012-06-19T23:04:21Z</published>
    <title>Robust Detection of Dynamic Community Structure in Networks</title>
    <summary>  We describe techniques for the robust detection of community structure in
some classes of time-dependent networks. Specifically, we consider the use of
statistical null models for facilitating the principled identification of
structural modules in semi-decomposable systems. Null models play an important
role both in the optimization of quality functions such as modularity and in
the subsequent assessment of the statistical validity of identified community
structure. We examine the sensitivity of such methods to model parameters and
show how comparisons to null models can help identify system scales. By
considering a large number of optimizations, we quantify the variance of
network diagnostics over optimizations (`optimization variance') and over
randomizations of network structure (`randomization variance'). Because the
modularity quality function typically has a large number of nearly-degenerate
local optima for networks constructed using real data, we develop a method to
construct representative partitions that uses a null model to correct for
statistical noise in sets of partitions. To illustrate our results, we employ
ensembles of time-dependent networks extracted from both nonlinear oscillators
and empirical neuroscience data.
</summary>
    <author>
      <name>Danielle S. Bassett</name>
    </author>
    <author>
      <name>Mason A. Porter</name>
    </author>
    <author>
      <name>Nicholas F. Wymbs</name>
    </author>
    <author>
      <name>Scott T. Grafton</name>
    </author>
    <author>
      <name>Jean M. Carlson</name>
    </author>
    <author>
      <name>Peter J. Mucha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4790830</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4790830" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos, 2013, 23, 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4358v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4358v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1217v1</id>
    <updated>2011-05-06T02:56:45Z</updated>
    <published>2011-05-06T02:56:45Z</published>
    <title>Marker Genes for Anatomical Regions in the Brain: Insights from the
  Allen Gene Expression Atlas</title>
    <summary>  Quantitative criteria are proposed to identify genes (and sets of genes)
whose expression marks a specific brain region (or a set of brain regions).
Gene-expression energies, obtained for thousands of mouse genes by numerization
of in-situ hybridization images in the Allen Gene Expression Atlas, are used to
test these methods in the mouse brain. Individual genes are ranked using
integrals of their expression energies across brain regions. The ranking is
generalized to sets of genes and the problem of optimal markers of a classical
region receives a linear-algebraic solution. Moreover, the goodness of the
fitting of the expression profile of a gene to the profile of a brain region is
closely related to the co-expression of genes. The geometric interpretation of
this fact leads to a quantitative criterion to detect markers of pairs of brain
regions. Local properties of the gene-expression profiles are also used to
detect genes that separate a given grain region from its environment.
</summary>
    <author>
      <name>Pascal Grange</name>
    </author>
    <author>
      <name>Partha P. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, LaTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.1217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.2686v1</id>
    <updated>2011-01-13T22:29:53Z</updated>
    <published>2011-01-13T22:29:53Z</published>
    <title>Neural development features: Spatio-temporal development of the
  Caenorhabditis elegans neuronal network</title>
    <summary>  The nematode Caenorhabditis elegans, with information on neural connectivity,
three-dimensional position and cell linage provides a unique system for
understanding the development of neural networks. Although C. elegans has been
widely studied in the past, we present the first statistical study from a
developmental perspective, with findings that raise interesting suggestions on
the establishment of long-distance connections and network hubs. Here, we
analyze the neuro-development for temporal and spatial features, using birth
times of neurons and their three-dimensional positions. Comparisons of growth
in C. elegans with random spatial network growth highlight two findings
relevant to neural network development. First, most neurons which are linked by
long-distance connections are born around the same time and early on,
suggesting the possibility of early contact or interaction between connected
neurons during development. Second, early-born neurons are more highly
connected (tendency to form hubs) than later born neurons. This indicates that
the longer time frame available to them might underlie high connectivity. Both
outcomes are not observed for random connection formation. The study finds that
around one-third of electrically coupled long-range connections are late
forming, raising the question of what mechanisms are involved in ensuring their
accuracy, particularly in light of the extremely invariant connectivity
observed in C. elegans. In conclusion, the sequence of neural network
development highlights the possibility of early contact or interaction in
securing long-distance and high-degree connectivity.
</summary>
    <author>
      <name>Sreedevi Varier</name>
    </author>
    <author>
      <name>Marcus Kaiser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1001044</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1001044" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Varier S, Kaiser M (2011) Neural Development Features:
  Spatio-Temporal Development of the Caenorhabditis elegans Neuronal Network.
  PLoS Comput Biol 7(1): e1001044</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.2686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.2686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2458v2</id>
    <updated>2014-04-28T18:27:01Z</updated>
    <published>2012-01-12T01:05:15Z</published>
    <title>Stochastic modeling of a serial killer</title>
    <summary>  We analyze the time pattern of the activity of a serial killer, who during
twelve years had murdered 53 people. The plot of the cumulative number of
murders as a function of time is of "Devil's staircase" type. The distribution
of the intervals between murders (step length) follows a power law with the
exponent of 1.4. We propose a model according to which the serial killer
commits murders when neuronal excitation in his brain exceeds certain
threshold. We model this neural activity as a branching process, which in turn
is approximated by a random walk. As the distribution of the random walk return
times is a power law with the exponent 1.5, the distribution of the
inter-murder intervals is thus explained. We illustrate analytical results by
numerical simulation. Time pattern activity data from two other serial killers
further substantiate our analysis.
</summary>
    <author>
      <name>M. V. Simkin</name>
    </author>
    <author>
      <name>V. P. Roychowdhury</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Theoretical Biology (2014) 355: 111-116</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.2458v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2458v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3014v2</id>
    <updated>2011-09-15T08:52:56Z</updated>
    <published>2011-09-14T08:27:46Z</published>
    <title>Relaxation and self-sustained oscillations in the time elapsed neuron
  network model</title>
    <summary>  The time elapsed model describes the firing activity of an homogeneous
assembly of neurons thanks to the distribution of times elapsed since the last
discharge. It gives a mathematical description of the probability density of
neurons structured by this time. In an earlier work, based on generalized
relative entropy methods, it is proved that for highly or weakly connected
networks the model exhibits relaxation to the steady state and for moderately
connected networks it is obtained numerical evidence of appearance of
self-sustained periodic solutions.
  Here, we go further and, using the particular form of the model, we quantify
the regime where relaxation to a stationary state occurs in terms of the
network connectivity. To introduce our methodology, we first consider the case
where the neurons are not connected and we give a new statement showing that
total asynchronous firing of neurons appears asymptotically. In a second step,
we consider the case with connections and give a low connectivity condition
that still leads to asynchronous firing. Our low connectivity condition is
somehow sharp because we can give an example, when this condition is not
fulfilled, where synchronous rhythmic activity occurs. Indeed, we are able to
build several explicit families of periodic solutions. Our construction is
fully nonlinear and the resynchronization of the neural activity in the network
does not follow from bifurcation analysis. It relies on an algebraically
nonlinear boundary condition that occurs in the model.These analytic results
are compared with numerical simulations under broader hypotheses and shown to
be robust.
</summary>
    <author>
      <name>Khashayar Pakdaman</name>
    </author>
    <author>
      <name>Benoît Perthame</name>
    </author>
    <author>
      <name>Delphine Salort</name>
    </author>
    <link href="http://arxiv.org/abs/1109.3014v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3014v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1503v1</id>
    <updated>2011-04-08T07:31:18Z</updated>
    <published>2011-04-08T07:31:18Z</published>
    <title>Short-term memory effects of an auditory biofeedback on isometric force
  control: Is there a differential effect as a function of transition trials?</title>
    <summary>  The aim of the present study was to investigate memory effects, force
accuracy, and variability during constant isometric force at different force
levels, using auditory biofeedback. Two types of transition trials were used: a
biofeedback-no biofeedback transition trial and a no biofeedback-biofeedback
transition trial. The auditory biofeedback produced a low- or high-pitched
sound when participants produced an isometric force lower or higher than
required, respectively. To achieve this goal, 16 participants were asked to
produce and maintain two different isometric forces (30$\pm$5% and 90N$\pm$5%)
during 25s. Constant error and standard deviation of the isometric force were
calculated. While accuracy and variability of the isometric force varied
according to the transition trial, a drift of the force appeared in the no
biofeedback condition. This result suggested that the degradation of
information about force output in the no biofeedback condition was provided by
a leaky memory buffer which was mainly dependent on the sense of effort.
Because this drift remained constant whatever the transition used, this memory
buffer seemed to be independent of short-term memory processes.
</summary>
    <author>
      <name>Rémy Cuisinier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TIMC</arxiv:affiliation>
    </author>
    <author>
      <name>Isabelle Olivier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TIMC</arxiv:affiliation>
    </author>
    <author>
      <name>Jocelyne Troccaz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TIMC</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Vuillerme</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AGIM</arxiv:affiliation>
    </author>
    <author>
      <name>Vincent Nougier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TIMC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.humov.2010.06.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.humov.2010.06.008" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Human Movement Science (2011) epub ahead of print</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6662v1</id>
    <updated>2012-11-28T17:09:14Z</updated>
    <published>2012-11-28T17:09:14Z</published>
    <title>Metabolic efficiency with fast spiking in the squid axon</title>
    <summary>  Fundamentally, action potentials in the squid axon are consequence of the
entrance of sodium ions during the depolarization of the rising phase of the
spike mediated by the outflow of potassium ions during the hyperpolarization of
the falling phase. Perfect metabolic efficiency with a minimum charge needed
for the change in voltage during the action potential would confine sodium
entry to the rising phase and potassium efflux to the falling phase. However,
because sodium channels remain open to a significant extent during the falling
phase, a certain overlap of inward and outward currents is observed. In this
work we investigate the impact of ion overlap on the number of the adenosine
triphosphate (ATP) molecules and energy cost required per action potential as a
function of the temperature in a Hodgkin-Huxley model. Based on a recent
approach to computing the energy cost of neuronal AP generation not based on
ion counting, we show that increased firing frequencies induced by higher
temperatures imply more efficient use of sodium entry, and then a decrease in
the metabolic energy cost required to restore the concentration gradients after
an action potential. Also, we determine values of sodium conductance at which
the hydrolysis efficiency presents a clear minimum.
</summary>
    <author>
      <name>Abdelmalik Moujahid</name>
    </author>
    <author>
      <name>Alicia D'Anjou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fncom.2012.00095</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fncom.2012.00095" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Comput. Neurosci. (2012) 6:95</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2521v3</id>
    <updated>2013-06-01T14:49:02Z</updated>
    <published>2011-07-13T10:59:42Z</published>
    <title>Network algorithmics and the emergence of synchronization in cortical
  models</title>
    <summary>  When brain signals are recorded in an electroencephalogram or some similar
large-scale record of brain activity, oscillatory patterns are typically
observed that are thought to reflect the aggregate electrical activity of the
underlying neuronal ensemble. Although it now seems that such patterns
participate in feedback loops both temporally with the neurons' spikes and
spatially with other brain regions, the mechanisms that might explain the
existence of such loops have remained essentially unknown. Here we present a
theoretical study of these issues on a cortical model we introduced earlier
[Nathan A, Barbosa VC (2010) Network algorithmics and the emergence of the
cortical synaptic-weight distribution. Phys Rev E 81: 021916]. We start with
the definition of two synchronization measures that aim to capture the
synchronization possibilities offered by the model regarding both the overall
spiking activity of the neurons and the spiking activity that causes the
immediate firing of the postsynaptic neurons. We present computational results
on our cortical model, on a model that is random in the Erd\H{o}s-R\'enyi
sense, and on a structurally deterministic model. We have found that the
algorithmic component underlying our cortical model ultimately provides,
through the two synchronization measures, a strong quantitative basis for the
emergence of both types of synchronization in all cases. This, in turn, may
explain the rise both of temporal feedback loops in the neurons' combined
electrical activity and of spatial feedback loops as brain regions that are
spatially separated engage in rhythmic behavior.
</summary>
    <author>
      <name>Andre Nathan</name>
    </author>
    <author>
      <name>Valmir C. Barbosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presentation improved</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2521v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2521v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3087v1</id>
    <updated>2012-02-14T17:01:20Z</updated>
    <published>2012-02-14T17:01:20Z</published>
    <title>Multistability, local pattern formation, and global collective firing in
  a small-world network of non-leaky integrate-and-fire neurons</title>
    <summary>  We investigate numerically the collective dynamical behavior of pulse-coupled
non-leaky integrate-and-fire-neurons that are arranged on a two-dimensional
small-world network. To ensure ongoing activity, we impose a probability for
spontaneous firing for each neuron. We study network dynamics evolving from
different sets of initial conditions in dependence on coupling strength and
rewiring probability. Beside a homogeneous equilibrium state for low coupling
strength, we observe different local patterns including cyclic waves, spiral
waves, and turbulent-like patterns, which -- depending on network parameters --
interfere with the global collective firing of the neurons. We attribute the
various network dynamics to distinct regimes in the parameter space. For the
same network parameters different network dynamics can be observed depending on
the set of initial conditions only. Such a multistable behavior and the
interplay between local pattern formation and global collective firing may be
attributable to the spatiotemporal dynamics of biological networks.
</summary>
    <author>
      <name>Alexander Rothkegel</name>
    </author>
    <author>
      <name>Klaus Lehnertz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3087432</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3087432" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 19, 015109 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.3087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4282v1</id>
    <updated>2012-05-18T23:54:35Z</updated>
    <published>2012-05-18T23:54:35Z</published>
    <title>The relationship between structure and function in complex networks
  observed locally</title>
    <summary>  The study of complex networks has drawn much attention over the last years,
mainly by virtue of its potential to characterize the most diverse systems
through unified mathematical and computational tools. Not long ago the emphasis
on this field mostly focused on the effects of the structural properties on the
global behavior of a dynamical process taking place in the system. Recently,
some studies started to unveil the richness of interactions that occur between
groups of nodes when we look at the small scale of interactions occurring in
the network. Such findings call for a new systematic methodology to quantify,
at node level, how a dynamics is being influenced (or differentiated) by the
structure of the underlying system. Here we present a first step towards this
direction, in which we define a new measurement that, based on dynamical
characteristics obtained for a large set of initial conditions, compares the
dynamical behavior of the nodes present in the system. Through this measurement
we find the high capacity of networks, generated by the geographic and
Barab\'asi-Albert models, to exhibit groups of nodes with distinct dynamics
compared to the rest of the network. We also present a practical application of
the methodology by using the neuronal network of the nematode
\emph{Caenorhabditis elegans}, where we show that the interneurons of the
ventral cord presents a very large dynamical differentiation when compared to
the rest of the network.
</summary>
    <author>
      <name>Cesar H. Comin</name>
    </author>
    <author>
      <name>João B. Bunoro</name>
    </author>
    <author>
      <name>Matheus P. Viana</name>
    </author>
    <author>
      <name>Luciano da F. Costa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5463v1</id>
    <updated>2011-12-22T21:12:09Z</updated>
    <published>2011-12-22T21:12:09Z</published>
    <title>Establishing, versus Maintaining, Brain Function: A Neuro-computational
  Model of Cortical Reorganization after Injury to the Immature Brain</title>
    <summary>  The effect of age at injury on outcome after acquired brain injury (ABI) has
been the subject of much debate. Many argue that young brains are relatively
tolerant of injury. A contrasting viewpoint due to Hebb argues that greater
system integrity may be required for the initial establishment of a function
than for preservation of an already-established function. A neuro-computational
model of cortical map formation was adapted to examine effects of focal and
distributed injury at various stages of development. This neural network model
requires a period of training during which it self-organizes to establish
cortical maps. Injuries were simulated by lesioning the model at various stages
of this process and network function was monitored as "development" progressed
to completion. Lesion effects are greater for larger, earlier, and distributed
(multifocal) lesions. The mature system is relatively robust, particularly to
focal injury. Activities in recovering systems injured at an early stage show
changes that emerge after an asymptomatic interval. Early injuries cause
qualitative changes in system behavior that emerge after a delay during which
the effects of the injury are latent. Functions that are incompletely
established at the time of injury may be vulnerable particularly to multifocal
injury.
</summary>
    <author>
      <name>Sreedevi Varier</name>
    </author>
    <author>
      <name>Marcus Kaiser</name>
    </author>
    <author>
      <name>Rob Forsyth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S1355617711000993</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S1355617711000993" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of the International Neuropsychological Society,
  17:1030-1038, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.5463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3622v2</id>
    <updated>2011-06-09T10:42:53Z</updated>
    <published>2011-01-19T05:45:14Z</published>
    <title>Searching and fixating: scale-invariance vs. characteristic timescales
  in attentional processes</title>
    <summary>  In an experiment involving semantic search, the visual movements of sample
populations subjected to visual and aural input were tracked in a taskless
paradigm. The probability distributions of saccades and fixations were obtained
and analyzed. Scale-invariance was observed in the saccadic distributions,
while the fixation distributions revealed the presence of a characteristic
(attentional) time scale for literate subjects. A detailed analysis of our
results suggests that saccadic eye motions are an example of Levy, rather than
Brownian, dynamics.
</summary>
    <author>
      <name>D. P. Shinde</name>
    </author>
    <author>
      <name>Anita Mehta</name>
    </author>
    <author>
      <name>R. K. Mishra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Europhysics Letters (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.3622v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3622v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2366v1</id>
    <updated>2011-03-07T23:51:22Z</updated>
    <published>2011-03-07T23:51:22Z</published>
    <title>Consciousness Viewed in the Framework of Brain Phase Space Dynamics,
  Criticality, and the Renormalization Group</title>
    <summary>  To set the stage for viewing Consciousness in terms of brain phase space
dynamics and criticality, I will first review currently prominent theoretical
conceptualizations and, where appropriate, identify ill-advised and flawed
notions in Theoretical Neuroscience that may impede viewing Consciousness as a
phenomenon in Physics. I will furthermore introduce relevant facts that tend
not to receive adequate attention in much of the current Consciousness
discourse. As a new approach to conceptualizing Consciousness, I propose
considering it as a collective achievement of the brain' s complex neural
dynamics that is amenable to study in the framework of state space dynamics and
criticality. In Physics, concepts of phase space transitions and the
Renormalization Group are powerful tools for interpreting phenomena involving
many scales of length and time in complex systems. The significance of these
concepts lies in their accounting for the emergence of different levels of new
collective behaviors in complex systems, each level with its distinct ontology,
organization and laws, as a new pattern of reality. The presumption of this
proposal is that the subjectivity of Consciousness is the epistemic
interpretation of a level of reality that originates in phase transitions of
the brain-body-environment system.
</summary>
    <author>
      <name>Gerhard Werner</name>
    </author>
    <link href="http://arxiv.org/abs/1103.2366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5507v5</id>
    <updated>2014-09-13T15:08:28Z</updated>
    <published>2011-12-23T02:56:26Z</published>
    <title>Fast Approximate Quadratic Programming for Large (Brain) Graph Matching</title>
    <summary>  Quadratic assignment problems (QAPs) arise in a wide variety of domains,
ranging from operations research to graph theory to computer vision to
neuroscience. In the age of big data, graph valued data is becoming more
prominent, and with it, a desire to run algorithms on ever larger graphs.
Because QAP is NP-hard, exact algorithms are intractable. Approximate
algorithms necessarily employ an accuracy/efficiency trade-off. We developed a
fast approximate quadratic assignment algorithm (FAQ). FAQ finds a local optima
in (worst case) time cubic in the number of vertices, similar to other
approximate QAP algorithms. We demonstrate empirically that our algorithm is
faster and achieves a lower objective value on over 80% of the suite of QAP
benchmarks, compared with the previous state-of-the-art. Applying the
algorithms to our motivating example, matching C. elegans connectomes
(brain-graphs), we find that FAQ achieves the optimal performance in record
time, whereas none of the others even find the optimum.
</summary>
    <author>
      <name>Joshua T. Vogelstein</name>
    </author>
    <author>
      <name>John M. Conroy</name>
    </author>
    <author>
      <name>Vince Lyzinski</name>
    </author>
    <author>
      <name>Louis J. Podrazik</name>
    </author>
    <author>
      <name>Steven G. Kratzer</name>
    </author>
    <author>
      <name>Eric T. Harley</name>
    </author>
    <author>
      <name>Donniell E. Fishkind</name>
    </author>
    <author>
      <name>R. Jacob Vogelstein</name>
    </author>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.5507v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5507v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5771v2</id>
    <updated>2013-08-06T17:27:01Z</updated>
    <published>2012-06-25T19:03:04Z</published>
    <title>The evolution of representation in simple cognitive networks</title>
    <summary>  Representations are internal models of the environment that can provide
guidance to a behaving agent, even in the absence of sensory information. It is
not clear how representations are developed and whether or not they are
necessary or even essential for intelligent behavior. We argue here that the
ability to represent relevant features of the environment is the expected
consequence of an adaptive process, give a formal definition of representation
based on information theory, and quantify it with a measure R. To measure how R
changes over time, we evolve two types of networks---an artificial neural
network and a network of hidden Markov gates---to solve a categorization task
using a genetic algorithm. We find that the capacity to represent increases
during evolutionary adaptation, and that agents form representations of their
environment during their lifetime. This ability allows the agents to act on
sensorial inputs in the context of their acquired representations and enables
complex and context-dependent behavior. We examine which concepts (features of
the environment) our networks are representing, how the representations are
logically encoded in the networks, and how they form as an agent behaves to
solve a task. We conclude that R should be able to quantify the representations
within any cognitive system, and should be predictive of an agent's long-term
adaptive success.
</summary>
    <author>
      <name>Lars Marstaller</name>
    </author>
    <author>
      <name>Arend Hintze</name>
    </author>
    <author>
      <name>Christoph Adami</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00475</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00475" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 10 figures, one Table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation 25 (2013) 2079-2107</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.5771v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5771v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4890v1</id>
    <updated>2012-09-21T19:40:01Z</updated>
    <published>2012-09-21T19:40:01Z</published>
    <title>Electrophysiological correlates of non-stationary BOLD functional
  connectivity fluctuations</title>
    <summary>  Spontaneous fluctuations of the BOLD (Blood Oxygen Level-Dependent) signal,
measured with fMRI (functional Magnetic Resonance Imaging), display a rich and
neurobiologically relevant functional connectivity structure. This structure is
usually revealed using time averaging methods, which prevent the detection of
functional connectivity changes over time. In this work we studied the
electrophysiological correlates of dynamical BOLD functional connectivity
fluctuations, by means of long (approx. 50 min) joint electroencephalographic
(EEG) and fMRI recordings. We identified widespread positive and negative
correlations between EEG spectral power and fMRI BOLD connectivity fluctuations
in a network of 90 cortical and subcortical regions. In particular, increased
alpha (8-12 Hz) and beta (15-30 Hz) power were related to decreased functional
connectivity, whereas gamma (30-60 Hz) power correlated positively with BOLD
connectivity between specific brain regions. Furthermore, these patterns were
altered for subjects undergoing vigilance changes, with an involvement of the
slow delta (0.4 - 4 Hz) band in localized positive correlations. Finally, graph
theoretical indices of network structure also exhibited sharp changes over
time, with average path length correlating positively with alpha power
extracted from central and frontal electrodes. Our results strongly suggest
that non-stationary BOLD functional connectivity has a neurophysiological
origin. Positive correlations of BOLD connectivity with gamma can be
interpreted as increased average binding over relatively long periods of time,
possibly due to spontaneous cognition occurring during rest. Negative
correlations with alpha suggest functional inhibition of local and long-range
connectivity, associated with an idling state of the brain.
</summary>
    <author>
      <name>Enzo Tagliazucchi</name>
    </author>
    <author>
      <name>Frederic von Wegner</name>
    </author>
    <author>
      <name>Astrid Morzelewski</name>
    </author>
    <author>
      <name>Verena Brodbeck</name>
    </author>
    <author>
      <name>Helmut Laufs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3577v1</id>
    <updated>2012-12-14T20:09:34Z</updated>
    <published>2012-12-14T20:09:34Z</published>
    <title>Dynamics and spike trains statistics in conductance-based
  Integrate-and-Fire neural networks with chemical and electric synapses</title>
    <summary>  We investigate the effect of electric synapses (gap junctions) on collective
neuronal dynamics and spike statistics in a conductance-based
Integrate-and-Fire neural network, driven by a Brownian noise, where
conductances depend upon spike history. We compute explicitly the time
evolution operator and show that, given the spike-history of the network and
the membrane potentials at a given time, the further dynamical evolution can be
written in a closed form. We show that spike train statistics is described by a
Gibbs distribution whose potential can be approximated with an explicit
formula, when the noise is weak. This potential form encompasses existing
models for spike trains statistics analysis such as maximum entropy models or
Generalized Linear Models (GLM). We also discuss the different types of
correlations: those induced by a shared stimulus and those induced by neurons
interactions.
</summary>
    <author>
      <name>Rodrigo Cofré</name>
    </author>
    <author>
      <name>Bruno Cessac</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/1471-2202-14-S1-P58</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/1471-2202-14-S1-P58" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 1 figure, submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5811v1</id>
    <updated>2012-06-25T20:00:33Z</updated>
    <published>2012-06-25T20:00:33Z</published>
    <title>On the Origin of Tremor in Parkinson's Disease</title>
    <summary>  The exact origin of tremor in Parkinson's disease remains unknown. We explain
why the existing data converge on the basal ganglia-thalamo-cortical loop as a
tremor generator and consider a conductance-based model of subthalamo-pallidal
circuits embedded into a simplified representation of the basal
ganglia-thalamo-cortical circuit to investigate the dynamics of this loop. We
show how variation of the strength of dopamine-modulated connections in the
basal ganglia-thalamo-cortical loop (representing the decreasing dopamine level
in Parkinson's disease) leads to the occurrence of tremor-like burst firing.
These tremor-like oscillations are suppressed when the connections are
modulated back to represent a higher dopamine level (as it would be the case in
dopaminergic therapy), as well as when the basal ganglia-thalamo-cortical loop
is broken (as would be the case for ablative anti-parkinsonian surgeries).
Thus, the proposed model provides an explanation for the basal
ganglia-thalamo-cortical loop mechanism of tremor generation. The strengthening
of the loop leads to tremor oscillations, while the weakening or disconnection
of the loop suppresses them. The loop origin of parkinsonian tremor also
suggests that new tremor-suppression therapies may have anatomical targets in
different cortical and subcortical areas as long as they are within the basal
ganglia-thalamo-cortical loop.
</summary>
    <author>
      <name>Andrey Dovzhenok</name>
    </author>
    <author>
      <name>Leonid L. Rubchinsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0041598</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0041598" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 8 figures, submitted to PLoS One</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(2012) PLoS ONE 7(7): e41598</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.5811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5425v2</id>
    <updated>2015-03-26T16:16:46Z</updated>
    <published>2011-04-28T15:28:07Z</published>
    <title>Noise-induced behaviors in neural mean field dynamics</title>
    <summary>  The collective behavior of cortical neurons is strongly affected by the
presence of noise at the level of individual cells. In order to study these
phenomena in large-scale assemblies of neurons, we consider networks of
firing-rate neurons with linear intrinsic dynamics and nonlinear coupling,
belonging to a few types of cell populations and receiving noisy currents.
Asymptotic equations as the number of neurons tends to infinity (mean field
equations) are rigorously derived based on a probabilistic approach. These
equations are implicit on the probability distribution of the solutions which
generally makes their direct analysis difficult. However, in our case, the
solutions are Gaussian, and their moments satisfy a closed system of nonlinear
ordinary differential equations (ODEs), which are much easier to study than the
original stochastic network equations, and the statistics of the empirical
process uniformly converge towards the solutions of these ODEs. Based on this
description, we analytically and numerically study the influence of noise on
the collective behaviors, and compare these asymptotic regimes to simulations
of the network. We observe that the mean field equations provide an accurate
description of the solutions of the network equations for network sizes as
small as a few hundreds of neurons. In particular, we observe that the level of
noise in the system qualitatively modifies its collective behavior, producing
for instance synchronized oscillations of the whole network, desynchronization
of oscillating regimes, and stabilization or destabilization of stationary
solutions. These results shed a new light on the role of noise in shaping
collective dynamics of neurons, and gives us clues for understanding similar
phenomena observed in biological networks.
</summary>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <author>
      <name>Geoffroy Hermann</name>
    </author>
    <author>
      <name>Olivier Faugeras</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/110832392</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/110832392" rel="related"/>
    <link href="http://arxiv.org/abs/1104.5425v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5425v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3277v2</id>
    <updated>2012-12-05T16:06:48Z</updated>
    <published>2012-09-14T18:42:31Z</published>
    <title>Dead leaves and the dirty ground: low-level image statistics in
  transmissive and occlusive imaging environments</title>
    <summary>  The opacity of typical objects in the world results in occlusion --- an
important property of natural scenes that makes inference of the full
3-dimensional structure of the world challenging. The relationship between
occlusion and low-level image statistics has been hotly debated in the
literature, and extensive simulations have been used to determine whether
occlusion is responsible for the ubiquitously observed power-law power spectra
of natural images. To deepen our understanding of this problem, we have
analytically computed the 2- and 4-point functions of a generalized "dead
leaves" model of natural images with parameterized object transparency.
Surprisingly, transparency alters these functions only by a multiplicative
constant, so long as object diameters follow a power law distribution. For
other object size distributions, transparency more substantially affects the
low-level image statistics. We propose that the universality of power law power
spectra for both natural scenes and radiological medical images -- formed by
the transmission of x-rays through partially transparent tissue -- stems from
power law object size distributions, independent of object opacity.
</summary>
    <author>
      <name>Joel Zylberberg</name>
    </author>
    <author>
      <name>David Pfau</name>
    </author>
    <author>
      <name>Michael Robert DeWeese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.86.066112</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.86.066112" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures. Matches the version accepted to Phys Rev E</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 86, 066112 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.3277v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3277v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.4773v1</id>
    <updated>2011-01-25T11:07:34Z</updated>
    <published>2011-01-25T11:07:34Z</published>
    <title>Hierarchical organization of brain functional network during visual task</title>
    <summary>  In this paper, the brain functional networks derived from high-resolution
synchronous EEG time series during visual task are generated by calculating the
phase synchronization among the time series. The hierarchical modular
organizations of these networks are systematically investigated by the fast
Girvan-Newman algorithm. At the same time, the spatially adjacent electrodes
(corresponding to EEG channels) are clustered into functional groups based on
anatomical parcellation of brain cortex, and this clustering information are
compared to that of the functional network. The results show that the modular
architectures of brain functional network are in coincidence with that from the
anatomical structures over different levels of hierarchy, which suggests that
population of neurons performing the same function excite and inhibit in
identical rhythms. The structure-function relationship further reveals that the
correlations among EEG time series in the same functional group are much
stronger than those in different ones and that the hierarchical organization of
brain functional network may be a consequence of functional segmentation of
brain cortex.
</summary>
    <author>
      <name>Zhao Zhuo</name>
    </author>
    <author>
      <name>Shi-Min Cai</name>
    </author>
    <author>
      <name>Zhong-Qian Fu</name>
    </author>
    <author>
      <name>Jie Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages,6 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 84, 031923 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.4773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.4773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3271v2</id>
    <updated>2013-02-11T19:08:36Z</updated>
    <published>2012-09-14T18:03:25Z</published>
    <title>Critical Avalanches and Subsampling in Map-based Neural Networks</title>
    <summary>  We investigate the synaptic noise as a novel mechanism for creating critical
avalanches in the activity of neural networks. We model neurons and chemical
synapses by dynamical maps with a uniform noise term in the synaptic coupling.
An advantage of utilizing maps is that the dynamical properties (action
potential profile, excitability properties, post synaptic potential summation
etc.) are not imposed to the system, but occur naturally by solving the system
equations. We discuss the relevant neuronal and synaptic properties to achieve
the critical state. We verify that networks of excitatory by rebound neurons
with fast synapses present power law avalanches. We also discuss the measuring
of neuronal avalanches by subsampling our data, shedding light on the
experimental search for Self-Organized Criticality in neural networks.
</summary>
    <author>
      <name>Mauricio Girardi-Schappo</name>
    </author>
    <author>
      <name>Osame Kinouchi</name>
    </author>
    <author>
      <name>Marcelo H. R. Tragtenberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures; Submitted to: Physical Review Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3271v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3271v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1946v2</id>
    <updated>2011-12-04T13:17:50Z</updated>
    <published>2011-04-11T13:38:22Z</published>
    <title>Coverage, Continuity and Visual Cortical Architecture</title>
    <summary>  The primary visual cortex of many mammals contains a continuous
representation of visual space, with a roughly repetitive aperiodic map of
orientation preferences superimposed. It was recently found that orientation
preference maps (OPMs) obey statistical laws which are apparently invariant
among species widely separated in eutherian evolution. Here, we examine whether
one of the most prominent models for the optimization of cortical maps, the
elastic net (EN) model, can reproduce this common design. The EN model
generates representations which optimally trade of stimulus space coverage and
map continuity. While this model has been used in numerous studies, no
analytical results about the precise layout of the predicted OPMs have been
obtained so far. We present a mathematical approach to analytically calculate
the cortical representations predicted by the EN model for the joint mapping of
stimulus position and orientation. We find that in all previously studied
regimes, predicted OPM layouts are perfectly periodic. An unbiased search
through the EN parameter space identifies a novel regime of aperiodic OPMs with
pinwheel densities lower than found in experiments. In an extreme limit,
aperiodic OPMs quantitatively resembling experimental observations emerge.
Stabilization of these layouts results from strong nonlocal interactions rather
than from a coverage-continuity-compromise. Our results demonstrate that
optimization models for stimulus representations dominated by nonlocal
suppressive interactions are in principle capable of correctly predicting the
common OPM design. They question that visual cortical feature representations
can be explained by a coverage-continuity-compromise.
</summary>
    <author>
      <name>Wolfgang Keil</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">100 pages, including an Appendix, 21 + 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1946v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1946v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3829v1</id>
    <updated>2012-09-18T02:25:50Z</updated>
    <published>2012-09-18T02:25:50Z</published>
    <title>Self-organized criticality in a network of interacting neurons</title>
    <summary>  This paper contains an analysis of a simple neural network that exhibits
self-organized criticality. Such criticality follows from the combination of a
simple neural network with an excitatory feedback loop that generates
bistability, in combination with an anti-Hebbian synapse in its input pathway.
Using the methods of statistical field theory, we show how one can formulate
the stochastic dynamics of such a network as the action of a path integral,
which we then investigate using renormalization group methods. The results
indicate that the network exhibits hysteresis in switching back and forward
between its two stable states, each of which loses its stability at a
saddle-node bifurcation. The renormalization group analysis shows that the
fluctuations in the neighborhood of such bifurcations have the signature of
directed percolation. Thus the network states undergo the neural analog of a
phase transition in the universality class of directed percolation. The network
replicates precisely the behavior of the original sand-pile model of Bak, Tang
&amp; Wiesenfeld.
</summary>
    <author>
      <name>J D Cowan</name>
    </author>
    <author>
      <name>J Neuman</name>
    </author>
    <author>
      <name>W van Drongelen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures, submitted to Journal of Statistical Mechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1330v1</id>
    <updated>2011-12-06T15:59:30Z</updated>
    <published>2011-12-06T15:59:30Z</published>
    <title>Emotional control - conditio sine qua non for advanced artificial
  intelligences?</title>
    <summary>  Humans dispose of two intertwined information processing pathways, cognitive
information processing via neural firing patterns and diffusive volume control
via neuromodulation. The cognitive information processing in the brain is
traditionally considered to be the prime neural correlate of human
intelligence, clinical studies indicate that human emotions intrinsically
correlate with the activation of the neuromodulatory system.
  We examine here the question: Why do humans dispose of the diffusive
emotional control system? Is this a coincidence, a caprice of nature, perhaps a
leftover of our genetic heritage, or a necessary aspect of any advanced
intelligence, being it biological or synthetic? We argue here that emotional
control is necessary to solve the motivational problem, viz the selection of
short-term utility functions, in the context of an environment where
information, computing power and time constitute scarce resources.
</summary>
    <author>
      <name>Claudius Gros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of PT-AI 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.1330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5428v1</id>
    <updated>2011-02-26T16:00:08Z</updated>
    <published>2011-02-26T16:00:08Z</published>
    <title>Reservoirs of Stability: Flux Tubes in the Dynamics of Cortical Circuits</title>
    <summary>  Triggering a single additional spike in a cerebral cortical neuron was
recently demonstrated to cause a cascade of extra spikes in the network that is
likely to rapidly decorrelate the network's microstate. The mechanisms involved
in this extreme sensitivity of cortical networks are currently not well
understood. Here, we show in a minimal model of cortical circuit dynamics that
exponential state separation after single spike and even single synapse
perturbations coexists with dynamical stability to infinitesimal state
perturbations. We propose a unifying picture of exponentially separating flux
tubes enclosing unique stable trajectories composing the networks' state
spaces.
</summary>
    <author>
      <name>Michael Monteforte</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.5428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.2434v1</id>
    <updated>2011-01-10T16:24:46Z</updated>
    <published>2011-01-10T16:24:46Z</published>
    <title>Spike Avalanches Exhibit Universal Dynamics across the Sleep-Wake Cycle</title>
    <summary>  Scale-invariant neuronal avalanches have been observed in cell cultures and
slices as well as anesthetized and awake brains, suggesting that the brain
operates near criticality, i.e. within a narrow margin between avalanche
propagation and extinction. In theory, criticality provides many desirable
features for the behaving brain, optimizing computational capabilities,
information transmission, sensitivity to sensory stimuli and size of memory
repertoires. However, a thorough characterization of neuronal avalanches in
freely-behaving (FB) animals is still missing, thus raising doubts about their
relevance for brain function. To address this issue, we employed chronically
implanted multielectrode arrays (MEA) to record avalanches of spikes from the
cerebral cortex (V1 and S1) and hippocampus (HP) of 14 rats, as they
spontaneously traversed the wake-sleep cycle, explored novel objects or were
subjected to anesthesia (AN). We then modeled spike avalanches to evaluate the
impact of sparse MEA sampling on their statistics. We found that the size
distribution of spike avalanches are well fit by lognormal distributions in FB
animals, and by truncated power laws in the AN group. The FB data are also
characterized by multiple key features compatible with criticality in the
temporal domain, such as 1/f spectra and long-term correlations as measured by
detrended fluctuation analysis. These signatures are very stable across waking,
slow-wave sleep and rapid-eye-movement sleep, but collapse during anesthesia.
Likewise, waiting time distributions obey a single scaling function during all
natural behavioral states, but not during anesthesia. Results are equivalent
for neuronal ensembles recorded from V1, S1 and HP. Altogether, the data
provide a comprehensive link between behavior and brain criticality, revealing
a unique scale-invariant regime of spike avalanches across all major behaviors.
</summary>
    <author>
      <name>Tiago L. Ribeiro</name>
    </author>
    <author>
      <name>Mauro Copelli</name>
    </author>
    <author>
      <name>Fábio Caixeta</name>
    </author>
    <author>
      <name>Hindiael Belchior</name>
    </author>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <author>
      <name>Miguel A. L. Nicolelis</name>
    </author>
    <author>
      <name>Sidarta Ribeiro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0014129</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0014129" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 9 figures, supporting material included (published in Plos
  One)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 5(11): e14129, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.2434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.2434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3113v2</id>
    <updated>2012-12-31T18:57:29Z</updated>
    <published>2012-03-14T15:27:17Z</published>
    <title>Consciousness and the structuring property of typical data</title>
    <summary>  The theoretical base for consciousness, in particular an explanation of how
consciousness is defined by the brain, has long been sought by science. We
propose a partial theory of consciousness as relations defined by typical data.
The theory is based on the idea that a brain state on its own is almost
meaningless but in the context of the typical brain states, defined by the
brain's structure, a particular brain state is highly structured by relations.
The proposed theory can be applied and tested both theoretically and
experimentally. Precisely how typical data determines relations is fully
established using discrete mathematics.
</summary>
    <author>
      <name>Jonathan W. Mason</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/cplx.21431</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/cplx.21431" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures, First submitted for publication March 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3113v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3113v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20, 91E30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0732v3</id>
    <updated>2012-05-28T09:15:33Z</updated>
    <published>2012-01-03T19:53:42Z</published>
    <title>Model-free reconstruction of neuronal network connectivity from calcium
  imaging signals</title>
    <summary>  A systematic assessment of global neural network connectivity through direct
electrophysiological assays has remained technically unfeasible even in
dissociated neuronal cultures. We introduce an improved algorithmic approach
based on Transfer Entropy to reconstruct approximations to network structural
connectivities from network activity monitored through calcium fluorescence
imaging. Based on information theory, our method requires no prior assumptions
on the statistics of neuronal firing and neuronal connections. The performance
of our algorithm is benchmarked on surrogate time-series of calcium
fluorescence generated by the simulated dynamics of a network with known
ground-truth topology. We find that the effective network topology revealed by
Transfer Entropy depends qualitatively on the time-dependent dynamic state of
the network (e.g., bursting or non-bursting). We thus demonstrate how
conditioning with respect to the global mean activity improves the performance
of our method. [...] Compared to other reconstruction strategies such as
cross-correlation or Granger Causality methods, our method based on improved
Transfer Entropy is remarkably more accurate. In particular, it provides a good
reconstruction of the network clustering coefficient, allowing to discriminate
between weakly or strongly clustered topologies, whereas on the other hand an
approach based on cross-correlations would invariantly detect artificially high
levels of clustering. Finally, we present the applicability of our method to
real recordings of in vitro cortical cultures. We demonstrate that these
networks are characterized by an elevated level of clustering compared to a
random graph (although not extreme) and by a markedly non-local connectivity.
</summary>
    <author>
      <name>Olav Stetter</name>
    </author>
    <author>
      <name>Demian Battaglia</name>
    </author>
    <author>
      <name>Jordi Soriano</name>
    </author>
    <author>
      <name>Theo Geisel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages, 8 figures (+9 supplementary figures), 1 table; submitted
  for publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0732v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0732v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.0298v4</id>
    <updated>2013-02-19T17:21:22Z</updated>
    <published>2012-07-02T07:35:27Z</published>
    <title>Echoes in correlated neural systems</title>
    <summary>  Correlations are employed in modern physics to explain microscopic and
macroscopic phenomena, like the fractional quantum Hall effect and the Mott
insulator state in high temperature superconductors and ultracold atoms.
Simultaneously probed neurons in the intact brain reveal correlations between
their activity, an important measure to study information processing in the
brain that also influences macroscopic signals of neural activity, like the
electro encephalogram (EEG). Networks of spiking neurons differ from most
physical systems: The interaction between elements is directed, time delayed,
mediated by short pulses, and each neuron receives events from thousands of
neurons. Even the stationary state of the network cannot be described by
equilibrium statistical mechanics. Here we develop a quantitative theory of
pairwise correlations in finite sized random networks of spiking neurons. We
derive explicit analytic expressions for the population averaged cross
correlation functions. Our theory explains why the intuitive mean field
description fails, how the echo of single action potentials causes an apparent
lag of inhibition with respect to excitation, and how the size of the network
can be scaled while maintaining its dynamical state. Finally, we derive a new
criterion for the emergence of collective oscillations from the spectrum of the
time-evolution propagator.
</summary>
    <author>
      <name>Moritz Helias</name>
    </author>
    <author>
      <name>Tom Tetzlaff</name>
    </author>
    <author>
      <name>Markus Diesmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1367-2630/15/2/023002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1367-2630/15/2/023002" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">M Helias, T Tetzlaff, M Diesmann (2013). Echoes in correlated
  neural systems. New J. Phys. 15 023002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.0298v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.0298v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6615v2</id>
    <updated>2013-04-22T20:06:00Z</updated>
    <published>2012-11-28T14:39:16Z</published>
    <title>Modeling geometric-optical illusions: A variational approach</title>
    <summary>  Visual distortions of perceived lengths, angles, or forms, are generally
known as "geometric-optical illusions" (GOI). In the present paper we focus on
a class of GOIs where the distortion of a straight line segment (the "target"
stimulus) is induced by an array of non-intersecting curvilinear elements
("context" stimulus). Assuming local target-context interactions in a vector
field representation of the context, we propose to model the perceptual
distortion of the target as the solution to a minimization problem in the
calculus of variations. We discuss properties of the solutions and reproduction
of the respective form of the perceptual distortion for several types of
contexts. Moreover, we draw a connection between the interactionist model of
GOIs and Riemannian geometry: the context stimulus is understood as perturbing
the geometry of the visual field from which the illusory distortion naturally
arises. The approach is illustrated by data from a psychophysical experiment
with nine subjects and six different contexts.
</summary>
    <author>
      <name>Werner Ehm</name>
    </author>
    <author>
      <name>Jiri Wackermann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor corrections, final version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Mathematical Psychology 56 (2012), 404-416</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6615v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6615v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B99, 49N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5350v4</id>
    <updated>2013-02-19T17:08:00Z</updated>
    <published>2012-08-27T10:06:12Z</published>
    <title>Impact of intrinsic biophysical diversity on the activity of spiking
  neurons</title>
    <summary>  We study the effect of intrinsic heterogeneity on the activity of a
population of leaky integrate-and-fire neurons. By rescaling the dynamical
equation, we derive mathematical relations between multiple neuronal parameters
and a fluctuating input noise. To this end, common input to heterogeneous
neurons is conceived as an identical noise with neuron-specific mean and
variance. As a consequence, the neuronal output rates can differ considerably,
and their relative spike timing becomes desynchronized. This theory can
quantitatively explain some recent experimental findings.
</summary>
    <author>
      <name>Man Yi Yim</name>
    </author>
    <author>
      <name>Ad Aertsen</name>
    </author>
    <author>
      <name>Stefan Rotter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.87.032710</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.87.032710" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 87, 032710 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.5350v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5350v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2443v1</id>
    <updated>2011-04-13T10:48:21Z</updated>
    <published>2011-04-13T10:48:21Z</published>
    <title>Effects of noise on models of spiny dendrites</title>
    <summary>  We study the effects of noise in two models of spiny dendrites. Through the
introduction of different types of noise to both the Spike-diffuse-spike (SDS)
and Baer-Rinzel (BR) models we investigate the change in behaviour of the
travelling wave solutions present in the deterministic systems, as noise
intensity increases. We show that the speed of wave propagation in the SDS and
BR models respectively decreases and increases as the noise intensity in the
spine heads increases. Interestingly the discrepancy between the models does
not seem to arise from the type of active spine head dynamics employed by the
model but rather by the form of the spine density used. In contrast the cable
is very robust to noise and as such the speed shows very little variation from
the deterministic system. We look at the effect of the noise interpretation
used to evaluate the stochastic integral; Ito or Statonovich and discuss which
may be appropriate. We also show that the correlation time and length scales of
the noise can enhance propagation of travelling wave solutions where the white
noise dominates the signal and produces noise induced phenomena.
</summary>
    <author>
      <name>Emma J. Coutts</name>
    </author>
    <author>
      <name>Gabriel J. Lord</name>
    </author>
    <link href="http://arxiv.org/abs/1104.2443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1358v1</id>
    <updated>2011-01-07T06:00:17Z</updated>
    <published>2011-01-07T06:00:17Z</published>
    <title>Mass synchronization: Occurrence and its control with possible
  applications to brain dynamics</title>
    <summary>  Occurrence of strong or mass synchronization of a large number of neuronal
populations in the brain characterizes its pathological states. In order to
establish an understanding of the mechanism underlying such pathological
synchronization we present a model of coupled populations of phase oscillators
representing the interacting neuronal populations. Through numerical analysis,
we discuss the occurrence of mass synchronization in the model, where a source
population which gets strongly synchronized drives the target populations onto
mass synchronization. We hypothesize and identify a possible cause for the
occurrence of such a synchronization, which is so far unknown: Pathological
synchronization is caused not just because of the increase in the strength of
coupling between the populations but also because of the strength of the strong
synchronization of the drive population. We propose a demand-controlled method
to control this pathological synchronization by providing a delayed feedback
where the strength and frequency of the synchronization determines the strength
and the time delay of the feedback. We provide an analytical explanation for
the occurrence of pathological synchronization and its control in the
thermodynamic limit.
</summary>
    <author>
      <name>V. K. Chandrasekar</name>
    </author>
    <author>
      <name>Jane H. Sheeba</name>
    </author>
    <author>
      <name>M. Lakshmanan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 20, 045106 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.1358v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1358v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0763v2</id>
    <updated>2012-03-27T16:20:20Z</updated>
    <published>2011-10-04T17:34:20Z</published>
    <title>Non-random walks in monkeys and humans</title>
    <summary>  Principles of self-organization play an increasingly central role in models
of human activity. Notably, individual human displacements exhibit strongly
recurrent patterns that are characterized by scaling laws and can be
mechanistically modelled as self-attracting walks. Recurrence is not, however,
unique to human displacements. Here we report that the mobility patterns of
wild capuchin monkeys are not random walks and exhibit recurrence properties
similar to those of cell phone users, suggesting spatial cognition mechanisms
shared with humans. We also show that the highly uneven visitation patterns
within monkey home ranges are not entirely self-generated but are forced by
spatio-temporal habitat heterogeneities. If models of human mobility are to
become useful tools for predictive purposes, they will need to consider the
interaction between memory and environmental heterogeneities.
</summary>
    <author>
      <name>Denis Boyer</name>
    </author>
    <author>
      <name>Margaret C. Crofoot</name>
    </author>
    <author>
      <name>Peter D. Walsh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. R. Soc. Interface 9, 842-847 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.0763v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0763v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3078v1</id>
    <updated>2012-12-13T07:58:24Z</updated>
    <published>2012-12-13T07:58:24Z</published>
    <title>Analytical Condition for Synchrony in a Neural Network with Two Periodic
  Inputs</title>
    <summary>  In this study, we apply a mean field theory to the neural network model with
two periodic inputs in order to clarify the conditions of synchronies. This
mean field theory yields a self-consistent condition for the synchrony and
enables us to study the effects of synaptic connections for the behavior of
neural networks. Then, we have obtained a condition of synaptic connections for
the synchrony with the cycle time $T$. The neurons in neural networks receive
sensory inputs and top-down inputs from outside of the network. When the
network neurons receive two or more inputs, their synchronization depends on
the conditions of inputs. We have also analyzed this case using the mean field
theory. As a result, we clarified the following points: (1) The stronger
synaptic connections enhance the shorter synchrony cycle of neurons. (2) The
cycle of the synchrony becomes longer as the cycle of external inputs becomes
longer. (3) The relationships among synaptic weights, the properties of input
trains, and the cycle of synchrony are expressed by one equation, and there are
two areas for asynchrony. In association with the third point, the yielded
equation is so simple for calculation that they can easily provide us feasible
and infeasible conditions for synchrony.
</summary>
    <author>
      <name>Yoichiro Hashizume</name>
    </author>
    <author>
      <name>Osamu Araki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.87.012713</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.87.012713" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages,4 figures,(accepted by Physical Review E)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 87, 012713 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0710v1</id>
    <updated>2012-04-03T15:26:53Z</updated>
    <published>2012-04-03T15:26:53Z</published>
    <title>Optogenetic control of genetically-targeted pyramidal neuron activity in
  prefrontal cortex</title>
    <summary>  A salient feature of prefrontal cortex organization is the vast diversity of
cell types that support the temporal integration of events required for
sculpting future responses. A major obstacle in understanding the routing of
information among prefrontal neuronal subtypes is the inability to manipulate
the electrical activity of genetically defined cell types over behaviorally
relevant timescales and activity patterns. To address these constraints, we
present here a simple approach for selective activation of prefrontal
excitatory neurons in both in vitro and in vivo preparations. Rat prelimbic
pyramidal neurons were genetically targeted to express a light-activated
nonselective cation channel, channelrhodopsin-2, or a light-driven inward
chloride pump, halorhodopsin, which enabled them to be rapidly and reversibly
activated or inhibited by pulses of light. These light responsive tools provide
a spatially and temporally precise means of studying how different cell types
contribute to information processing in cortical circuits. Our customized
optrodes and optical commutators for in vivo recording allow for efficient
light delivery and recording and can be requested at
www.neuro-cloud.net/nature-precedings/baratta.
</summary>
    <author>
      <name>Michael V. Baratta</name>
    </author>
    <author>
      <name>Shinya Nakamura</name>
    </author>
    <author>
      <name>Peter Dobelis</name>
    </author>
    <author>
      <name>Matthew B. Pomrenze</name>
    </author>
    <author>
      <name>Samuel D. Dolzani</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/npre.2012.7102.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/npre.2012.7102.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures Posted on
  http://www.neuro-cloud.net/nature-precedings/baratta</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1108v1</id>
    <updated>2012-06-06T02:30:44Z</updated>
    <published>2012-06-06T02:30:44Z</published>
    <title>Thermodynamic Model of Criticality in the Cortex Based On EEG/ECOG Data</title>
    <summary>  Criticality in the cortex emerges from the seemingly random interaction of
microscopic components and produces higher cognitive functions at mesoscopic
and macroscopic scales. Random graphs and percolation theory provide natural
means to de- scribe critical regions in the behavior of the cortex and they are
proposed here as novel mathematical tools helping us deciphering the language
of the brain.
</summary>
    <author>
      <name>Robert Kozma</name>
    </author>
    <author>
      <name>Marko Puljic</name>
    </author>
    <author>
      <name>Walter J. Freeman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Criticality in Neural Systems, 2012 (book chapter)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0097v2</id>
    <updated>2011-12-15T22:13:03Z</updated>
    <published>2011-11-01T00:57:39Z</published>
    <title>Adaptive probabilistic neural coding from deterministic spiking neurons:
  analysis from first principles</title>
    <summary>  A neuron transforms its input into output spikes, and this transformation is
the basic unit of computation in the nervous system. The spiking response of
the neuron to a complex, time-varying input can be predicted from the detailed
biophysical properties of the neuron, modeled as a deterministic nonlinear
dynamical system. In the tradition of neural coding, however, a neuron or
neural system is treated as a black box and statistical techniques are used to
identify functional models of its encoding properties. The goal of this work is
to connect the mechanistic, biophysical approach to neuronal function to a
description in terms of a coding model. Building from preceding work at the
single neuron level, we develop from first principles a mathematical theory
mapping the relationships between two simple but powerful classes of models:
deterministic integrate-and-fire dynamical models and linear-nonlinear coding
models. To do so, we develop an approach for studying a nonlinear dynamical
system by conditioning on an observed linear estimator. We derive asymptotic
closed-form expressions for the linear filter and estimates for the nonlinear
decision function of the linear/nonlinear model. We analytically derive the
dependence of the linear filter on the input statistics and we show how
deterministic nonlinear dynamics can be used to modulate the properties of a
probabilistic code. We demonstrate that integrate-and-fire models without any
additional currents can perform perfect contrast gain control, a sophisticated
adaptive computation, and we identify the general dynamical principles
responsible. We then design from first principles a nonlinear dynamical model
that implements gain control. While we focus on the integrate-and-fire models
for tractability, the framework we propose to relate LN and dynamical models
generalizes naturally to more complex biophysical models.
</summary>
    <author>
      <name>Michael Famulare</name>
    </author>
    <author>
      <name>Adrienne Fairhall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v2: revised/expanded results/discussion regarding contrast gain
  control. 51 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.0097v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0097v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0328v1</id>
    <updated>2012-01-01T04:25:20Z</updated>
    <published>2012-01-01T04:25:20Z</published>
    <title>Let us first agree on what the term "semantics" means: An unorthodox
  approach to an age-old debate</title>
    <summary>  Traditionally, semantics has been seen as a feature of human language. The
advent of the information era has led to its widespread redefinition as an
information feature. Contrary to this praxis, I define semantics as a special
kind of information. Revitalizing the ideas of Bar-Hillel and Carnap I have
recreated and re-established the notion of semantics as the notion of Semantic
Information. I have proposed a new definition of information (as a description,
a linguistic text, a piece of a story or a tale) and a clear segregation
between two different types of information - physical and semantic information.
I hope, I have clearly explained the (usually obscured and mysterious)
interrelations between data and physical information as well as the relation
between physical information and semantic information. Consequently, usually
indefinable notions of "information", "knowledge", "memory", "learning" and
"semantics" have also received their suitable illumination and explanation.
</summary>
    <author>
      <name>Emanuel Diamant</name>
    </author>
    <link href="http://arxiv.org/abs/1201.0328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.4771v1</id>
    <updated>2012-03-21T16:16:30Z</updated>
    <published>2012-03-21T16:16:30Z</published>
    <title>Desynchronizing effect of high-frequency stimulation in a generic
  cortical network model</title>
    <summary>  Transcranial Electrical Stimulation (TCES) and Deep Brain Stimulation (DBS)
are two different applications of electrical current to the brain used in
different areas of medicine. Both have a similar frequency dependence of their
efficiency, with the most pronounced effects around 100Hz. We apply
superthreshold electrical stimulation, specifically depolarizing DC current,
interrupted at different frequencies, to a simple model of a population of
cortical neurons which uses phenomenological descriptions of neurons by
Izhikevich and synaptic connections on a similar level of sophistication. With
this model, we are able to reproduce the optimal desynchronization around
100Hz, as well as to predict the full frequency dependence of the efficiency of
desynchronization, and thereby to give a possible explanation for the action
mechanism of TCES.
</summary>
    <author>
      <name>Markus Schütt</name>
    </author>
    <author>
      <name>Jens Christian Claussen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, figs included. Accepted for publication in Cognitive
  Neurodynamics</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.4771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.4771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1558v1</id>
    <updated>2012-04-06T20:33:47Z</updated>
    <published>2012-04-06T20:33:47Z</published>
    <title>Nicotinic α7 acetylcholine receptor-mediated currents are not
  modulated by the tryptophan metabolite kynurenic acid in adult hippocampal
  interneurons</title>
    <summary>  The tryptophan metabolite, kynurenic acid (KYNA), is classically known to be
an antagonist of ionotropic glutamate receptors. Within the last decade several
reports have been published suggesting that KYNA also blocks nicotinic
acetylcholine receptors (nAChRs) containing the \alpha7 subunit (\alpha7*).
Most of these reports involve either indirect measurements of KYNA effects on
\alpha7 nAChR function, or are reports of KYNA effects in complicated in vivo
systems. However, a recent report investigating KYNA interactions with \alpha7
nAChRs failed to detect an interaction using direct measurements of \alpha7
nAChRs function. Further, it showed that a KYNA blockade of \alpha7 nAChR
stimulated GABA release (an indirect measure of \alpha7 nAChR function) was not
due to KYNA blockade of the \alpha7 nAChRs. The current study measured the
direct effects of KYNA on \alpha7-containing nAChRs expressed on interneurons
in the hilar and CA1 stratum radiatum regions of the mouse hippocampus and on
interneurons in the CA1 region of the rat hippocampus. Here we show that KYNA
does not block \alpha7* nACHRs using direct patch-clamprecording of \alpha7
currents in adult brain slices.
</summary>
    <author>
      <name>Peter Dobelis</name>
    </author>
    <author>
      <name>Andrew L. Varnell</name>
    </author>
    <author>
      <name>Kevin J. Staley</name>
    </author>
    <author>
      <name>Donald C. Cooper</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/npre.2011.6277.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/npre.2011.6277.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, Nature Precedings
  http://dx.doi.org/10.1038/npre.2011.6277.1</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3073v1</id>
    <updated>2012-03-14T13:00:51Z</updated>
    <published>2012-03-14T13:00:51Z</published>
    <title>Nearly extensive sequential memory lifetime achieved by coupled
  nonlinear neurons</title>
    <summary>  Many cognitive processes rely on the ability of the brain to hold sequences
of events in short-term memory. Recent studies have revealed that such memory
can be read out from the transient dynamics of a network of neurons. However,
the memory performance of such a network in buffering past information has only
been rigorously estimated in networks of linear neurons. When signal gain is
kept low, so that neurons operate primarily in the linear part of their
response nonlinearity, the memory lifetime is bounded by the square root of the
network size. In this work, I demonstrate that it is possible to achieve a
memory lifetime almost proportional to the network size, "an extensive memory
lifetime", when the nonlinearity of neurons is appropriately utilized. The
analysis of neural activity revealed that nonlinear dynamics prevented the
accumulation of noise by partially removing noise in each time step. With this
error-correcting mechanism, I demonstrate that a memory lifetime of order
$N/\log N$ can be achieved.
</summary>
    <author>
      <name>Taro Toyoizumi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00324</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00324" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 5 figures, the manuscript has been accepted for publication
  in Neural Computation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Computation 24 (2012) 2678-2699</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.3073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0321v1</id>
    <updated>2012-01-01T03:11:49Z</updated>
    <published>2012-01-01T03:11:49Z</published>
    <title>Maximally informative "stimulus energies" in the analysis of neural
  responses to natural signals</title>
    <summary>  The concept of feature selectivity in sensory signal processing can be
formalized as dimensionality reduction: in a stimulus space of very high
dimensions, neurons respond only to variations within some smaller, relevant
subspace. But if neural responses exhibit invariances, then the relevant
subspace typically cannot be reached by a Euclidean projection of the original
stimulus. We argue that, in several cases, we can make progress by appealing to
the simplest nonlinear construction, identifying the relevant variables as
quadratic forms, or "stimulus energies." Natural examples include
non-phase-locked cells in the auditory system, complex cells in visual cortex,
and motion-sensitive neurons in the visual system. Generalizing the idea of
maximally informative dimensions, we show that one can search for the kernels
of the relevant quadratic forms by maximizing the mutual information between
the stimulus energy and the arrival times of action potentials. Simple
implementations of this idea successfully recover the underlying properties of
model neurons even when the number of parameters in the kernel is comparable to
the number of action potentials and stimuli are completely natural. We explore
several generalizations that allow us to incorporate plausible structure into
the kernel and thereby restrict the number of parameters. We hope that this
approach will add significantly to the set of tools available for the analysis
of neural responses to complex, naturalistic stimuli.
</summary>
    <author>
      <name>Kanaka Rajan</name>
    </author>
    <author>
      <name>William Bialek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5458v1</id>
    <updated>2011-04-28T17:56:32Z</updated>
    <published>2011-04-28T17:56:32Z</published>
    <title>An MRI-Derived Definition of MCI-to-AD Conversion for Long-Term,
  Automati c Prognosis of MCI Patients</title>
    <summary>  Alzheimer's disease (AD) and mild cognitive impairment (MCI), continue to be
widely studied. While there is no consensus on whether MCIs actually "convert"
to AD, the more important question is not whether MCIs convert, but what is the
best such definition. We focus on automatic prognostication, nominally using
only a baseline image brain scan, of whether an MCI individual will convert to
AD within a multi-year period following the initial clinical visit. This is in
fact not a traditional supervised learning problem since, in ADNI, there are no
definitive labeled examples of MCI conversion. Prior works have defined MCI
subclasses based on whether or not clinical/cognitive scores such as CDR
significantly change from baseline. There are concerns with these definitions,
however, since e.g. most MCIs (and ADs) do not change from a baseline CDR=0.5,
even while physiological changes may be occurring. These works ignore rich
phenotypical information in an MCI patient's brain scan and labeled AD and
Control examples, in defining conversion. We propose an innovative conversion
definition, wherein an MCI patient is declared to be a converter if any of the
patient's brain scans (at follow-up visits) are classified "AD" by an
(accurately-designed) Control-AD classifier. This novel definition bootstraps
the design of a second classifier, specifically trained to predict whether or
not MCIs will convert. This second classifier thus predicts whether an
AD-Control classifier will predict that a patient has AD. Our results
demonstrate this new definition leads not only to much higher prognostic
accuracy than by-CDR conversion, but also to subpopulations much more
consistent with known AD brain region biomarkers. We also identify key
prognostic region biomarkers, essential for accurately discriminating the
converter and nonconverter groups.
</summary>
    <author>
      <name>Yaman Aksu</name>
    </author>
    <author>
      <name>David J. Miller</name>
    </author>
    <author>
      <name>George Kesidis</name>
    </author>
    <author>
      <name>Don C. Bigler</name>
    </author>
    <author>
      <name>Qing X. Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1104.5458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3474v1</id>
    <updated>2012-10-12T10:48:41Z</updated>
    <published>2012-10-12T10:48:41Z</published>
    <title>Observing scale-invariance in non-critical dynamical systems</title>
    <summary>  Recent observation for scale invariant neural avalanches in the brain have
been discussed in details in the scientific literature. We point out, that
these results do not necessarily imply that the properties of the underlying
neural dynamics are also scale invariant. The reason for this discrepancy lies
in the fact that the sampling statistics of observations and experiments is
generically biased by the size of the basins of attraction of the processes to
be studied. One has hence to precisely define what one means with statements
like `the brain is critical'.
  We recapitulate the notion of criticality, as originally introduced in
statistical physics for second order phase transitions, turning then to the
discussion of critical dynamical systems. We elucidate in detail the difference
between a 'critical system', viz a system on the verge of a phase transition,
and a 'critical state', viz state with scale-invariant correlations, stressing
the fact that the notion of universality is linked to critical states.
  We then discuss rigorous results for two classes of critical dynamical
systems, the Kauffman net and a vertex routing model, which both have
non-critical states. However, an external observer that samples randomly the
phase space of these two critical models, would find scale invariance. We
denote this phenomenon as 'observational criticality' and discuss its relevance
for the response properties of critical dynamical systems.
</summary>
    <author>
      <name>Claudius Gros</name>
    </author>
    <author>
      <name>Dimitrije Markovic</name>
    </author>
    <link href="http://arxiv.org/abs/1210.3474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1858v1</id>
    <updated>2011-01-10T16:08:00Z</updated>
    <published>2011-01-10T16:08:00Z</published>
    <title>Dual-task Coordination in Children and Adolescents with Attention
  Deficit Hyperactivity Disorder (ADHD)</title>
    <summary>  The deficit of executive functioning was found to be associated with
attention deficit hyperactivity disorder (ADHD) in general and its subtypes.
One of the important functions of central executive is the ability
simultaneously coordinate two tasks. The study aimed at defining the dual-task
performance characteristics in healthy children and adolescents on the
computerised and the paper and pencil dual-task methods; investigating the
effect of task difficulty on dual-task performance in ADHD in comparison to age
and years of education matched healthy controls; testing if the paper and
pencil version of the dual-task method is giving the same results in ADHD and
healthy controls; investigating whether the dual-task functioning in ADHD is
defined by the deficits in the general motor functioning and comorbidity
factors. The study investigated dual task functioning in 6-16 years old 91
typically developing controls and 91 children with ADHD. It was found that: (1)
the dual-task coordination is available in children and adolescents with ADHD
in general and in its subtypes and not significantly different from performance
of age and years of education matched healthy controls; (2) Increase of the
task difficulty in dual-task paradigm don't affect disproportionately children
and adolescents with ADHD in comparison to age and years of education matched
healthy controls; (3) The paper and pencil version of the dual-task method is
giving the same results in ADHD and healthy controls as computerised version;
(4) The dual-task functioning in ADHD in general and in its subtypes is not
defined by the general motor functioning while in healthy controls dual task
performance is associated with the general motor functioning level; (5) The
dual-task functioning in ADHD in general and in its subtypes is not defined by
the comorbidity factors.
</summary>
    <author>
      <name>Ketevan Inasaridze</name>
    </author>
    <author>
      <name>Vera Bzhalava</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 9 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.1858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3353v3</id>
    <updated>2012-01-23T10:23:09Z</updated>
    <published>2011-02-16T14:50:23Z</published>
    <title>Coordinated optimization of visual cortical maps (I) Symmetry-based
  analysis</title>
    <summary>  In the primary visual cortex of primates and carnivores, functional
architecture can be characterized by maps of various stimulus features such as
orientation preference (OP), ocular dominance (OD), and spatial frequency. It
is a long-standing question in theoretical neuroscience whether the observed
maps should be interpreted as optima of a specific energy functional that
summarizes the design principles of cortical functional architecture. A
rigorous evaluation of this optimization hypothesis is particularly demanded by
recent evidence that the functional architecture of OP columns precisely
follows species invariant quantitative laws. Because it would be desirable to
infer the form of such an optimization principle from the biological data, the
optimization approach to explain cortical functional architecture raises the
following questions: i) What are the genuine ground states of candidate energy
functionals and how can they be calculated with precision and rigor? ii) How do
differences in candidate optimization principles impact on the predicted map
structure and conversely what can be learned about an hypothetical underlying
optimization principle from observations on map structure? iii) Is there a way
to analyze the coordinated organization of cortical maps predicted by
optimization principles in general? To answer these questions we developed a
general dynamical systems approach to the combined optimization of visual
cortical maps of OP and another scalar feature such as OD or spatial frequency
preference.
</summary>
    <author>
      <name>Lars Reichl</name>
    </author>
    <author>
      <name>Dominik Heide</name>
    </author>
    <author>
      <name>Siegrid Löwel</name>
    </author>
    <author>
      <name>Justin C. Crowley</name>
    </author>
    <author>
      <name>Matthias Kaschube</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">90 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3353v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3353v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.2957v1</id>
    <updated>2011-11-12T19:20:33Z</updated>
    <published>2011-11-12T19:20:33Z</published>
    <title>Portosystemic hepatic encephalopathy model shows reversal learning
  impairment and dysfunction of neural activity in the prefrontal cortex and
  regions involved in motivated behavior</title>
    <summary>  Hepatic encephalopathy is a neurological complication that affects attention
and memory. Experimental animal models have been used to study hepatic
Encephalopathy, the most frequent being the portacaval shunt. In order to
determine learning impairment and brain functional alterations in this model,
we assessed reversal learning and neural metabolic activity in a PCS rat model.
Portacaval shunt and sham-operated rats were tested for reversal learning in
the Morris water maze. Brains were processed for cytochrome oxidase
histochemistry. The portacaval shunt group presents reversal learning
impairment and cytochrome oxidase activity reduction in prefrontal cortex,
ventral tegmental area and accumbens shell nucleus. These results suggest that
this model of portosystemic hepatic encephalopathy shows learning impairment
that could be linked to dysfunction in neural activity in the prefrontal cortex
and regions involved in motivated behavior.
</summary>
    <author>
      <name>M. Méndez</name>
    </author>
    <author>
      <name>M. Méndez-López</name>
    </author>
    <author>
      <name>L. López</name>
    </author>
    <author>
      <name>M. A. Aller</name>
    </author>
    <author>
      <name>J. Arias</name>
    </author>
    <author>
      <name>J. L. Arias</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jocn.2010.09.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jocn.2010.09.010" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Clinical Neuroscience (2011)18(5):690-4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.2957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.2957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4487v2</id>
    <updated>2013-04-08T02:03:15Z</updated>
    <published>2012-11-19T16:35:18Z</published>
    <title>Memcomputing: a computing paradigm to store and process information on
  the same physical platform</title>
    <summary>  In present day technology, storing and processing of information occur on
physically distinct regions of space. Not only does this result in space
limitations; it also translates into unwanted delays in retrieving and
processing of relevant information. There is, however, a class of two-terminal
passive circuit elements with memory, memristive, memcapacitive and
meminductive systems -- collectively called memelements -- that perform both
information processing and storing of the initial, intermediate and final
computational data on the same physical platform. Importantly, the states of
these memelements adjust to input signals and provide analog capabilities
unavailable in standard circuit elements, resulting in adaptive circuitry, and
providing analog massively-parallel computation. All these features are
tantalizingly similar to those encountered in the biological realm, thus
offering new opportunities for biologically-inspired computation. Of particular
importance is the fact that these memelements emerge naturally in nanoscale
systems, and are therefore a consequence and a natural by-product of the
continued miniaturization of electronic devices. We will discuss the various
possibilities offered by memcomputing, discuss the criteria that need to be
satisfied to realize this paradigm, and provide an example showing the solution
of the shortest-path problem and demonstrate the healing property of the
solution path.
</summary>
    <author>
      <name>M. Di Ventra</name>
    </author>
    <author>
      <name>Y. V. Pershin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/nphys2566</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/nphys2566" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first part of this paper has been published in Nature Physics 9,
  200-202 (2013). The second part has been expanded and is now included in
  arXiv:1304.1675</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature Physics 9, 200-202 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4487v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4487v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0668v1</id>
    <updated>2011-03-03T12:37:57Z</updated>
    <published>2011-03-03T12:37:57Z</published>
    <title>Spike Onset Dynamics and Response Speed in Neuronal Populations</title>
    <summary>  Recent studies of cortical neurons driven by fluctuating currents revealed
cutoff frequencies for action potential encoding of several hundred Hz.
Theoretical studies of biophysical neuron models have predicted a much lower
cutoff frequency of the order of average firing rate or the inverse membrane
time constant. The biophysical origin of the observed high cutoff frequencies
is thus not well understood. Here we introduce a neuron model with dynamical
action potential generation, in which the linear response can be analytically
calculated for uncorrelated synaptic noise. We find that the cutoff frequencies
increase to very large values when the time scale of action potential
initiation becomes short.
</summary>
    <author>
      <name>Wei Wei</name>
    </author>
    <author>
      <name>Fred Wolf</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. Lett. 106, 088102 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1865v1</id>
    <updated>2012-06-08T20:09:44Z</updated>
    <published>2012-06-08T20:09:44Z</published>
    <title>Frequency decoding of periodically timed action potentials through
  distinct activity patterns in a random neural network</title>
    <summary>  Frequency discrimination is a fundamental task of the auditory system. The
mammalian inner ear, or cochlea, provides a place code in which different
frequencies are detected at different spatial locations. However, a temporal
code based on spike timing is also available: action potentials evoked in an
auditory-nerve fiber by a low-frequency tone occur at a preferred phase of the
stimulus-they exhibit phase locking-and thus provide temporal information about
the tone's frequency. In an accompanying psychoacoustic study, and in agreement
with previous experiments, we show that humans employ this temporal information
for discrimination of low frequencies. How might such temporal information be
read out in the brain? Here we demonstrate that recurrent random neural
networks in which connections between neurons introduce characteristic time
delays, and in which neurons require temporally coinciding inputs for spike
initiation, can perform sharp frequency discrimination when stimulated with
phase-locked inputs. Although the frequency resolution achieved by such
networks is limited by the noise in phase locking, the resolution for realistic
values reaches the tiny frequency difference of 0.2% that has been measured in
humans.
</summary>
    <author>
      <name>Tobias Reichenbach</name>
    </author>
    <author>
      <name>A. J. Hudspeth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures, and supplementary information</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1864v1</id>
    <updated>2012-06-08T20:07:16Z</updated>
    <published>2012-06-08T20:07:16Z</published>
    <title>Discrimination of low-frequency tones employs temporal fine structure</title>
    <summary>  An auditory neuron can preserve the temporal fine structure of a
low-frequency tone by phase-locking its response to the stimulus. Apart from
sound localization, however, little is known about the role of this temporal
information for signal processing in the brain. Through psychoacoustic studies
we provide direct evidence that humans employ temporal fine structure to
discriminate between frequencies. To this end we construct tones that are based
on a single frequency but in which, through the concatenation of wavelets, the
phase changes randomly every few cycles. We then test the frequency
discrimination of these phase-changing tones, of control tones without phase
changes, and of short tones that consist of a single wavelets. For carrier
frequencies below a few kilohertz we find that phase changes systematically
worsen frequency discrimination. No such effect appears for higher carrier
frequencies at which temporal information is not available in the central
auditory system.
</summary>
    <author>
      <name>Tobias Reichenbach</name>
    </author>
    <author>
      <name>A. J. Hudspeth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0045579</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0045579" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 7, e45579 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.1864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0628v1</id>
    <updated>2012-11-03T18:20:20Z</updated>
    <published>2012-11-03T18:20:20Z</published>
    <title>Transient localized wave patterns and their application to migraine</title>
    <summary>  Transient dynamics is pervasive in the human brain and poses challenging
problems both in mathematical tractability and clinical observability. We
investigate statistical properties of transient cortical wave patterns with
characteristic forms (shape, size, duration) in a canonical reaction-diffusion
model with mean field inhibition. The patterns are formed by a ghost near a
saddle-node bifurcation in which a stable traveling wave (node) collides with
its critical nucleation mass (saddle). Similar patterns have been observed with
fMRI in migraine. Our results support the controversial idea that waves of
cortical spreading depression (SD) have a causal relationship with the headache
phase in migraine and therefore occur not only in migraine with aura (MA) but
also in migraine without aura (MO), i.e., in the two major migraine subforms.
We suggest a congruence between the prevalence of MO and MA with the
statistical properties of the traveling waves' forms, according to which (i)
activation of nociceptive mechanisms relevant for headache is dependent upon a
sufficiently large instantaneous affected cortical area anti-correlated to both
SD duration and total affected cortical area such that headache would be less
severe in MA than in MO (ii) the incidence of MA is reflected in the distance
to the saddle-node bifurcation, and (iii) the contested notion of MO attacks
with silent aura is resolved. We briefly discuss model-based control and means
by which neuromodulation techniques may affect pathways of pain formation.
</summary>
    <author>
      <name>Markus A Dahlem</name>
    </author>
    <author>
      <name>Thomas M Isele</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0025v1</id>
    <updated>2011-03-31T20:35:44Z</updated>
    <published>2011-03-31T20:35:44Z</published>
    <title>Information content of colored motifs in complex networks</title>
    <summary>  We study complex networks in which the nodes of the network are tagged with
different colors depending on the functionality of the nodes (colored graphs),
using information theory applied to the distribution of motifs in such
networks. We find that colored motifs can be viewed as the building blocks of
the networks (much more so than the uncolored structural motifs can be) and
that the relative frequency with which these motifs appear in the network can
be used to define the information content of the network. This information is
defined in such a way that a network with random coloration (but keeping the
relative number of nodes with different colors the same) has zero color
information content. Thus, colored motif information captures the
exceptionality of coloring in the motifs that is maintained via selection. We
study the motif information content of the C. elegans brain as well as the
evolution of colored motif information in networks that reflect the interaction
between instructions in genomes of digital life organisms. While we find that
colored motif information appears to capture essential functionality in the C.
elegans brain (where the color assignment of nodes is straightforward) it is
not obvious whether the colored motif information content always increases
during evolution, as would be expected from a measure that captures network
complexity. For a single choice of color assignment of instructions in the
digital life form Avida, we find rather that colored motif information content
increases or decreases during evolution, depending on how the genomes are
organized, and therefore could be an interesting tool to dissect genomic
rearrangements.
</summary>
    <author>
      <name>Christoph Adami</name>
    </author>
    <author>
      <name>Jifeng Qian</name>
    </author>
    <author>
      <name>Matthew Rupp</name>
    </author>
    <author>
      <name>Arend Hintze</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/artl_a_00045</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/artl_a_00045" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 8 figures, to appear in Artificial Life</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Artificial Life 17 (2011) 375-390</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0388v1</id>
    <updated>2011-11-02T05:04:06Z</updated>
    <published>2011-11-02T05:04:06Z</published>
    <title>Influence of Alcohol Smell and Imagination on the Condition of the Human
  Organism and Subjective Human Experience</title>
    <summary>  In this study, alcohol smell and imagination of alcohol has been shown to
change the condition of a human organism.In this study, alcohol smell has been
shown to change the condition of a human organism. Based on the test results,
the presence of alcohol was observed upon breathing out, but was rarely
observed in spits and much rarer in urines. This effect is most evident shortly
after an olfactory perception of alcohol and continues for 60 min for some test
persons. The test persons also noted the appearance of a subjective feeling of
alcohol intoxication. However, the condition developed when the alcohol smell
perception differed from the classical alcohol intoxication, i.e., the test
subjects only have a few intoxication symptoms, and not one person would have
all of them.
</summary>
    <author>
      <name>Tatiana Berezina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Table</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.0388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3270v1</id>
    <updated>2012-04-15T13:59:36Z</updated>
    <published>2012-04-15T13:59:36Z</published>
    <title>Quantifying impacts of short-term plasticity on neuronal information
  transfer</title>
    <summary>  Short-term changes in efficacy have been postulated to enhance the ability of
synapses to transmit information between neurons, and within neuronal networks.
Even at the level of connections between single neurons, direct confirmation of
this simple conjecture has proven elusive. By combining paired-cell recordings,
realistic synaptic modelling and information theory, we provide evidence that
short-term plasticity can not only improve, but also reduce information
transfer between neurons. We focus on a concrete example in rat neocortex, but
our results may generalise to other systems. When information is contained in
the timings of individual spikes, we find that facilitation, depression and
recovery affect information transmission in proportion to their impacts upon
the probability of neurotransmitter release. When information is instead
conveyed by mean spike rate only, the influences of short-term plasticity
critically depend on the range of spike frequencies that the target network can
distinguish (its effective dynamic range). Our results suggest that to
efficiently transmit information, the brain must match synaptic type, coding
strategy and network connectivity during development and behaviour.
</summary>
    <author>
      <name>Pat Scott</name>
    </author>
    <author>
      <name>Anna I. Cowan</name>
    </author>
    <author>
      <name>Christian Stricker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.85.041921</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.85.041921" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Phys Rev E. 42 pages in referee format, 9
  figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 85, 041921 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1105v2</id>
    <updated>2012-03-14T13:49:43Z</updated>
    <published>2011-06-06T16:01:10Z</published>
    <title>Naturally Supervised Learning in Manipulable Technologies</title>
    <summary>  The relationship between physiological systems and modern electromechanical
technologies is fast becoming intimate with high degrees of complex
interaction. It can be argued that muscular function, limb movements, and touch
perception serve supervisory functions for movement control in motion and
touch-based (e.g. manipulable) devices/interfaces and human-machine interfaces
in general. To get at this hypothesis requires the use of novel techniques and
analyses which demonstrate the multifaceted and regulatory role of adaptive
physiological processes in these interactions. Neuromechanics is an approach
that unifies the role of physiological function, motor performance, and
environmental effects in determining human performance. A neuromechanical
perspective will be used to explain the effect of environmental fluctuations on
supervisory mechanisms, which leads to adaptive physiological responses. Three
experiments are presented using two different types of virtual environment that
allowed for selective switching between two sets of environmental forces. This
switching was done in various ways to maximize the variety of results.
Electromyography (EMG) and kinematic information contributed to the development
of human performance-related measures. Both descriptive and specialized
analyses were conducted: peak amplitude analysis, loop trace analysis, and the
analysis of unmatched muscle power. Results presented here provide a window
into performance under a range of conditions. These analyses also demonstrated
myriad consequences for force-related fluctuations on dynamic physiological
regulation. The findings presented here could be applied to the dynamic control
of touch-based and movement-sensitive human-machine systems. In particular, the
design of systems such as human-robotic systems, touch screen devices, and
rehabilitative technologies could benefit from this research.
</summary>
    <author>
      <name>Bradly Alicea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 12 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.1105v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1105v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3443v1</id>
    <updated>2011-07-18T14:14:09Z</updated>
    <published>2011-07-18T14:14:09Z</published>
    <title>Quantitative aspects of L-type calcium currents</title>
    <summary>  Calcium currents in neurons and muscle cells have been classified as being
one of 5 types of which four, L, N, P/Q and R were said to be high threshold
and one, T, was designated low threshold. This review focuses on quantitative
aspects of L-type currents. L-type channels are now distinguished according to
their structure as one of four main subtypes 1.1-1.4. L-type calcium currents
play many fundamental roles in cellular dynamical processes including
pacemaking in neurons and cardiac cells, the activation of transcription
factors involved in synaptic plasticity and in immune cells. The
half-activation potentials of L-type currents have been ascribed values as low
as -50 mV and as high as near 0 mV. The inactivation of I_L has been found to
be both voltage (VDI) and calcium-dependent (CDI) and the latter component may
involve calcium-induced calcium release. CDI is often an important aspect of
dynamical models of cell electrophysiology. We describe the basic components in
modeling I_L including activation and both voltage and calcium dependent
inactivation and the two main approaches to determining the current. We review,
by means of tables of values from over 65 representative studies, the various
details of the dynamical properties associated with I_L that have been found
experimentally or employed in the last 25 years in deterministic modeling in
various nervous system and cardiac cells. Distributions and statistics of
several parameters related to activation and inactivation are obtained. There
are few reliable experimental data on L-type calcium current kinetics for cells
at physiological calcium ion concentrations. Neurons are divided approximately
into two groups with experimental half-activation potentials.
</summary>
    <author>
      <name>Henry C Tuckwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">92 pages 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2265v1</id>
    <updated>2011-06-11T22:42:33Z</updated>
    <published>2011-06-11T22:42:33Z</published>
    <title>If Experts Converge on the Same Answer are they Less Creative than
  Beginners? Redefining Creativity in Terms of Adaptive Landscapes</title>
    <summary>  The standard view that creativity entails both originality and
appropriateness leads to the paradox that experts who converge on one optimal
solution are rated as no more creative than beginners who give many original
solutions. This paper asserts that there is no one-size-fits-all definition of
creativity; creativity must be assessed relative to the constraints and
affordances of the task. The flatter the adaptive landscape associated with the
task, the greater the extent to which creativity is a function of originality
only. For tasks with a single-peaked adaptive landscape, there is a tradeoff
between originality and appropriateness. Only for tasks with rugged adaptive
landscapes is creativity positively correlated with both originality and
appropriateness. It is suggested that the adaptive landscapes associated with
artistic and scientific pursuits are equally rugged, but for artistic pursuits
their topologies reflect idiosyncratic experiences and emotions (the peaks and
valleys are not aligned).
</summary>
    <author>
      <name>Liane Gabora</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages; 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0738v4</id>
    <updated>2012-07-15T12:54:06Z</updated>
    <published>2012-03-04T13:16:19Z</published>
    <title>Avalanche analysis from multi-electrode ensemble recordings in cat,
  monkey and human cerebral cortex during wakefulness and sleep</title>
    <summary>  Self-organized critical states are found in many natural systems, from
earthquakes to forest fires, they have also been observed in neural systems,
particularly, in neuronal cultures. However, the presence of critical states in
the awake brain remains controversial. Here, we compared avalanche analyses
performed on different in vivo preparations during wakefulness, slow-wave sleep
and REM sleep, using high-density electrode arrays in cat motor cortex (96
electrodes), monkey motor cortex and premotor cortex and human temporal cortex
(96 electrodes) in epileptic patients. In neuronal avalanches defined from
units (up to 160 single units), the size of avalanches never clearly scaled as
power-law, but rather scaled exponentially or displayed intermediate scaling.
We also analyzed the dynamics of local field potentials (LFPs) and in
particular LFP negative peaks (nLFPs) among the different electrodes (up to 96
sites in temporal cortex or up to 128 sites in adjacent motor and pre-motor
cortices). In this case, the avalanches defined from nLFPs displayed power-law
scaling in double log representations, as reported previously in monkey.
However, avalanche defined as positive LFP (pLFP) peaks, which are less
directly related to neuronal firing, also displayed apparent power-law scaling.
Closer examination of this scaling using more reliable cumulative distribution
functions (CDF) and other rigorous statistical measures, did not confirm
power-law scaling. The same pattern was seen for cats, monkey and human, as
well as for different brain states of wakefulness and sleep. We also tested
other alternative distributions. Multiple exponential fitting yielded optimal
fits of the avalanche dynamics with bi-exponential distributions. Collectively,
these results show no clear evidence for power-law scaling or self-organized
critical states in the awake and sleeping brain of mammals, from cat to man.
</summary>
    <author>
      <name>Nima Dehghani</name>
    </author>
    <author>
      <name>Nicholas G. Hatsopoulos</name>
    </author>
    <author>
      <name>Zach D. Haga</name>
    </author>
    <author>
      <name>Rebecca A. Parker</name>
    </author>
    <author>
      <name>Bradley Greger</name>
    </author>
    <author>
      <name>Eric Halgren</name>
    </author>
    <author>
      <name>Sydney S. Cash</name>
    </author>
    <author>
      <name>Alain Destexhe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In press in: Frontiers in Physiology, 2012, special issue "Critical
  Brain Dynamics" (Edited by He BY, Daffertshofer A, Boonstra TW); 33 pages, 13
  figures. 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers in Physiology 3: 302, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0738v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0738v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5721v2</id>
    <updated>2012-02-17T20:18:44Z</updated>
    <published>2012-01-27T08:37:14Z</published>
    <title>Short-term synaptic facilitation improves information retrieval in noisy
  neural networks</title>
    <summary>  Short-term synaptic depression and facilitation have been found to greatly
influence the performance of autoassociative neural networks. However, only
partial results, focused for instance on the computation of the maximum storage
capacity at zero temperature, have been obtained to date. In this work, we
extended the study of the effect of these synaptic mechanisms on
autoassociative neural networks to more realistic and general conditions,
including the presence of noise in the system. In particular, we characterized
the behavior of the system by means of its phase diagrams, and we concluded
that synaptic facilitation significantly enlarges the region of good retrieval
performance of the network. We also found that networks with facilitating
synapses may have critical temperatures substantially higher than those of
standard autoassociative networks, thus allowing neural networks to perform
better under high-noise conditions.
</summary>
    <author>
      <name>J. F. Mejias</name>
    </author>
    <author>
      <name>B. Hernandez-Gomez</name>
    </author>
    <author>
      <name>J. J. Torres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, to appear in EPL</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.5721v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5721v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3354v1</id>
    <updated>2012-08-16T12:32:52Z</updated>
    <published>2012-08-16T12:32:52Z</published>
    <title>States of Enhanced Activity in a Network of Pulse Coupled Oscillators
  with Dynamic Coupling</title>
    <summary>  We investigate states of enhanced activity in a biological neuronal network
composed of pulse-coupled oscillators. The synaptic couplings between the
neurons are dynamic, modeling spike time dependent plasticity. The network
exhibits statistical characteristics which recently have been identified in an
analysis of epileptic seizures [Osorio et al., Phys. Rev. E 82, 021919(2010)]
based on analogies to the onset of earth quakes.
</summary>
    <author>
      <name>Daniel Ritterskamp</name>
    </author>
    <author>
      <name>Rudolf Friedrich</name>
    </author>
    <link href="http://arxiv.org/abs/1208.3354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.6568v1</id>
    <updated>2011-10-29T23:35:37Z</updated>
    <published>2011-10-29T23:35:37Z</published>
    <title>Strange Nonchaotic Bursting in A Quasiperiodially-Forced Hindmarsh-Rose
  Neuron</title>
    <summary>  We study the transition from a silent state to a bursting state by varying
the dc stimulus in the Hindmarsh-Rose neuron under quasiperiodic stimulation.
For this quasiperiodically forced case, a new type of strange nonchaotic (SN)
bursting state is found to occur between the silent state and the chaotic
bursting state. This is in contrast to the periodically forced case where the
silent state transforms directly to a chaotic bursting state. Using a rational
approximation to the quasiperiodic forcing, the mechanism for the appearance of
such an SN bursting state is investigated. Thus, a smooth torus (corresponding
to a silent state) is found to transform to an SN bursting attractor through a
phase-dependent subcritical period-doubling bifurcation. These SN bursting
states, together with chaotic bursting states, are characterized in terms of
the interburst interval, the bursting length, and the number of spikes in each
burst. Both bursting states are found to be aperiodic complex ones.
Consequently, aperiodic complex burstings may result from two dynamically
different states with strange geometry (one is chaotic and the other one is
nonchaotic). Thus, in addition to chaotic burstings, SN burstings may become a
dynamical origin for complex physiological rhythms which are ubiquitous in
organisms.
</summary>
    <author>
      <name>Woochang Lim</name>
    </author>
    <author>
      <name>Sang-Yoon Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3938/jkps57.1356</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3938/jkps57.1356" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Korean Phys. Soc. 57, 1356 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.6568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.6568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2816v1</id>
    <updated>2012-07-12T00:30:41Z</updated>
    <published>2012-07-12T00:30:41Z</published>
    <title>Formation of feedforward networks and frequency synchrony by
  spike-timing-dependent plasticity</title>
    <summary>  Spike-timing-dependent plasticity (STDP) with asymmetric learning windows is
commonly found in the brain and useful for a variety of spike-based
computations such as input filtering and associative memory. A natural
consequence of STDP is establishment of causality in the sense that a neuron
learns to fire with a lag after specific presynaptic neurons have fired. The
effect of STDP on synchrony is elusive because spike synchrony implies unitary
spike events of different neurons rather than a causal delayed relationship
between neurons. We explore how synchrony can be facilitated by STDP in
oscillator networks with a pacemaker. We show that STDP with asymmetric
learning windows leads to self-organization of feedforward networks starting
from the pacemaker. As a result, STDP drastically facilitates frequency
synchrony. Even though differences in spike times are lessened as a result of
synaptic plasticity, the finite time lag remains so that perfect spike
synchrony is not realized. In contrast to traditional mechanisms of large-scale
synchrony based on mutual interaction of coupled neurons, the route to
synchrony discovered here is enslavement of downstream neurons by upstream
ones. Facilitation of such feedforward synchrony does not occur for STDP with
symmetric learning windows.
</summary>
    <author>
      <name>Naoki Masuda</name>
    </author>
    <author>
      <name>Hiroshi Kori</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10827-007-0022-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10827-007-0022-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Neuroscience, 22, 327-345 (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.2816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5348v1</id>
    <updated>2012-10-19T09:07:33Z</updated>
    <published>2012-10-19T09:07:33Z</published>
    <title>Operational Design Considerations for Retinal Prostheses</title>
    <summary>  Three critical improvements for present day and future retinal vision
implants are proposed and discussed: (1) A time profile for the stimulation
current that leads predominantly to transverse stimulation of nerve cells; (2)
auxiliary electric currents for electric field shaping with a time profile
chosen such that these currents have small probability to cause stimulation;
and (3) a local area scanning procedure that results in high pixel density for
image/percept formation (except for losses at the boundary of an electrode
array).
</summary>
    <author>
      <name>Erich W. Schmid</name>
    </author>
    <author>
      <name>Wolfgang Fink</name>
    </author>
    <link href="http://arxiv.org/abs/1210.5348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4695v1</id>
    <updated>2012-10-17T11:12:02Z</updated>
    <published>2012-10-17T11:12:02Z</published>
    <title>Regulating the information in spikes: a useful bias</title>
    <summary>  The bias/variance tradeoff is fundamental to learning: increasing a model's
complexity can improve its fit on training data, but potentially worsens
performance on future samples. Remarkably, however, the human brain
effortlessly handles a wide-range of complex pattern recognition tasks. On the
basis of these conflicting observations, it has been argued that useful biases
in the form of "generic mechanisms for representation" must be hardwired into
cortex (Geman et al).
  This note describes a useful bias that encourages cooperative learning which
is both biologically plausible and rigorously justified.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2012 workshop on Information in Perception and Action</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.4695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4812v2</id>
    <updated>2013-06-11T16:11:01Z</updated>
    <published>2012-06-21T09:13:39Z</published>
    <title>A biological gradient descent for prediction through a combination of
  STDP and homeostatic plasticity</title>
    <summary>  Identifying, formalizing and combining biological mechanisms which implement
known brain functions, such as prediction, is a main aspect of current research
in theoretical neuroscience. In this letter, the mechanisms of Spike Timing
Dependent Plasticity (STDP) and homeostatic plasticity, combined in an original
mathematical formalism, are shown to shape recurrent neural networks into
predictors. Following a rigorous mathematical treatment, we prove that they
implement the online gradient descent of a distance between the network
activity and its stimuli. The convergence to an equilibrium, where the network
can spontaneously reproduce or predict its stimuli, does not suffer from
bifurcation issues usually encountered in learning in recurrent neural
networks.
</summary>
    <author>
      <name>Mathieu Galtier</name>
    </author>
    <author>
      <name>Gilles Wainrib</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4812v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4812v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.0817v1</id>
    <updated>2011-02-04T00:27:48Z</updated>
    <published>2011-02-04T00:27:48Z</published>
    <title>Natural images from the birthplace of the human eye</title>
    <summary>  Here we introduce a database of calibrated natural images publicly available
through an easy-to-use web interface. Using a Nikon D70 digital SLR camera, we
acquired about 5000 six-megapixel images of Okavango Delta of Botswana, a
tropical savanna habitat similar to where the human eye is thought to have
evolved. Some sequences of images were captured unsystematically while
following a baboon troop, while others were designed to vary a single parameter
such as aperture, object distance, time of day or position on the horizon.
Images are available in the raw RGB format and in grayscale. Images are also
available in units relevant to the physiology of human cone photoreceptors,
where pixel values represent the expected number of photoisomerizations per
second for cones sensitive to long (L), medium (M) and short (S) wavelengths.
This database is distributed under a Creative Commons Attribution-Noncommercial
Unported license to facilitate research in computer vision, psychophysics of
perception, and visual neuroscience.
</summary>
    <author>
      <name>Gašper Tkačik</name>
    </author>
    <author>
      <name>Patrick Garrigan</name>
    </author>
    <author>
      <name>Charles Ratliff</name>
    </author>
    <author>
      <name>Grega Milčinski</name>
    </author>
    <author>
      <name>Jennifer M Klein</name>
    </author>
    <author>
      <name>Lucia H Seyfarth</name>
    </author>
    <author>
      <name>Peter Sterling</name>
    </author>
    <author>
      <name>David Brainard</name>
    </author>
    <author>
      <name>Vijay Balasubramanian</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0020409</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0020409" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to PLoS ONE</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 6: e20409 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.0817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.0817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.6074v3</id>
    <updated>2012-12-18T06:40:52Z</updated>
    <published>2011-01-31T20:39:44Z</published>
    <title>Reverse engineering of complex dynamical networks in the presence of
  time-delayed interactions based on noisy time series</title>
    <summary>  Reverse engineering of complex dynamical networks is important for a variety
of fields where uncovering the full topology of unknown networks and estimating
parameters characterizing the network structure and dynamical processes are of
interest. We consider complex oscillator networks with time-delayed
interactions in a noisy environment, and develop an effective method to infer
the full topology of the network and evaluate the amount of time delay based
solely on noise- contaminated time series. In particular, we develop an
analytic theory establishing that the dynamical correlation matrix, which can
be constructed purely from time series, can be manipulated to yield both the
network topology and the amount of time delay simultaneously. Extensive
numerical support is provided to validate the method. While our method provides
a viable solution to the network inverse problem, significant difficulties,
limitations, and challenges still remain, and these are discussed thoroughly.
</summary>
    <author>
      <name>Wen-Xu Wang</name>
    </author>
    <author>
      <name>Jie Ren</name>
    </author>
    <author>
      <name>Ying-Cheng Lai</name>
    </author>
    <author>
      <name>Baowen Li</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4747708</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4747708" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. The formal published version is referred to
  http://chaos.aip.org/resource/1/chaoeh/v22/i3/p033131_s1?ver=pdfcov&amp;bypassSSO=1</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 22, 033131 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.6074v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.6074v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0866v3</id>
    <updated>2012-03-12T13:45:18Z</updated>
    <published>2011-05-04T16:33:28Z</published>
    <title>A Mathematical Model of Tripartite Synapse: Astrocyte Induced Synaptic
  Plasticity</title>
    <summary>  In this paper we present a biologically detailed mathematical model of
tripartite synapses, where astrocytes modulate short-term synaptic plasticity.
The model consists of a pre-synaptic bouton, a post-synaptic dendritic
spine-head, a synaptic cleft and a peri-synaptic astrocyte controlling Ca2+
dynamics inside the synaptic bouton. This in turn controls glutamate release
dynamics in the cleft. As a consequence of this, glutamate concentration in the
cleft has been modeled, in which glutamate reuptake by astrocytes has also been
incorporated. Finally, dendritic spine-head dynamics has been modeled. As an
application, this model clearly shows synaptic potentiation in the hippocampal
region, i.e., astrocyte Ca2+ mediates synaptic plasticity, which is in
conformity with the majority of the recent findings (Perea &amp; Araque, 2007;
Henneberger et al., 2010; Navarrete et al., 2012).
</summary>
    <author>
      <name>Shivendra Tewari</name>
    </author>
    <author>
      <name>Kaushik Majumdar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10867-012-9267-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10867-012-9267-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 14 figures, Journal of Biological Physics (to appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0866v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0866v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C20, 65C40, 92C05, 92C20, 92C37" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2012v1</id>
    <updated>2012-05-09T15:19:49Z</updated>
    <published>2012-05-09T15:19:49Z</published>
    <title>The effect of temporal pattern of injury on disability in learning
  networks</title>
    <summary>  How networks endure damage is a central issue in neural network research.
This includes temporal as well as spatial pattern of damage. Here, based on
some very simple models we study the difference between a slow-growing and
acute damage and the relation between the size and rate of injury. Our result
shows that in both a three-layer and a homeostasis model a slow-growing damage
has a decreasing effect on network disability as compared with a fast growing
one. This finding is in accord with clinical reports where the state of
patients before and after the operation for slow-growing injuries is much
better that those patients with acute injuries.
</summary>
    <author>
      <name>Mohammadkarim Saeedghalati</name>
    </author>
    <author>
      <name>Abdolhossein Abbassian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Latex, 17 pages, 7 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2928v1</id>
    <updated>2012-07-12T11:33:19Z</updated>
    <published>2012-07-12T11:33:19Z</published>
    <title>Self-organized stochastic tipping in slow-fast dynamical systems</title>
    <summary>  Polyhomeostatic adaption occurs when evolving systems try to achieve a target
distribution function for certain dynamical parameters, a generalization of the
notion of homeostasis. Here we consider a single rate encoding leaky integrator
neuron model driven by white noise, adapting slowly its internal parameters,
the threshold and the gain, in order to achieve a given target distribution for
its time-average firing rate. For the case of sparse encoding, when the target
firing-rated distribution is bimodal, we observe the occurrence of spontaneous
quasi-periodic adaptive oscillations resulting from fast transition between two
quasi-stationary attractors. We interpret this behavior as self-organized
stochastic tipping, with noise driving the escape from the quasi-stationary
attractors.
</summary>
    <author>
      <name>Mathias Linkerhand</name>
    </author>
    <author>
      <name>Claudius Gros</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics and Mechanics of Complex Systems, Vol 1, 129 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.2928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2630v3</id>
    <updated>2012-01-19T20:46:53Z</updated>
    <published>2011-12-12T17:19:26Z</published>
    <title>Generalized Functions &amp; Experimental Methods of Obtaining Statistical
  Variable-Quantities Which Fully Determine Preferences in Choice-Rich
  Environments</title>
    <summary>  Preferences of individuals are distributions of elements generated by
generalized functions. Models of economic decision-making derived from such
distributions are consistent with results of physiological experiments, and
explain any behavioral situations without simplifying assumptions. Quantities
in such models precisely correspond to experimentally obtainable physiological
observables which determine statistical properties of central nervous system as
it represents different stimuli. Graphical method of consistently and
quantitatively at-a-glance interpreting or visualizing physiological data
within context of economic models is demonstrated.
</summary>
    <author>
      <name>Leonid A. Shapiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 1 figures, Version 3 (January 19), Version 2 (December 31),
  Version 1 (December 12), in review process</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2630v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2630v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3539v1</id>
    <updated>2012-02-16T09:23:15Z</updated>
    <published>2012-02-16T09:23:15Z</published>
    <title>Multiple firing coherence resonances in excitatory and inhibitory
  coupled neurons</title>
    <summary>  The impact of inhibitory and excitatory synapses in delay-coupled
Hodgkin--Huxley neurons that are driven by noise is studied. If both synaptic
types are used for coupling, appropriately tuned delays in the inhibition
feedback induce multiple firing coherence resonances at sufficiently strong
coupling strengths, thus giving rise to tongues of coherency in the
corresponding delay-strength parameter plane. If only inhibitory synapses are
used, however, appropriately tuned delays also give rise to multiresonant
responses, yet the successive delays warranting an optimal coherence of
excitations obey different relations with regards to the inherent time scales
of neuronal dynamics. This leads to denser coherence resonance patterns in the
delay-strength parameter plane. The robustness of these findings to the
introduction of delay in the excitatory feedback, to noise, and to the number
of coupled neurons is determined. Mechanisms underlying our observations are
revealed, and it is suggested that the regularity of spiking across neuronal
networks can be optimized in an unexpectedly rich variety of ways, depending on
the type of coupling and the duration of delays.
</summary>
    <author>
      <name>Qingyun Wang</name>
    </author>
    <author>
      <name>Honghui Zhang</name>
    </author>
    <author>
      <name>Matjaz Perc</name>
    </author>
    <author>
      <name>Guanrong Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cnsns.2012.02.019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cnsns.2012.02.019" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 two-column pages, 6 figures; accepted for publication in
  Communications in Nonlinear Science and Numerical Simulation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Commun. Nonlinear Sci. Numer. Simulat. 17 (2012) 3979-3988</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.3539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6027v1</id>
    <updated>2012-11-26T17:08:24Z</updated>
    <published>2012-11-26T17:08:24Z</published>
    <title>Influence of paroxysmal activity on background synchronization in
  epileptic records</title>
    <summary>  The presence of spikes and sharp waves in the recordings of epileptic
patients may contaminate background signal synchronization in different ways.
In this Technical Note, we present a simple procedure for assessing whether a
particular synchronization method should be used (or not) with data from
neurophysiological recordings commonly used to evaluate epilepsy. The
information provided by this procedure makes it possible to differentiate true
background synchronization from spike synchronization. This issue is
particularly relevant when differentiating between the mechanisms underlying
the onset of interictal epileptiform discharges and limbic network dynamics.
</summary>
    <author>
      <name>Jesús Pastor</name>
    </author>
    <author>
      <name>Guillermo Ortega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.6027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.5673v2</id>
    <updated>2013-01-31T13:19:52Z</updated>
    <published>2012-03-26T14:08:44Z</published>
    <title>The Effect of Nonstationarity on Models Inferred from Neural Data</title>
    <summary>  Neurons subject to a common non-stationary input may exhibit a correlated
firing behavior. Correlations in the statistics of neural spike trains also
arise as the effect of interaction between neurons. Here we show that these two
situations can be distinguished, with machine learning techniques, provided the
data are rich enough. In order to do this, we study the problem of inferring a
kinetic Ising model, stationary or nonstationary, from the available data. We
apply the inference procedure to two data sets: one from salamander retinal
ganglion cells and the other from a realistic computational cortical network
model. We show that many aspects of the concerted activity of the salamander
retinal neurons can be traced simply to the external input. A model of
non-interacting neurons subject to a non-stationary external field outperforms
a model with stationary input with couplings between neurons, even accounting
for the differences in the number of model parameters. When couplings are added
to the non-stationary model, for the retinal data, little is gained: the
inferred couplings are generally not significant. Likewise, the distribution of
the sizes of sets of neurons that spike simultaneously and the frequency of
spike patterns as function of their rank (Zipf plots) are well-explained by an
independent-neuron model with time-dependent external input, and adding
connections to such a model does not offer significant improvement. For the
cortical model data, robust couplings, well correlated with the real
connections, can be inferred using the non-stationary model. Adding connections
to this model slightly improves the agreement with the data for the probability
of synchronous spikes but hardly affects the Zipf plot.
</summary>
    <author>
      <name>Joanna Tyrcha</name>
    </author>
    <author>
      <name>Yasser Roudi</name>
    </author>
    <author>
      <name>Matteo Marsili</name>
    </author>
    <author>
      <name>John Hertz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">version in press in J Stat Mech</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.5673v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.5673v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0637v1</id>
    <updated>2012-06-04T14:50:03Z</updated>
    <published>2012-06-04T14:50:03Z</published>
    <title>A Quantum-mechanical description of ion motion within the confining
  potentials of voltage gated ion channels</title>
    <summary>  Voltage gated channel proteins cooperate in the transmission of membrane
potentials between nerve cells. With the recent progress in atomic-scaled
biological chemistry it has now become established that these channel proteins
provide highly correlated atomic environments that may maintain electronic
coherences even at warm temperatures. Here we demonstrate solutions of the
Schr\"{o}dinger equation that represent the interaction of a single potassium
ion within the surrounding carbonyl dipoles in the Berneche-Roux model of the
bacterial \textit{KcsA} model channel. We show that, depending on the
surrounding carbonyl derived potentials, alkali ions can become highly
delocalized in the filter region of proteins at warm temperatures. We provide
estimations about the temporal evolution of the kinetic energy of ions
depending on their interaction with other ions, their location within the
oxygen cage of the proteins filter region and depending on different
oscillation frequencies of the surrounding carbonyl groups. Our results provide
the first evidence that quantum mechanical properties are needed to explain a
fundamental biological property such as ion-selectivity in trans-membrane
ion-currents and the effect on gating kinetics and shaping of classical
conductances in electrically excitable cells.
</summary>
    <author>
      <name>Johann Summhammer</name>
    </author>
    <author>
      <name>Vahid Salari</name>
    </author>
    <author>
      <name>Gustav Bernroider</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0219635212500094</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0219635212500094" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Integrative Neuroscience 11, No.2 (2012), 123-135</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.0637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0324v1</id>
    <updated>2012-06-01T22:54:52Z</updated>
    <published>2012-06-01T22:54:52Z</published>
    <title>What does the Allen Gene Expression Atlas tell us about mouse brain
  evolution?</title>
    <summary>  We use the Allen Gene Expression Atlas (AGEA) and the OMA ortholog dataset to
investigate the evolution of mouse-brain neuroanatomy from the standpoint of
the molecular evolution of brain-specific genes. For each such gene, using the
phylogenetic tree for all fully sequenced species and the presence of orthologs
of the gene in these species, we construct and assign a discrete measure of
evolutionary age. The gene expression profile of all gene of similar age,
relative to the average gene expression profile, distinguish regions of the
brain that are over-represented in the corresponding evolutionary timescale. We
argue that the conclusions one can draw on evolution of twelve major brain
regions from such a molecular level analysis supplements existing knowledge of
mouse brain evolution and introduces new quantitative tools, especially for
comparative studies, when AGEA-like data sets for other species become
available. Using the functional role of the genes representational of a certain
evolutionary timescale and brain region we compare and contrast, wherever
possible, our observations with existing knowledge in evolutionary
neuroanatomy.
</summary>
    <author>
      <name>Swagatam Mukhopadhyay</name>
    </author>
    <author>
      <name>Pascal Grange</name>
    </author>
    <author>
      <name>Anirvan M. Sengupta</name>
    </author>
    <author>
      <name>Partha P. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0729v1</id>
    <updated>2012-09-04T18:50:51Z</updated>
    <published>2012-09-04T18:50:51Z</published>
    <title>Intra- and Inter-Frequency Brain Network Structure in Health and
  Schizophrenia</title>
    <summary>  Empirical studies over the past two decades have supported the hypothesis
that schizophrenia is characterized by altered connectivity patterns in
functional brain networks. These alterations have been proposed as
genetically-mediated diagnostic biomarkers and are thought to underlie altered
cognitive functions such as working memory. In this study, we perform an
extensive analysis of functional connectivity patterns extracted from MEG data
in 14 subjects with schizophrenia and 14 healthy controls during a 2-back
working memory task. We investigate uni-, bi- and multivariate properties of
sensor time series by computing wavelet entropy of and correlation between time
series, and by constructing binary networks of functional connectivity both
within and between classical frequency bands (gamma, beta, alpha, and theta).
Networks are based on the mutual information between wavelet time series, and
estimated for 66 separate time windows. We observed decreases in entropy in
prefrontal and lateral sensor time series and increases in connectivity
strength in the schizophrenia group in comparison to the healthy controls. We
identified an inverse relationship between entropy and strength across both
subjects and sensors that varied over frequency bands and was more pronounced
in controls than in patients. Brain network topology was altered in
schizophrenia specifically in high frequency gamma and beta band networks as
well as in the gamma-beta cross-frequency networks. Network topology varied
over trials to a greater extent in patients than in controls, suggesting
disease-associated alterations in dynamic network properties of brain function.
Our results identify signatures of aberrant neurophysiological behavior in
schizophrenia across uni-, bi- and multivariate scales and identify
cross-frequency network architecture and network dynamics as candidate
intermediate phenotypes.
</summary>
    <author>
      <name>Felix Siebenhuhner</name>
    </author>
    <author>
      <name>Shennan A. Weiss</name>
    </author>
    <author>
      <name>Richard Coppola</name>
    </author>
    <author>
      <name>Daniel R. Weinberger</name>
    </author>
    <author>
      <name>Danielle S. Bassett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 8 figures, 1 table, supplementary materials</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.0729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3364v1</id>
    <updated>2012-07-13T21:06:28Z</updated>
    <published>2012-07-13T21:06:28Z</published>
    <title>Speed and Accuracy of Static Image Discrimination by Rats</title>
    <summary>  When discriminating dynamic noisy sensory signals, human and primate subjects
achieve higher accuracy when they take more time to decide, an effect
attributed to accumulation of evidence over time to overcome neural noise. We
measured the speed and accuracy of twelve freely behaving rats discriminating
static, high contrast photographs of real-world objects for water reward in a
self-paced task. Response latency was longer in correct trials compared to
error trials. Discrimination accuracy increased with response latency over the
range of 500-1200ms. We used morphs between previously learned images to vary
the image similarity parametrically, and thereby modulate task difficulty from
ceiling to chance. Over this range we find that rats take more time before
responding in trials with more similar stimuli. We conclude that rats'
perceptual decisions improve with time even in the absence of temporal
information in the stimulus, and that rats modulate speed in response to
discrimination difficulty to balance speed and accuracy.
</summary>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <author>
      <name>Robert E Clark</name>
    </author>
    <link href="http://arxiv.org/abs/1207.3364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.6199v1</id>
    <updated>2012-01-30T12:43:26Z</updated>
    <published>2012-01-30T12:43:26Z</published>
    <title>Spontaneous formation of synchronization clusters in homogenous neuronal
  ensembles induced by noise and interaction delays</title>
    <summary>  Spontaneous formation of clusters of synchronized spiking in a structureless
ensemble of equal stochastically perturbed excitable neurons with delayed
coupling is demonstrated for the first time. The effect is a consequence of a
subtle interplay between interaction delays, noise and the excitable character
of a single neuron. Dependence of the cluster properties on the time-lag, noise
intensity and the synaptic strength is investigated.
</summary>
    <author>
      <name>Igor Franovic</name>
    </author>
    <author>
      <name>Kristina Todorovic</name>
    </author>
    <author>
      <name>Nebojsa Vasovic</name>
    </author>
    <author>
      <name>Nikola Buric</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.6199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.6199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3697v3</id>
    <updated>2012-08-03T20:13:55Z</updated>
    <published>2012-06-16T19:11:27Z</published>
    <title>Molecular Constraints on Synaptic Tagging and Maintenance of Long-Term
  Potentiation: A Predictive Model</title>
    <summary>  Protein synthesis-dependent, late long-term potentiation (LTP) and depression
(LTD) at glutamatergic hippocampal synapses are well characterized examples of
long-term synaptic plasticity. Persistent increased activity of the enzyme
protein kinase M (PKM) is thought essential for maintaining LTP. Additional
spatial and temporal features that govern LTP and LTD induction are embodied in
the synaptic tagging and capture (STC) and cross capture hypotheses. Only
synapses that have been "tagged" by an stimulus sufficient for LTP and learning
can "capture" PKM. A model was developed to simulate the dynamics of key
molecules required for LTP and LTD. The model concisely represents
relationships between tagging, capture, LTD, and LTP maintenance. The model
successfully simulated LTP maintained by persistent synaptic PKM, STC, LTD, and
cross capture, and makes testable predictions concerning the dynamics of PKM.
The maintenance of LTP, and consequently of at least some forms of long-term
memory, is predicted to require continual positive feedback in which PKM
enhances its own synthesis only at potentiated synapses. This feedback
underlies bistability in the activity of PKM. Second, cross capture requires
the induction of LTD to induce dendritic PKM synthesis, although this may
require tagging of a nearby synapse for LTP. The model also simulates the
effects of PKM inhibition, and makes additional predictions for the dynamics of
CaM kinases. Experiments testing the above predictions would significantly
advance the understanding of memory maintenance.
</summary>
    <author>
      <name>Paul Smolen</name>
    </author>
    <author>
      <name>Douglas A. Baxter</name>
    </author>
    <author>
      <name>John H. Byrne</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002620</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002620" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v3. Minor text edits to reflect published version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS Comput Biol 8(8): e1002620, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.3697v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3697v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.6352v1</id>
    <updated>2012-01-30T20:52:53Z</updated>
    <published>2012-01-30T20:52:53Z</published>
    <title>Homoclinic Orbits of the FitzHugh-Nagumo Equation: Bifurcations in the
  Full System</title>
    <summary>  This paper investigates travelling wave solutions of the FitzHugh-Nagumo
equation from the viewpoint of fast-slow dynamical systems. These solutions are
homoclinic orbits of a three dimensional vector field depending upon system
parameters of the FitzHugh-Nagumo model and the wave speed. Champneys et al.
[A.R. Champneys, V. Kirk, E. Knobloch, B.E. Oldeman, and J. Sneyd, When
Shilnikov meets Hopf in excitable systems, SIAM Journal of Applied Dynamical
Systems, 6(4), 2007] observed sharp turns in the curves of homoclinic
bifurcations in a two dimensional parameter space. This paper demonstrates
numerically that these turns are located close to the intersection of two
curves in the parameter space that locate non-transversal intersections of
invariant manifolds of the three dimensional vector field. The relevant
invariant manifolds in phase space are visualized. A geometrical model inspired
by the numerical studies displays the sharp turns of the homoclinic
bifurcations curves and yields quantitative predictions about multi-pulse and
homoclinic orbits and periodic orbits that have not been resolved in the
FitzHugh-Nagumo model. Further observations address the existence of canard
explosions and mixed-mode oscillations.
</summary>
    <author>
      <name>John Guckenheimer</name>
    </author>
    <author>
      <name>Christian Kuehn</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/090758404</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/090758404" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint version - for final version please see journal reference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Applied Dynamical Systems, Vol. 9, No. 1, pp.
  138-153, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.6352v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.6352v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6230v2</id>
    <updated>2012-10-25T13:55:10Z</updated>
    <published>2012-10-23T13:19:08Z</published>
    <title>A Self-Organized Neural Comparator</title>
    <summary>  Learning algorithms need generally the possibility to compare several streams
of information. Neural learning architectures hence need a unit, a comparator,
able to compare several inputs encoding either internal or external
information, like for instance predictions and sensory readings. Without the
possibility of comparing the values of prediction to actual sensory inputs,
reward evaluation and supervised learning would not be possible.
  Comparators are usually not implemented explicitly, necessary comparisons are
commonly performed by directly comparing one-to-one the respective activities.
This implies that the characteristics of the two input streams (like size and
encoding) must be provided at the time of designing the system.
  It is however plausible that biological comparators emerge from
self-organizing, genetically encoded principles, which allow the system to
adapt to the changes in the input and in the organism.
  We propose an unsupervised neural circuitry, where the function of input
comparison emerges via self-organization only from the interaction of the
system with the respective inputs, without external influence or supervision.
  The proposed neural comparator adapts, unsupervised, according to the
correlations present in the input streams. The system consists of a multilayer
feed-forward neural network which follows a local output minimization
(anti-Hebbian) rule for adaptation of the synaptic weights.
  The local output minimization allows the circuit to autonomously acquire the
capability of comparing the neural activities received from different neural
populations, which may differ in the size of the population and in the neural
encoding used. The comparator is able to compare objects never encountered
before in the sensory input streams and to evaluate a measure of their
similarity, even when differently encoded.
</summary>
    <author>
      <name>Guillermo A. Ludueña</name>
    </author>
    <author>
      <name>Claudius Gros</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00424</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00424" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">G. A. Ludue\~na and C. Gros, A self-organized neural comparator,
  Neural Computation, 25, pp 1006 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6230v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6230v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.1101v1</id>
    <updated>2011-02-05T20:59:45Z</updated>
    <published>2011-02-05T20:59:45Z</published>
    <title>Total variation regularization for fMRI-based prediction of behaviour</title>
    <summary>  While medical imaging typically provides massive amounts of data, the
extraction of relevant information for predictive diagnosis remains a difficult
challenge. Functional MRI (fMRI) data, that provide an indirect measure of
task-related or spontaneous neuronal activity, are classically analyzed in a
mass-univariate procedure yielding statistical parametric maps. This analysis
framework disregards some important principles of brain organization:
population coding, distributed and overlapping representations. Multivariate
pattern analysis, i.e., the prediction of behavioural variables from brain
activation patterns better captures this structure. To cope with the high
dimensionality of the data, the learning method has to be regularized. However,
the spatial structure of the image is not taken into account in standard
regularization methods, so that the extracted features are often hard to
interpret. More informative and interpretable results can be obtained with the
l_1 norm of the image gradient, a.k.a. its Total Variation (TV), as
regularization. We apply for the first time this method to fMRI data, and show
that TV regularization is well suited to the purpose of brain mapping while
being a powerful tool for brain decoding. Moreover, this article presents the
first use of TV regularization for classification.
</summary>
    <author>
      <name>Vincent Michel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Alexandre Gramfort</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Gaël Varoquaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, Parietal, LCogn</arxiv:affiliation>
    </author>
    <author>
      <name>Evelyn Eger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LCogn</arxiv:affiliation>
    </author>
    <author>
      <name>Bertrand Thirion</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LNAO, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMI.2011.2113378</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMI.2011.2113378" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Medical Imaging (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.1101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.1101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2250v2</id>
    <updated>2012-01-10T16:36:22Z</updated>
    <published>2011-06-11T15:49:44Z</published>
    <title>Synaptic potentiation facilitates memory-like attractor dynamics in
  cultured in vitro hippocampal networks</title>
    <summary>  Collective rhythmic dynamics from neurons is vital for cognitive functions
such as memory formation but how neurons self-organize to produce such activity
is not well understood. Attractor-based models have been successfully
implemented as a theoretical framework for memory storage in networks of
neurons. Activity-dependent modification of synaptic transmission is thought to
be the physiological basis of learning and memory. The goal of this study is to
demonstrate that using a pharmacological perturbation on in vitro networks of
hippocampal neurons that has been shown to increase synaptic strength follows
the dynamical postulates theorized by attractor models. We use a grid of
extracellular electrodes to study changes in network activity after this
perturbation and show that there is a persistent increase in overall spiking
and bursting activity after treatment. This increase in activity appears to
recruit more "errant" spikes into bursts. Lastly, phase plots indicate a
conserved activity pattern suggesting that the network is operating in a stable
dynamical state.
</summary>
    <author>
      <name>Mark Niedringhaus</name>
    </author>
    <author>
      <name>Xin Chen</name>
    </author>
    <author>
      <name>Katherine Conant</name>
    </author>
    <author>
      <name>Rhonda Dzakpasu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Niedringhaus M, Chen X, Conant K, Dzakpasu R (2013) Synaptic
  Potentiation Facilitates Memory-like Attractor Dynamics in Cultured In Vitro
  Hippocampal Networks. PLoS ONE 8(3): e57144</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.2250v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2250v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6189v1</id>
    <updated>2012-04-27T12:42:11Z</updated>
    <published>2012-04-27T12:42:11Z</published>
    <title>Which coordinate system for modelling path integration?</title>
    <summary>  Path integration is a navigation strategy widely observed in nature where an
animal maintains a running estimate of its location during an excursion.
Evidence suggests it is both ancient and ubiquitous in nature. Over the past
century or so, canonical and neural network models have flourished, based on a
wide range of assumptions, justifications and supporting data. Despite the
importance of the phenomenon, consensus and unifying principles appear lacking.
A fundamental issue is the neural representation of space needed for biological
path integration. This paper presents a scheme to classify path integration
systems on the basis of the way the home vector records and updates the spatial
relationship between the animal and its home location. Four extended classes of
coordinate systems are used to unify and review both canonical and neural
network models of path integration, from the arthropod and mammalian
literature. This scheme demonstrates analytical equivalence between models
which may otherwise appear unrelated, and distinguishes between models which
may superficially appear similar. A thorough analysis is carried out of the
equational forms of important facets of path integration including updating,
steering, searching and systematic errors, using each of the four coordinate
systems. The type of available directional cue, namely allothetic or
idiothetic, is also considered. It is shown that on balance, the class of home
vectors which includes the geocentric Cartesian coordinate system, appears to
be the most robust for biological systems. A key conclusion is that deducing
computational structure from behavioural data alone will be difficult or
impossible, at least in the absence of an analysis of random errors.
Consequently it is likely that further theoretical insights into path
integration will require an in-depth study of the effect of noise on the four
classes of home vectors.
</summary>
    <author>
      <name>Robert J. Vickerstaff</name>
    </author>
    <author>
      <name>Allen Cheung</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jtbi.2009.11.021</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jtbi.2009.11.021" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 8 figures, 7 tables. Contains one change compared to the
  published version: the reference to Fuhs &amp; Touretzky (2006) J. Neurosci. has
  been changed to Burak &amp; Fiete (2009) PLoS Comput. Biol</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Theor. Biol. 263, 242-261 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.6189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6286v4</id>
    <updated>2013-05-10T22:02:16Z</updated>
    <published>2012-06-25T21:02:44Z</published>
    <title>Influence of macrocolumnar EEG on Ca waves</title>
    <summary>  Macroscopic electroencephalographic (EEG) fields can be an explicit top-down
neocortical mechanism that directly drives bottom-up processes that describe
memory, attention, and other neuronal processes. The top-down mechanism
considered are macrocolumnar EEG firings in neocortex, as described by a
statistical mechanics of neocortical interactions (SMNI), developed as a
magnetic vector potential $\mathbf{A}$. The bottom-up process considered are
$\mathrm{Ca}^{2+}$ waves prominent in synaptic and extracellular processes that
are considered to greatly influence neuronal firings. Here, the complimentary
effects are considered, i.e., the influence of $\mathbf{A}$ on
$\mathrm{Ca}^{2+}$ momentum, $\mathbf{p}$. The canonical momentum of a charged
particle in an electromagnetic field, $\mathbf{\Pi} = \mathbf{p} + q
\mathbf{A}$ (SI units), is calculated, where the charge of $\mathrm{Ca}^{2+}$
is $q = - 2 e$, $e$ is the magnitude of the charge of an electron. Calculations
demonstrate that macroscopic EEG $\mathbf{A}$ can be quite influential on the
momentum $\mathbf{p}$ of $\mathrm{Ca}^{2+}$ ions, in both classical and quantum
mechanics. Molecular scales of $\mathrm{Ca}^{2+}$ wave dynamics are coupled
with $\mathbf{A}$ fields developed at macroscopic regional scales measured by
coherent neuronal firing activity measured by scalp EEG. The project has three
main aspects: fitting $\mathbf{A}$ models to EEG data as reported here,
building tripartite models to develop $\mathbf{A}$ models, and studying long
coherence times of $\mathrm{Ca}^{2+}$ waves in the presence of $\mathbf{A}$ due
to coherent neuronal firings measured by scalp EEG.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2012:CEEG. This paper has been superceded by the expanded paper
  "Electroencephalographic field influence on calcium momentum waves"
  arXiv:1105.2352</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Current Progress Journal 1 (1), 4-8 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.6286v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6286v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4223v2</id>
    <updated>2012-10-01T08:14:52Z</updated>
    <published>2012-09-19T12:19:31Z</published>
    <title>Evidence for early identification of Alzheimer's disease</title>
    <summary>  Alzheimer's disease is a human brain disease that affects a significant
fraction of the population by causing problems with short-term memory,
thinking, spatial orientation and behavior, memory loss and other intellectual
abilities. Up to date there is no singular test that can definitively diagnose
Alzheimer's disease, although imaging technology designed to detect Alzheimer's
plaques and tangles is rapidly becoming more powerful and precise. In this
paper we introduce a decision-making model, based on the combination of
mitochondrial hypothesis-dynamics with the role of electromagnetic influences
of the metal ions into the inner mitochondrial membrane and the quantitative
analysis of mitochondrial population. While there are few disappointing
clinical-trial results for drug treatments in patients with Alzheimer's
disease, scientific community need alternative diagnostic tools rather
investing mainly in amyloid-targeting drugs.
</summary>
    <author>
      <name>Athanasios Alexiou</name>
    </author>
    <author>
      <name>Panayiotis Vlamos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4223v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4223v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B, 92C05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1824v1</id>
    <updated>2011-04-11T01:17:01Z</updated>
    <published>2011-04-11T01:17:01Z</published>
    <title>Simulating Spiking Neural P systems without delays using GPUs</title>
    <summary>  We present in this paper our work regarding simulating a type of P system
known as a spiking neural P system (SNP system) using graphics processing units
(GPUs). GPUs, because of their architectural optimization for parallel
computations, are well-suited for highly parallelizable problems. Due to the
advent of general purpose GPU computing in recent years, GPUs are not limited
to graphics and video processing alone, but include computationally intensive
scientific and mathematical applications as well. Moreover P systems, including
SNP systems, are inherently and maximally parallel computing models whose
inspirations are taken from the functioning and dynamics of a living cell. In
particular, SNP systems try to give a modest but formal representation of a
special type of cell known as the neuron and their interactions with one
another. The nature of SNP systems allowed their representation as matrices,
which is a crucial step in simulating them on highly parallel devices such as
GPUs. The highly parallel nature of SNP systems necessitate the use of hardware
intended for parallel computations. The simulation algorithms, design
considerations, and implementation are presented. Finally, simulation results,
observations, and analyses using an SNP system that generates all numbers in
$\mathbb N$ - {1} are discussed, as well as recommendations for future work.
</summary>
    <author>
      <name>Francis Cabarle</name>
    </author>
    <author>
      <name>Henry Adorna</name>
    </author>
    <author>
      <name>Miguel A. Martinez-del-Amor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages in total, 4 figures, listings/algorithms, submitted at the
  9th Brainstorming Week in Membrane Computing, University of Seville, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q85" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3552v1</id>
    <updated>2012-01-17T16:37:38Z</updated>
    <published>2012-01-17T16:37:38Z</published>
    <title>Retinal adaptation and invariance to changes in higher-order stimulus
  statistics</title>
    <summary>  Adaptation in the retina is thought to optimize the encoding of natural light
signals into sequences of spikes sent to the brain. However, adaptation also
entails computational costs: adaptive code is intrinsically ambiguous, because
output symbols cannot be trivially mapped back to the stimuli without the
knowledge of the adaptive state of the encoding neuron. It is thus important to
learn which statistical changes in the input do, and which do not, invoke
adaptive responses, and ask about the reasons for potential limits to
adaptation. We measured the ganglion cell responses in the tiger salamander
retina to controlled changes in the second (contrast), third (skew) and fourth
(kurtosis) moments of the light intensity distribution of spatially uniform
temporally independent stimuli. The skew and kurtosis of the stimuli were
chosen to cover the range observed in natural scenes. We quantified adaptation
in ganglion cells by studying two-dimensional linear-nonlinear models that
capture well the retinal encoding properties across all stimuli. We found that
the retinal ganglion cells adapt to contrast, but exhibit remarkably invariant
behavior to changes in higher-order statistics. Finally, by theoretically
analyzing optimal coding in LN-type models, we showed that the neural code can
maintain a high information rate without dynamic adaptation despite changes in
stimulus skew and kurtosis.
</summary>
    <author>
      <name>Gašper Tkačik</name>
    </author>
    <author>
      <name>Anandamohan Ghosh</name>
    </author>
    <author>
      <name>Elad Schneidman</name>
    </author>
    <author>
      <name>Ronen Segev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0085841</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0085841" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLOS One 9 (2014): e85841</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.3552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1355v1</id>
    <updated>2011-04-07T15:23:24Z</updated>
    <published>2011-04-07T15:23:24Z</published>
    <title>Recursive Shortest Path Algorithm with Application to
  Density-integration of Weighted Graphs</title>
    <summary>  Graph theory is increasingly commonly utilised in genetics, proteomics and
neuroimaging. In such fields, the data of interest generally constitute
weighted graphs. Analysis of such weighted graphs often require the integration
of topological metrics with respect to the density of the graph. Here, density
refers to the proportion of the number of edges present in that graph. When
topological metrics based on shortest paths are of interest, such
density-integration usually necessitates the iterative application of
Dijkstra's algorithm in order to compute the shortest path matrix at each
density level. In this short note, we describe a recursive shortest path
algorithm based on single edge updating, which replaces the need for the
iterative use of Dijkstra's algorithm. Our proposed procedure is based on pairs
of breadth-first searches around each of the vertices incident to the edge
added at each recursion. An algorithmic analysis of the proposed technique is
provided. When the graph of interest is coded as an adjacency list, our
algorithm can be shown to be more efficient than an iterative use of Dijkstra's
algorithm.
</summary>
    <author>
      <name>Cedric E. Ginestet</name>
    </author>
    <author>
      <name>Andrew Simmons</name>
    </author>
    <link href="http://arxiv.org/abs/1104.1355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0309v1</id>
    <updated>2012-11-01T21:16:47Z</updated>
    <published>2012-11-01T21:16:47Z</published>
    <title>Brain complexity born out of criticality</title>
    <summary>  In this essay we elaborate on recent evidence demonstrating the presence of a
second order phase transition in human brain dynamics and discuss its
consequences for theoretical approaches to brain function. We review early
evidence of criticality in brain dynamics at different spatial and temporal
scales, and we stress how it was necessary to unify concepts and analysis
techniques across scales to introduce the adequate order and control parameters
which define the transition. A discussion on the relation between structural
vs. dynamical complexity exposes future steps to understand the dynamics of the
connectome (structure) from which emerges the cognitome (function).
</summary>
    <author>
      <name>Enzo Tagliazucchi</name>
    </author>
    <author>
      <name>Dante R. Chialvo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 12th Granada Seminar "Physics, Computation, and
  the Mind - Advances and Challenges at Interfaces-". (J. Marro, P. L. Garrido
  &amp; J. J. Torres, Eds.) American Institute of Physics (2012, in press)</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5674v2</id>
    <updated>2011-09-07T20:35:55Z</updated>
    <published>2011-04-29T16:32:00Z</published>
    <title>Using causal models to distinguish between neurogenesis-dependent and
  -independent effects on behaviour</title>
    <summary>  There has been a substantial amount of research on the relationship between
hippocampal neurogenesis and behaviour over the past fifteen years, but the
causal role that new neurons have on cognitive and affective behavioural tasks
is still far from clear. This is partly due to the difficulty of manipulating
levels of neurogenesis without inducing off-target effects, which might also
influence behaviour. In addition, the analytical methods typically used do not
directly test whether neurogenesis mediates the effect of an intervention on
behaviour. Previous studies may have incorrectly attributed changes in
behavioural performance to neurogenesis because the role of known (or unknown)
neurogenesis-independent mechanisms were not formally taken into consideration
during the analysis. Causal models can tease apart complex causal relationships
and were used to demonstrate that the effect of exercise on pattern separation
is via neurogenesis-independent mechanisms. Many studies in the neurogenesis
literature would benefit from the use of statistical methods that can separate
neurogenesis-dependent from neurogenesis-independent effects on behaviour.
</summary>
    <author>
      <name>Stanley E. Lazic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/?rsif.2011.0510</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/?rsif.2011.0510" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in the Journal of the Royal Society Interface</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.5674v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5674v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3433v2</id>
    <updated>2011-04-19T02:39:19Z</updated>
    <published>2011-04-18T11:10:58Z</published>
    <title>Spatiotemporal dynamics on small-world neuronal networks: The roles of
  two types of time-delayed coupling</title>
    <summary>  We investigate temporal coherence and spatial synchronization on small-world
networks consisting of noisy Terman-Wang (TW) excitable neurons in dependence
on two types of time-delayed coupling: $\{x_j(t-\tau)-x_i (t)\}$ and
$\{x_j(t-\tau)-x_i(t-\tau)\}$. For the former case, we show that time delay in
the coupling can dramatically enhance temporal coherence and spatial synchrony
of the noise-induced spike trains. In addition, if the delay time $\tau$ is
tuned to nearly match the intrinsic spike period of the neuronal network, the
system dynamics reaches a most ordered state, which is both periodic in time
and nearly synchronized in space, demonstrating an interesting resonance
phenomenon with delay. For the latter case, however, we can not achieve a
similar spatiotemporal ordered state, but the neuronal dynamics exhibits
interesting synchronization transition with time delay from zigzag fronts of
excitations to dynamic clustering anti-phase synchronization (APS), and further
to clustered chimera states which have spatially distributed anti-phase
coherence separated by incoherence. Furthermore, we also show how these
findings are influenced by the change of the noise intensity and the rewiring
probability. Finally, qualitative analysis is given to illustrate the numerical
results.
</summary>
    <author>
      <name>Hao Wu</name>
    </author>
    <author>
      <name>Huijun Jiang</name>
    </author>
    <author>
      <name>Zhonghuai Hou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.chaos.2011.06.016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.chaos.2011.06.016" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.3433v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3433v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2034v1</id>
    <updated>2012-02-09T16:18:13Z</updated>
    <published>2012-02-09T16:18:13Z</published>
    <title>The Complexity of Synaptic Transmission Revealed by a Multiscale
  Analysis Approach From The Molecular to The Cellular Level</title>
    <summary>  Synaptic Transmission is a multiscale process, revealed by various
approaches, going from the molecular to the cellular level. This correspondence
points out to our recent contributions in this field. We now provide the
physical and mathematical foundation, leading to the rational quantification of
the analysis of the stochastic steps, underlying synaptic transmission.
</summary>
    <author>
      <name>David Holcman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This Correspondence contains remarks and comments and corrections on
  a recent review on synaptic transmission and modeling</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.2034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92C20 92C30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5001v2</id>
    <updated>2012-04-24T13:30:27Z</updated>
    <published>2012-04-23T08:48:14Z</published>
    <title>Improving the Entropy Estimate of Neuronal Firings of Modeled Cochlear
  Nucleus Neurons</title>
    <summary>  In this correspondence information theoretical tools are used to investigate
the statistical properties of modeled cochlear nucleus globular bushy cell
spike trains. The firing patterns are obtained from a simulation software that
generates sample spike trains from any auditory input. Here we analyze for the
first time the responses of globular bushy cells to voiced and unvoiced speech
sounds. Classical entropy estimates, such as the direct method, are improved
upon by considering a time-varying and time-dependent entropy estimate. With
this method we investigated the relationship between the predictability of the
neuronal response and the frequency content in the auditory signals. The
analysis quantifies the temporal precision of the neuronal coding and the
memory in the neuronal response.
</summary>
    <author>
      <name>Andrea Grigorescu</name>
    </author>
    <author>
      <name>Marek Rudnicki</name>
    </author>
    <author>
      <name>Michael Isik</name>
    </author>
    <author>
      <name>Werner Hemmert</name>
    </author>
    <author>
      <name>Stefano Rini</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5001v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5001v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3386v1</id>
    <updated>2011-06-17T05:20:47Z</updated>
    <published>2011-06-17T05:20:47Z</published>
    <title>Evolutionary Approaches to Creativity</title>
    <summary>  Many species engage in acts that could be called creative. However, human
creativity is unique in that it has transformed our planet. Given that the
anatomy of the human brain is not so different from that of the great apes,
what enables us to be so creative? Recent collaborations at the frontier of
anthropology, archaeology, psychology, and cognitive science are culminating in
speculative but increasingly sophisticated efforts to answer to this question.
Examining the skeletons of our ancestors gives cues as to anatomical
constraints that hindered or made possible various kinds of creative
expression. Relics of the past have much to tell us about the thoughts,
beliefs, and creative abilities of the people who invented and used them. How
the spectacular creativity of humans came about is the first topic addressed in
this chapter. Studies at the intersection of creativity and evolution are not
limited to investigations into the biological evolution of a highly creative
species. Creative ideas themselves might be said to evolve through culture.
Human creativity is distinctive because of the adaptive and open-ended manner
in which change accumulates. Inventions build on previous ones in ways that
enhance their utility or aesthetic appeal, or make them applicable in different
situations. There is no a priori limit to how a creative idea might unfold. It
is this proclivity to take an idea and make it our own, or 'put our own spin on
it', that makes creative ideas evolve. The next section of this chapter
investigates in what sense creative ideas evolve through culture. Finally, we
address what forces supported the evolution of creativity. Does being creative
help us live longer, or attract mates? Perhaps creative projects can sometimes
interfere with survival and reproductive fitness; are there non-biological
factors that compel us to create? This is a third topic addressed in this
chapter.
</summary>
    <author>
      <name>Liane Gabora</name>
    </author>
    <author>
      <name>Scott Barry Kaufman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Gabora, L. &amp; Kaufman, S. (2010). Evolutionary perspectives on
  creativity. In (J. Kaufman &amp; R. Sternberg, Eds.) The Cambridge Handbook of
  Creativity (pp. 279-300). Cambridge UK: Cambridge University Press</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.3386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2977v1</id>
    <updated>2011-06-15T14:19:48Z</updated>
    <published>2011-06-15T14:19:48Z</published>
    <title>An analysis of the emergence of adaptive Bayesian priors from Hebbian
  learning in a simple attractor network model</title>
    <summary>  We have recently shown that the statistical properties of goal directed
reaching in human subjects depends on recent experience in a way that is
consistent with the presence of adaptive Bayesian priors (Verstynen and Sabes,
2011). We also showed that when Hebbian (associative) learning is added to a
simple line-attractor network model, the network provides both a good account
of the experimental data and a good approximation to a normative Bayesian
estimator. This latter conclusion was based entirely on empirical simulations
of the network model. Here we study the effects of Hebbian learning on the
line-attractor model using a combination of analytic and computational
approaches. Specifically, we find an approximate solution to the network
steady-state. We show numerically that the solution approximates Bayesian
estimation. We next show that the solution contains two opposing terms: one
that depends on the distribution of recent network activity and one that
depends on the current network inputs. These results provide additional
intuition for why Hebbian learning mimics adaptive Bayesian estimation in this
context.
</summary>
    <author>
      <name>Timothy Verstynen</name>
    </author>
    <author>
      <name>Philip N. Sabes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplement to Verstynen and Sabes, "How Each Movement Changes the
  Next: an Experimental and Theoretical Study of Fast Adaptive Priors in
  Reaching", Journal of Neuroscience (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1386v1</id>
    <updated>2011-05-06T21:11:49Z</updated>
    <published>2011-05-06T21:11:49Z</published>
    <title>Self-organized adaptation of a simple neural circuit enables complex
  robot behaviour</title>
    <summary>  Controlling sensori-motor systems in higher animals or complex robots is a
challenging combinatorial problem, because many sensory signals need to be
simultaneously coordinated into a broad behavioural spectrum. To rapidly
interact with the environment, this control needs to be fast and adaptive.
Current robotic solutions operate with limited autonomy and are mostly
restricted to few behavioural patterns. Here we introduce chaos control as a
new strategy to generate complex behaviour of an autonomous robot. In the
presented system, 18 sensors drive 18 motors via a simple neural control
circuit, thereby generating 11 basic behavioural patterns (e.g., orienting,
taxis, self-protection, various gaits) and their combinations. The control
signal quickly and reversibly adapts to new situations and additionally enables
learning and synaptic long-term storage of behaviourally useful motor
responses. Thus, such neural control provides a powerful yet simple way to
self-organize versatile behaviours in autonomous agents with many degrees of
freedom.
</summary>
    <author>
      <name>Silke Steingrube</name>
    </author>
    <author>
      <name>Marc Timme</name>
    </author>
    <author>
      <name>Florentin Woergoetter</name>
    </author>
    <author>
      <name>Poramate Manoonpong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/nphys1860</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/nphys1860" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, non-final version, for final see Nature Physics homepage</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature Phys. 6:224 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5686v1</id>
    <updated>2012-11-24T17:39:07Z</updated>
    <published>2012-11-24T17:39:07Z</published>
    <title>Critical and resonance phenomena in neural networks</title>
    <summary>  Brain rhythms contribute to every aspect of brain function. Here, we study
critical and resonance phenomena that precede the emergence of brain rhythms.
Using an analytical approach and simulations of a cortical circuit model of
neural networks with stochastic neurons in the presence of noise, we show that
spontaneous appearance of network oscillations occurs as a dynamical
(non-equilibrium) phase transition at a critical point determined by the noise
level, network structure, the balance between excitatory and inhibitory
neurons, and other parameters. We find that the relaxation time of neural
activity to a steady state, response to periodic stimuli at the frequency of
the oscillations, amplitude of damped oscillations, and stochastic fluctuations
of neural activity are dramatically increased when approaching the critical
point of the transition.
</summary>
    <author>
      <name>A. V. Goltsev</name>
    </author>
    <author>
      <name>M. A. Lopes</name>
    </author>
    <author>
      <name>K. -E. Lee</name>
    </author>
    <author>
      <name>J. F. F. Mendes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Proceedings of 12th Granada Seminar, September 17-21, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.5686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3563v2</id>
    <updated>2013-06-15T21:15:12Z</updated>
    <published>2012-07-16T02:28:23Z</published>
    <title>A mathematical model of the metabolic and perfusion effects on cortical
  spreading depression</title>
    <summary>  Cortical spreading depression (CSD) is a slow-moving ionic and metabolic
disturbance that propagates in cortical brain tissue. In addition to massive
cellular depolarization, CSD also involves significant changes in perfusion and
metabolism -- aspects of CSD that had not been modeled and are important to
traumatic brain injury, subarachnoid hemorrhage, stroke, and migraine.
  In this study, we develop a mathematical model for CSD where we focus on
modeling the features essential to understanding the implications of
neurovascular coupling during CSD. In our model, the sodium-potassium--ATPase,
mainly responsible for ionic homeostasis and active during CSD, operates at a
rate that is dependent on the supply of oxygen. The supply of oxygen is
determined by modeling blood flow through a lumped vascular tree with an
effective local vessel radius that is controlled by the extracellular potassium
concentration. We show that during CSD, the metabolic demands of the cortex
exceed the physiological limits placed on oxygen delivery, regardless of
vascular constriction or dilation. However, vasoconstriction and vasodilation
play important roles in the propagation of CSD and its recovery. Our model
replicates the qualitative and quantitative behavior of CSD --
vasoconstriction, oxygen depletion, extracellular potassium elevation,
prolonged depolarization -- found in experimental studies.
  We predict faster, longer duration CSD in vivo than in vitro due to the
contribution of the vasculature. Our results also help explain some of the
variability of CSD between species and even within the same animal. These
results have clinical and translational implications, as they allow for more
precise in vitro, in vivo, and in silico exploration of a phenomenon broadly
relevant to neurological disease.
</summary>
    <author>
      <name>Joshua C. Chang</name>
    </author>
    <author>
      <name>K. C. Brennan</name>
    </author>
    <author>
      <name>Dongdong He</name>
    </author>
    <author>
      <name>Huaxiong Huang</name>
    </author>
    <author>
      <name>Robert M. Miura</name>
    </author>
    <author>
      <name>Phillip L. Wilson</name>
    </author>
    <author>
      <name>Jonathan J. Wylie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0070469</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0070469" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages including 9 figures, accepted by PLoS One</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3563v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3563v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4082v1</id>
    <updated>2012-06-18T21:38:05Z</updated>
    <published>2012-06-18T21:38:05Z</published>
    <title>Dorsal lateral geniculate substructure in the Long-Evans rat: A cholera
  toxin B-subunit study</title>
    <summary>  This study describes the substructure of the dorsal lateral geniculate
nucleus of the thalamus of the pigmented rat (Rattus norvegicus) based on the
eye-of-origin of its retinal ganglion cell inputs. We made monocular
intra-ocular injections of the B-subunit of cholera toxin (CTB), a sensitive
anterograde tracer, in three adult male Long-Evans rats. In four additional
subjects, we injected fluorophor-conjugated CTB in both eyes, using a different
fluorophor in each eye. Brains of these subjects were fixed and sectioned, and
the labeled retinal ganglion cell termini were imaged with wide-field
sub-micron resolution slide scanners. Retinal termination zones were traced to
reconstruct a three dimensional model of the ipsilateral and contralateral
retinal termination zones in the dLGN on both sides of the brain. The dLGN
volume was 1.58 \pm0.094 mm^{3}, comprising 70 \pm 3% the volume of the entire
retinorecipient LGN. We find the retinal terminals to be well-segregated by eye
of origin. We consistently found three or four spatially separated
ipsilateral-recipient zones within each dLGN, rather than the single compact
zone expected. It remains to be determined whether these subdomains represent
distinct functional sublaminae.
</summary>
    <author>
      <name>Claire B. Discenza</name>
    </author>
    <author>
      <name>Pamela Reinagel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fnana.2012.00040</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fnana.2012.00040" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Front. Neuroanat. 6:40 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3111v4</id>
    <updated>2012-11-30T20:55:08Z</updated>
    <published>2011-07-15T17:20:20Z</published>
    <title>Decorrelation by recurrent inhibition in heterogeneous neural circuits</title>
    <summary>  The activity of neurons is correlated, and this correlation affects how the
brain processes information. We study the neural circuit mechanisms of
correlations by analyzing a network model characterized by strong and
heterogeneous interactions: excitatory input drives the fluctuations of neural
activity, which are counterbalanced by inhibitory feedback. In particular,
excitatory input tends to correlate neurons, while inhibitory feedback reduces
correlations. We demonstrate that heterogeneity of synaptic connections is
necessary for this inhibition of correlations. We calculate statistical
averages over the disordered synaptic interactions, and we apply our findings
to both a simple linear model and to a more realistic spiking network model. We
find that correlations at zero time-lag are positive and of magnitude K^{-1/2},
where K is the number of connections to a neuron. Correlations at longer
timescales are of smaller magnitude, of order K^{-1}, implying that inhibition
of correlations occurs quickly, on a timescale of K^{-1/2}. The small magnitude
of correlations agrees qualitatively with physiological measurements in the
Cerebral Cortex and Basal Ganglia. The model could be used to study
correlations in brain regions dominated by recurrent inhibition, such as the
Striatum and Globus Pallidus.
</summary>
    <author>
      <name>Alberto Bernacchia</name>
    </author>
    <author>
      <name>Xiao-Jing Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3111v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3111v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2743v2</id>
    <updated>2013-06-18T15:27:41Z</updated>
    <published>2012-07-11T18:45:51Z</published>
    <title>The evolutionary origins of modularity</title>
    <summary>  A central biological question is how natural organisms are so evolvable
(capable of quickly adapting to new environments). A key driver of evolvability
is the widespread modularity of biological networks--their organization as
functional, sparsely connected subunits--but there is no consensus regarding
why modularity itself evolved. While most hypotheses assume indirect selection
for evolvability, here we demonstrate that the ubiquitous, direct selection
pressure to reduce the cost of connections between network nodes causes the
emergence of modular networks. Experiments with selection pressures to maximize
network performance and minimize connection costs yield networks that are
significantly more modular and more evolvable than control experiments that
only select for performance. These results will catalyze research in numerous
disciplines, including neuroscience, genetics and harnessing evolution for
engineering purposes.
</summary>
    <author>
      <name>Jeff Clune</name>
    </author>
    <author>
      <name>Jean-Baptiste Mouret</name>
    </author>
    <author>
      <name>Hod Lipson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rspb.2012.2863</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rspb.2012.2863" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Clune J, Mouret J-B, Lipson H. 2013 The evolutionary origins of
  modularity. Proceedings of the Royal Society B. 280: 20122863</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.2743v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2743v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4823v1</id>
    <updated>2011-04-25T23:39:12Z</updated>
    <published>2011-04-25T23:39:12Z</published>
    <title>The what and where of adding channel noise to the Hodgkin-Huxley
  equations</title>
    <summary>  One of the most celebrated successes in computational biology is the
Hodgkin-Huxley framework for modeling electrically active cells. This
framework, expressed through a set of differential equations, synthesizes the
impact of ionic currents on a cell's voltage -- and the highly nonlinear impact
of that voltage back on the currents themselves -- into the rapid push and pull
of the action potential. Latter studies confirmed that these cellular dynamics
are orchestrated by individual ion channels, whose conformational changes
regulate the conductance of each ionic current. Thus, kinetic equations
familiar from physical chemistry are the natural setting for describing
conductances; for small-to-moderate numbers of channels, these will predict
fluctuations in conductances and stochasticity in the resulting action
potentials. At first glance, the kinetic equations provide a far more complex
(and higher-dimensional) description than the original Hodgkin-Huxley
equations. This has prompted more than a decade of efforts to capture channel
fluctuations with noise terms added to the Hodgkin-Huxley equations. Many of
these approaches, while intuitively appealing, produce quantitative errors when
compared to kinetic equations; others, as only very recently demonstrated, are
both accurate and relatively simple. We review what works, what doesn't, and
why, seeking to build a bridge to well-established results for the
deterministic Hodgkin-Huxley equations. As such, we hope that this review will
speed emerging studies of how channel noise modulates electrophysiological
dynamics and function. We supply user-friendly Matlab simulation code of these
stochastic versions of the Hodgkin-Huxley equations on the ModelDB website
(accession number 138950) and
http://www.amath.washington.edu/~etsb/tutorials.html.
</summary>
    <author>
      <name>Joshua H. Goldwyn</name>
    </author>
    <author>
      <name>Eric Shea-Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, review article</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0868v1</id>
    <updated>2012-03-05T11:29:15Z</updated>
    <published>2012-03-05T11:29:15Z</published>
    <title>Computational modeling of neuronal networks</title>
    <summary>  Human brain contains about 10 billion neurons, each of which has about
10~10,000 nerve endings from which neurotransmitters are released in response
to incoming spikes, and the released neurotransmitters then bind to receptors
located in the postsynaptic neurons. However, individually, neurons are noisy
and synaptic release is in general unreliable. But groups of neurons that are
arranged in specialized modules can collectively perform complex information
processing tasks robustly and reliably. How functionally groups of neurons
perform behavioural related tasks crucial rely on a coherent organization of
dynamics from membrane ionic kinetics to synaptic coupling of the network and
dynamics of rhythmic oscillations that are tightly linked to behavioural state.
  To capture essential features of the biological system at multiple
spatial-temporal scales, it is important to construct a suitable computational
model that is closely or solely based on experimental data. Depending on what
one wants to understand, these models can either be very functional and
biologically realistic descriptions with thousands of coupled differential
equations (Hodgkin-Huxley type) or greatly simplified caricatures
(integrate-and-fire type) which are useful for studying large interconnected
networks.
</summary>
    <author>
      <name>Xuejuan Zhang</name>
    </author>
    <author>
      <name>Jianfeng Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.0868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.3106v1</id>
    <updated>2011-05-16T14:37:15Z</updated>
    <published>2011-05-16T14:37:15Z</published>
    <title>Collective stability of networks of winner-take-all circuits</title>
    <summary>  The neocortex has a remarkably uniform neuronal organization, suggesting that
common principles of processing are employed throughout its extent. In
particular, the patterns of connectivity observed in the superficial layers of
the visual cortex are consistent with the recurrent excitation and inhibitory
feedback required for cooperative-competitive circuits such as the soft
winner-take-all (WTA). WTA circuits offer interesting computational properties
such as selective amplification, signal restoration, and decision making. But,
these properties depend on the signal gain derived from positive feedback, and
so there is a critical trade-off between providing feedback strong enough to
support the sophisticated computations, while maintaining overall circuit
stability. We consider the question of how to reason about stability in very
large distributed networks of such circuits. We approach this problem by
approximating the regular cortical architecture as many interconnected
cooperative-competitive modules. We demonstrate that by properly understanding
the behavior of this small computational module, one can reason over the
stability and convergence of very large networks composed of these modules. We
obtain parameter ranges in which the WTA circuit operates in a high-gain
regime, is stable, and can be aggregated arbitrarily to form large stable
networks. We use nonlinear Contraction Theory to establish conditions for
stability in the fully nonlinear case, and verify these solutions using
numerical simulations. The derived bounds allow modes of operation in which the
WTA network is multi-stable and exhibits state-dependent persistent activities.
Our approach is sufficiently general to reason systematically about the
stability of any network, biological or technological, composed of networks of
small modules that express competition through shared inhibition.
</summary>
    <author>
      <name>Ueli Rutishauser</name>
    </author>
    <author>
      <name>Rodney J. Douglas</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1162/NECO_a_00091</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1162/NECO_a_00091" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural computation 23(3):735-773, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.3106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.3106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6445v2</id>
    <updated>2013-03-07T17:07:06Z</updated>
    <published>2012-09-28T08:07:33Z</published>
    <title>A Balance Equation Determines a Switch in Neuronal Excitability</title>
    <summary>  We use the qualitative insight of a planar neuronal phase portrait to detect
an excitability switch in arbitrary conductance-based models from a simple
mathematical condition. The condition expresses a balance between ion channels
that provide a negative feedback at resting potential (restorative channels)
and those that provide a positive feedback at resting potential (regenerative
channels). Geometrically, the condition imposes a transcritical bifurcation
that rules the switch of excitability through the variation of a single
physiological parameter. Our analysis of six different published conductance
based models always finds the transcritical bifurcation and the associated
switch in excitability, which suggests that the mathematical predictions have a
physiological relevance and that a same regulatory mechanism is potentially
involved in the excitability and signaling of many neurons.
</summary>
    <author>
      <name>Alessio Franci</name>
    </author>
    <author>
      <name>Guillaume Drion</name>
    </author>
    <author>
      <name>Vincent Seutin</name>
    </author>
    <author>
      <name>Rodolphe Sepulchre</name>
    </author>
    <link href="http://arxiv.org/abs/1209.6445v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6445v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2148v1</id>
    <updated>2012-02-09T23:03:57Z</updated>
    <published>2012-02-09T23:03:57Z</published>
    <title>Neurogenesis Drives Stimulus Decorrelation in a Model of the Olfactory
  Bulb</title>
    <summary>  The reshaping and decorrelation of similar activity patterns by neuronal
networks can enhance their discriminability, storage, and retrieval. How can
such networks learn to decorrelate new complex patterns, as they arise in the
olfactory system? Using a computational network model for the dominant neural
populations of the olfactory bulb we show that fundamental aspects of the adult
neurogenesis observed in the olfactory bulb -- the persistent addition of new
inhibitory granule cells to the network, their activity-dependent survival, and
the reciprocal character of their synapses with the principal mitral cells --
are sufficient to restructure the network and to alter its encoding of odor
stimuli adaptively so as to reduce the correlations between the bulbar
representations of similar stimuli. The decorrelation is quite robust with
respect to various types of perturbations of the reciprocity. The model
parsimoniously captures the experimentally observed role of neurogenesis in
perceptual learning and the enhanced response of young granule cells to novel
stimuli. Moreover, it makes specific predictions for the type of odor
enrichment that should be effective in enhancing the ability of animals to
discriminate similar odor mixtures.
</summary>
    <author>
      <name>Siu-Fai Chow</name>
    </author>
    <author>
      <name>Stuart D. Wick</name>
    </author>
    <author>
      <name>Hermann Riecke</name>
    </author>
    <link href="http://arxiv.org/abs/1202.2148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.0604v2</id>
    <updated>2012-05-11T19:44:09Z</updated>
    <published>2011-02-03T06:03:41Z</published>
    <title>A small-world of weak ties provides optimal global integration of
  self-similar modules in functional brain networks</title>
    <summary>  The human brain is organized in functional modules. Such an organization
presents a basic conundrum: modules ought to be sufficiently independent to
guarantee functional specialization and sufficiently connected to bind multiple
processors for efficient information transfer. It is commonly accepted that
small-world architecture of short lengths and large local clustering may solve
this problem. However, there is intrinsic tension between shortcuts generating
small-worlds and the persistence of modularity; a global property unrelated to
local clustering. Here, we present a possible solution to this puzzle. We first
show that a modified percolation theory can define a set of hierarchically
organized modules made of strong links in functional brain networks. These
modules are "large-world" self-similar structures and, therefore, are far from
being small-world. However, incorporating weaker ties to the network converts
it into a small-world preserving an underlying backbone of well-defined
modules. Remarkably, weak ties are precisely organized as predicted by theory
maximizing information transfer with minimal wiring cost. This trade-off
architecture is reminiscent of the "strength of weak ties" crucial concept of
social networks. Such a design suggests a natural solution to the paradox of
efficient information flow in the highly modular structure of the brain.
</summary>
    <author>
      <name>Lazaros K. Gallos</name>
    </author>
    <author>
      <name>Hernan A. Makse</name>
    </author>
    <author>
      <name>Mariano Sigman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the National Academy of Sciences USA, 109, 2825
  (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.0604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.0604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3106v1</id>
    <updated>2012-12-13T10:07:11Z</updated>
    <published>2012-12-13T10:07:11Z</published>
    <title>Self-organized criticality in neural network models</title>
    <summary>  It has long been argued that neural networks have to establish and maintain a
certain intermediate level of activity in order to keep away from the regimes
of chaos and silence. Strong evidence for criticality has been observed in
terms of spatio-temporal activity avalanches first in cultures of rat cortex by
Beggs and Plenz (2003) and subsequently in many more experimental setups. These
findings sparked intense research on theoretical models for criticality and
avalanche dynamics in neural networks, where usually some dynamical order
parameter is fed back onto the network topology by adapting the synaptic
couplings. We here give an overview of existing theoretical models of dynamical
networks. While most models emphasize biological and neurophysiological detail,
our path here is different: we pick up the thread of an early self-organized
critical neural network model by Bornholdt and Roehl (2001) and test its
applicability in the light of experimental data. Keeping the simplicity of
early models, and at the same time lifting the drawback of a spin formulation
with respect to the biological system, we here study an improved model
(Rybarsch and Bornholdt, 2012b) and show that it adapts to criticality
exhibiting avalanche statistics that compare well with experimental data
without the need for parameter tuning.
</summary>
    <author>
      <name>Matthias Rybarsch</name>
    </author>
    <author>
      <name>Stefan Bornholdt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In "Criticality in Neural Systems", Niebur E, Plenz D, Schuster HG
  (eds.) 2013 (in press)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0986v1</id>
    <updated>2012-08-05T07:17:40Z</updated>
    <published>2012-08-05T07:17:40Z</published>
    <title>Spatial constraints underlying the retinal mosaics of two types of
  horizontal cells in cat and macaque</title>
    <summary>  Most types of retinal neurons are spatially positioned in non-random
patterns, termed retinal mosaics. Several developmental mechanisms are thought
to be important in the formation of these mosaics. Most evidence to date
suggests that homotypic constraints within a type of neuron are dominant, and
that heterotypic interactions between different types of neuron are rare. In an
analysis of macaque H1 and H2 horizontal cell mosaics, W\"assle et al. (2000)
suggested that the high regularity index of the combined H1 and H2 mosaic might
be caused by heterotypic interactions during development. Here we use computer
modelling to suggest that the high regularity index of the combined H1 and H2
mosaic is a by-product of the basic constraint that two neurons cannot occupy
the same space. The spatial arrangement of type A and type B horizontal cells
in cat retina also follow this same principle.
</summary>
    <author>
      <name>Stephen J. Eglen</name>
    </author>
    <author>
      <name>James C. T. Wong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S0952523808080176</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S0952523808080176" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Visual Neuroscience (2008) 25:209--214</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.0986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0574v1</id>
    <updated>2012-04-03T02:20:09Z</updated>
    <published>2012-04-03T02:20:09Z</published>
    <title>Phase lagging model of brain response to external stimuli - modeling of
  single action potential</title>
    <summary>  In this paper we detail a phase lagging model of brain response to external
stimuli. The model is derived using the basic laws of physics like conservation
of energy law. This model eliminates the paradox of instantaneous propagation
of the action potential in the brain. The solution of this model is then
presented. The model is further applied in the case of a single neuron and is
verified by simulating a single action potential. The results of this modeling
are useful not only for the fundamental understanding of single action
potential generation, but also they can be applied in case of neuronal
interactions where the results can be verified against the real EEG signal.
</summary>
    <author>
      <name>Karthik Seetharaman</name>
    </author>
    <author>
      <name>Hamidreza Namazi</name>
    </author>
    <author>
      <name>Vladimir V. Kulish</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0576v1</id>
    <updated>2012-04-03T02:42:45Z</updated>
    <published>2012-04-03T02:42:45Z</published>
    <title>Diffusion Based Modeling of Human Brain Response to External Stimuli</title>
    <summary>  Human brain response is the overall ability of the brain in analyzing
internal and external stimuli in the form of transferred energy to the
mind/brain phase-space and thus, making the proper decisions. During the last
decade scientists discovered about this phenomenon and proposed some models
based on computational, biological, or neuropsychological methods. Despite some
advances in studies related to this area of the brain research there was less
effort which have been done on the mathematical modeling of the human brain
response to external stimuli. This research is devoted to the modeling of human
EEG signal, as an alert state of overall human brain activity monitoring, due
to receiving external stimuli, based on fractional diffusion equation. The
results of this modeling show very good agreement with the real human EEG
signal and thus, this model can be used as a strong representative of the human
brain activity.
</summary>
    <author>
      <name>Hamidreza Namazi</name>
    </author>
    <author>
      <name>Vladimir V. Kulish</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0469v2</id>
    <updated>2013-02-07T17:02:21Z</updated>
    <published>2012-12-03T17:59:52Z</published>
    <title>Pushing the Communication Speed Limit of a Noninvasive BCI Speller</title>
    <summary>  Electroencephalogram (EEG) based brain-computer interfaces (BCI) may provide
a means of communication for those affected by severe paralysis. However, the
relatively low information transfer rates (ITR) of these systems, currently
limited to 1 bit/sec, present a serious obstacle to their widespread adoption
in both clinical and non-clinical applications. Here, we report on the
development of a novel noninvasive BCI communication system that achieves ITRs
that are severalfold higher than those previously reported with similar
systems. Using only 8 EEG channels, 6 healthy subjects with little to no prior
BCI experience selected characters from a virtual keyboard with sustained,
error-free, online ITRs in excess of 3 bit/sec. By factoring in the time spent
to notify the subjects of their selection, practical, error-free typing rates
as high as 12.75 character/min were achieved, which allowed subjects to
correctly type a 44-character sentence in less than 3.5 minutes. We hypothesize
that ITRs can be further improved by optimizing the parameters of the
interface, while practical typing rates can be significantly improved by
shortening the selection notification time. These results provide compelling
evidence that the ITR limit of noninvasive BCIs has not yet been reached and
that further investigation into this matter is both justified and necessary.
</summary>
    <author>
      <name>Po T. Wang</name>
    </author>
    <author>
      <name>Christine E. King</name>
    </author>
    <author>
      <name>An H. Do</name>
    </author>
    <author>
      <name>Zoran Nenadic</name>
    </author>
    <link href="http://arxiv.org/abs/1212.0469v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0469v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4786v1</id>
    <updated>2011-05-24T14:40:41Z</updated>
    <published>2011-05-24T14:40:41Z</published>
    <title>Failure of adaptive self-organized criticality during epileptic seizure
  attacks</title>
    <summary>  Critical dynamics are assumed to be an attractive mode for normal brain
functioning as information processing and computational capabilities are found
to be optimized there. Recent experimental observations of neuronal activity
patterns following power-law distributions, a hallmark of systems at a critical
state, have led to the hypothesis that human brain dynamics could be poised at
a phase transition between ordered and disordered activity. A so far unresolved
question concerns the medical significance of critical brain activity and how
it relates to pathological conditions. Using data from invasive
electroencephalogram recordings from humans we show that during epileptic
seizure attacks neuronal activity patterns deviate from the normally observed
power-law distribution characterizing critical dynamics. The comparison of
these observations to results from a computational model exhibiting
self-organized criticality (SOC) based on adaptive networks allows further
insights into the underlying dynamics. Together these results suggest that
brain dynamics deviates from criticality during seizures caused by the failure
of adaptive SOC.
</summary>
    <author>
      <name>Christian Meisel</name>
    </author>
    <author>
      <name>Alexander Storch</name>
    </author>
    <author>
      <name>Susanne Hallmeyer-Elgner</name>
    </author>
    <author>
      <name>Ed Bullmore</name>
    </author>
    <author>
      <name>Thilo Gross</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1160v2</id>
    <updated>2011-09-23T12:11:35Z</updated>
    <published>2011-07-06T15:29:30Z</published>
    <title>Power-law forgetting in synapses with metaplasticity</title>
    <summary>  The idea of using metaplastic synapses to incorporate the separate storage of
long- and short-term memories via an array of hidden states was put forward in
the cascade model of Fusi et al. In this paper, we devise and investigate two
models of a metaplastic synapse based on these general principles. The main
difference between the two models lies in their available mechanisms of decay,
when a contrarian event occurs after the build-up of a long-term memory. In one
case, this leads to the conversion of the long-term memory to a short-term
memory of the opposite kind, while in the other, a long-term memory of the
opposite kind may be generated as a result. Appropriately enough, the response
of both models to short-term events is not affected by this difference in
architecture. On the contrary, the transient response of both models, after
long-term memories have been created by the passage of sustained signals, is
rather different. The asymptotic behaviour of both models is, however,
characterised by power-law forgetting with the same universal exponent.
</summary>
    <author>
      <name>A. Mehta</name>
    </author>
    <author>
      <name>J. M. Luck</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2011/09/P09025</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2011/09/P09025" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 17 figures. A few updates and other minor changes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2011) P09025</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.1160v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1160v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3677v1</id>
    <updated>2011-10-14T14:11:10Z</updated>
    <published>2011-10-14T14:11:10Z</published>
    <title>Cortical phase transitions, non-equilibrium thermodynamics and the
  time-dependent Ginzburg-Landau equation</title>
    <summary>  The formation of amplitude modulated and phase modulated assemblies of
neurons is observed in the brain functional activity. The study of the
formation of such structures requires that the analysis has to be organized in
hierarchical levels, microscopic, mesoscopic, macroscopic, each with its
characteristic space-time scales and the various forms of energy, electric,
chemical, thermal produced and used by the brain. In this paper, we discuss the
microscopic dynamics underlying the mesoscopic and the macroscopic levels and
focus our attention on the thermodynamics of the non-equilibrium phase
transitions. We obtain the time-dependent Ginzburg-Landau equation for the
non-stationary regime and consider the formation of topologically non-trivial
structures such as the vortex solution. The power laws observed in functional
activities of the brain is also discussed and related to coherent states
characterizing the many-body dissipative model of brain.
</summary>
    <author>
      <name>W. J. Freeman</name>
    </author>
    <author>
      <name>R. Livi</name>
    </author>
    <author>
      <name>M. Obinata</name>
    </author>
    <author>
      <name>G. Vitiello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures, research paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.3677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7165v1</id>
    <updated>2012-10-26T15:15:08Z</updated>
    <published>2012-10-26T15:15:08Z</published>
    <title>Cellular Adaptation Accounts for the Sparse and Reliable Sensory
  Stimulus Representation</title>
    <summary>  Most neurons in peripheral sensory pathways initially respond vigorously when
a preferred stimulus is presented, but adapt as stimulation continues. It is
unclear how this phenomenon affects stimulus representation in the later stages
of cortical sensory processing. Here, we show that a temporally sparse and
reliable stimulus representation develops naturally in a network with adapting
neurons. We find that cellular adaptation plays a critical role in the
transient reduction of the trial-by-trial variability of cortical spiking,
providing an explanation for a wide-spread and hitherto unexplained phenomenon
by a simple mechanism. In insect olfaction, cellular adaptation is sufficient
to explain the emergence of the temporally sparse and reliable stimulus
representation in the mushroom body, independent of inhibitory mechanisms. Our
results reveal a computational principle that relates neuronal firing rate
adaptation to temporal sparse coding and variability suppression in nervous
systems with a sequential processing architecture.
</summary>
    <author>
      <name>Farzad Farkhooi</name>
    </author>
    <author>
      <name>Anja Froese</name>
    </author>
    <author>
      <name>Eilif Muller</name>
    </author>
    <author>
      <name>Randolf Menzel</name>
    </author>
    <author>
      <name>Martin P. Nawrot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.7165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3805v1</id>
    <updated>2011-04-19T17:12:50Z</updated>
    <published>2011-04-19T17:12:50Z</published>
    <title>How shoud prey animals respond to uncertain threats?</title>
    <summary>  A prey animal surveying its environment must decide whether there is a
dangerous predator present or not. If there is, it may flee. Flight has an
associated cost, so the animal should not flee if there is no danger. However,
the prey animal cannot know the state of its environment with certainty, and is
thus bound to make some errors. We formulate a probabilistic automaton model of
a prey animal's life and use it to compute the optimal escape decision
strategy, subject to the animal's uncertainty. The uncertainty is a major
factor in determining the decision strategy: only in the presence of
uncertainty do economic factors (like mating opportunities lost due to flight)
influence the decision. We performed computer simulations and found that
\emph{in silico} populations of animals subject to predation evolve to display
the strategies predicted by our model, confirming our choice of objective
function for our analytic calculations. To the best of our knowledge, this is
the first theoretical study of escape decisions to incorporate the effects of
uncertainty, and to demonstrate the correctness of the objective function used
in the model.
</summary>
    <author>
      <name>Joel Zylberberg</name>
    </author>
    <author>
      <name>Michael R. DeWeese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fncom.2011.00020</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fncom.2011.00020" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 figures, 10 pages of text</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers in Computational Neuroscience (2011) 5:20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.3805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2901v1</id>
    <updated>2012-10-10T13:07:09Z</updated>
    <published>2012-10-10T13:07:09Z</published>
    <title>Transient to Zero-Lag Synchronization in Excitable Networks</title>
    <summary>  The scaling of transient times to zero-lag synchronization in networks
composed of excitable units is shown to be governed by three features of the
graph representing the network: the longest path between pairs of neurons
(diameter), the largest loop (circumference) and the loop with the maximal
average out degree. The upper bound of transient times can vary between O(1)
and O(N2), where N is the size of the network, and its scaling can be predicted
in many scenarios from finite time accumulated information of the transient.
Results challenge the assumption that functionality of neural networks might
depend solely upon the synchronized repeated activation such as zero-lag
synchronization.
</summary>
    <author>
      <name>H. Brama</name>
    </author>
    <author>
      <name>Y. Peleg</name>
    </author>
    <author>
      <name>W. Kinzel</name>
    </author>
    <author>
      <name>I. Kanter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3822v1</id>
    <updated>2012-04-17T16:05:55Z</updated>
    <published>2012-04-17T16:05:55Z</published>
    <title>Energy efficiency of information transmission by electrically coupled
  neurons</title>
    <summary>  The generation of spikes by neurons is energetically a costly process. This
paper studies the consumption of energy and the information entropy in the
signalling activity of a model neuron both when it is supposed isolated and
when it is coupled to another neuron by an electrical synapse. The neuron has
been modelled by a four dimensional Hindmarsh-Rose type kinetic model for which
an energy function has been deduced. For the isolated neuron values of energy
consumption and information entropy at different signalling regimes have been
computed. For two neurons coupled by a gap junction we have analyzed the roles
of the membrane and synapse in the contribution of the energy that is required
for their organized signalling. Computational results are provided for cases of
identical and nonidentical neurons coupled by unidirectional and bidirectional
gap junctions. One relevant result is that there are values of the coupling
strength at which the organized signalling of two neurons induced by the gap
junction takes place at relatively low values of energy consumption and the
ratio of mutual information to energy consumption is relatively high.
Therefore, communicating at these coupling values could be energetically the
most efficient option.
</summary>
    <author>
      <name>Francisco J. Torrealdea</name>
    </author>
    <author>
      <name>Cecilia Sarasola</name>
    </author>
    <author>
      <name>Alicia d'Anjou</name>
    </author>
    <author>
      <name>Abdelmalik Moujahid</name>
    </author>
    <author>
      <name>N. Vélez de Mendizábal</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.biosystems.2009.04.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.biosystems.2009.04.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Biosystems 97 (2009) 60-71</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.3822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0083v1</id>
    <updated>2012-12-01T08:27:24Z</updated>
    <published>2012-12-01T08:27:24Z</published>
    <title>From the decoding of cortical activities to the control of a JACO
  robotic arm: a whole processing chain</title>
    <summary>  This paper presents a complete processing chain for decoding intracranial
data recorded in the cortex of a monkey and replicates the associated movements
on a JACO robotic arm by Kinova. We developed specific modules inside the
OpenViBE platform in order to build a Brain-Machine Interface able to read the
data, compute the position of the robotic finger and send this position to the
robotic arm. More pre- cisely, two client/server protocols have been tested to
transfer the finger positions: VRPN and a light protocol based on TCP/IP
sockets. According to the requested finger position, the server calls the
associ- ated functions of an API by Kinova to move the fin- gers properly.
Finally, we monitor the gap between the requested and actual fingers positions.
This chain can be generalized to any movement of the arm or wrist.
</summary>
    <author>
      <name>Laurent Bougrain</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Rochel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Octave Boussaton</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Lionel Havet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CAR - Control Architecture of Robots - 2012 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.0083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4059v1</id>
    <updated>2011-12-17T14:39:07Z</updated>
    <published>2011-12-17T14:39:07Z</published>
    <title>Synchronous chaos and broad band gamma rhythm in a minimal multi-layer
  model of primary visual cortex</title>
    <summary>  Visually induced neuronal activity in V1 displays a marked gamma-band
component which is modulated by stimulus properties. It has been argued that
synchronized oscillations contribute to these gamma-band activity [...
however,] even when oscillations are observed, they undergo temporal
decorrelation over very few cycles. This is not easily accounted for in
previous network modeling of gamma oscillations. We argue here that
interactions between cortical layers can be responsible for this fast
decorrelation. We study a model of a V1 hypercolumn, embedding a simplified
description of the multi-layered structure of the cortex. When the stimulus
contrast is low, the induced activity is only weakly synchronous and the
network resonates transiently without developing collective oscillations. When
the contrast is high, on the other hand, the induced activity undergoes
synchronous oscillations with an irregular spatiotemporal structure expressing
a synchronous chaotic state. As a consequence the population activity undergoes
fast temporal decorrelation, with concomitant rapid damping of the oscillations
in LFPs autocorrelograms and peak broadening in LFPs power spectra. [...]
Finally, we argue that the mechanism underlying the emergence of synchronous
chaos in our model is in fact very general. It stems from the fact that gamma
oscillations induced by local delayed inhibition tend to develop chaos when
coupled by sufficiently strong excitation.
</summary>
    <author>
      <name>Demian Battaglia</name>
    </author>
    <author>
      <name>David Hansel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1002176</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1002176" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages, 11 figures, 7 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published in PLoS Comput Biol 7(10): e1002176 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.4059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4751v1</id>
    <updated>2012-02-21T20:55:07Z</updated>
    <published>2012-02-21T20:55:07Z</published>
    <title>Fractal-based Correlation Analysis for Resting State Functional
  Connectivity of the Rat Brain in Functional MRI</title>
    <summary>  The most studies on functional connectivity have been done by analyzing the
brain's hemodynamic response to a stimulation. On the other hand, the
low-frequency spontaneous fluctuations in the blood oxygen level dependent
(BOLD) signals of functional MRI have been observed in the resting state.
However, the BOLD signals in resting state are significantly corrupted by huge
noises arising from cardiac pulsation, respiration, subject motion, scanner,
and so forth. Especially, the noise compounds are stronger in the rat brain
than in the human brain. To overcome such an artifact, we assumed that fractal
behavior in BOLD signals reflects low frequency neural activity, and applied
the theorem such that the wavelet correlation spectrum between long memory
processes is scale-invariant over low frequency scales. Here, we report an
experiment that shows special correlation patterns not only in correlation of
scaling coefficients in very low-frequency band (less than 0.0078Hz) but also
in asymptotic wavelet correlation. In addition, we show the distribution of the
Hurst exponents in the rat brain.
</summary>
    <author>
      <name>Wonsang You</name>
    </author>
    <author>
      <name>Joerg Stadler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CBBS Educational Workshop on Resting State fMRI 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.2407v3</id>
    <updated>2011-10-31T09:36:56Z</updated>
    <published>2011-08-11T14:11:01Z</published>
    <title>On the dynamics of mean-field equations for stochastic neural fields
  with delays</title>
    <summary>  The cortex is composed of large-scale cell assemblies sharing the same
individual properties and receiving the same input, in charge of certain
functions, and subject to noise. Such assemblies are characterized by specific
space locations and space-dependent delayed interactions. The mean-field
equations for such systems were rigorously derived in a recent paper for
general models, under mild assumptions on the network, using probabilistic
methods. We summarize and investigate general implications of this result. We
then address the dynamics of these stochastic neural field equations in the
case of firing-rate neurons. This is a unique case where the very complex
stochastic mean-field equations exactly reduce to a set of delayed differential
or integro-differential equations on the two first moments of the solutions,
this reduction being possible due to the Gaussian nature of the solutions. The
obtained equations differ from more customary approaches in that it
incorporates intrinsic noise levels nonlinearly and make explicit the
interaction between the mean activity and its correlations. We analyze the
dynamics of these equations, with a particular focus on the influence of noise
levels on shaping the collective response of neural assemblies and brain
states. Cascades of Hopf bifurcations are observed as a function of noise
amplitude, for noise levels small enough, and delays, in a finite-population
system. The presence of spatially homogeneous solutions in law is discussed in
different non-delayed neural fields and an instability, as noise amplitude is
varied, of the homogeneous state, is found. In these regimes, very complex
irregular and structured spatio-temporal patterns of activity are exhibited
including in particular wave or bump splitting.
</summary>
    <author>
      <name>Jonathan Touboul</name>
    </author>
    <link href="http://arxiv.org/abs/1108.2407v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.2407v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0751v2</id>
    <updated>2013-01-13T01:00:17Z</updated>
    <published>2012-04-03T18:02:02Z</published>
    <title>Optimal Channel Efficiency in a Sensory Network</title>
    <summary>  We show that the entropy of the distribution of avalanche lifetimes in the
Kinouchi-Copelli model always achieves a maximum jointly with the dynamic
range. This is noteworthy and nontrivial because while the dynamic range is an
equilibrium average measure of the sensibility of a sensory system to a
stimulus, the entropy of relaxation times is a purely dynamical quantity,
independent of the stimulus rate, that can be interpreted as the efficiency of
the network seen as a communication channel. The newly found optimization
occurs for all topologies we tested, even when the distribution of avalanche
lifetimes itself is not a power-law and when the entropy of the size
distribution of avalanches is not concomitantly maximized, strongly suggesting
that dynamical rules allowing a proper temporal matching of the states of the
interacting neurons is the key for achieving good performance in information
processing, rather than increasing the number of available units.
</summary>
    <author>
      <name>Thiago S. Mosqueiro</name>
    </author>
    <author>
      <name>Leonardo P. Maia</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.88.012712</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.88.012712" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 captions, submitted</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 88 (1) 012712 - 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.0751v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0751v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
